{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bee and hornet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a link to the genome assemblies that we did: https://www.dropbox.com/sh/8leaqum6nnvrein/AADBQfsW7UvLZI7ZBfsDs1sza?dl=0   The assemblies are a mix of Oxford Nanopore and Illumina and are pretty good.   It would probably be best if your postdoc could run MAKER2 to do the annotation and BUSCO: https://busco.ezlab.org/ which gives a good picture of assembly completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run maker2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Elf server, creat environment with `conda create -p /gpfs/gpfs/scratch/xc278/maker2`\n",
    "\n",
    "install genemark-es manually. link the file to the bin path of the environment \n",
    "`ln -s /gpfs/gpfs/scratch/xc278/p/gm_et_linux_64/gmes_petap/gmhmme3 /gpfs/gpfs/scratch/xc278/maker2/bin/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix problem with repeatmasker `https://wiki.hpcc.msu.edu/display/ITH/Installing+maker+using+conda?preview=/29655183/29655184/repeatmasker-small-copy.mp4`\n",
    "\n",
    "```bash\n",
    "source activate /gpfs/gpfs/scratch/xc278/maker2\n",
    "cd /gpfs/gpfs/scratch/xc278/maker2/share/RepeatMasker\n",
    "perl ./configure\n",
    "```\n",
    "finish as in the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trinity assembly for Vespa mandarinia\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/sra/?term=SRP064879\n",
    "\n",
    "SRR2664950\n",
    "\n",
    "Note: need to install Trinity, bowtie2 and other required programs. `conda bioconda` installed Trinity seems not working\n",
    "\n",
    "```bash\n",
    "source activate bio\n",
    "cd /home/scratch\n",
    "wget ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/SRR266/SRR2664950/SRR2664950.sra\n",
    "fastq-dump --split-files '@$sn[_$rn]/$ri' -O ./ SRR2664950.sra\n",
    "\n",
    "Trinity  --seqType fq  --max_memory 240G --CPU 36 --trimmomatic --no_normalize_reads --output /home/scratch/Trinity/  --left  SRR2664950_1.fastq   --right SRR2664950_2.fastq\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare reference sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download swissprot sequence from uniprot website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for bee, choose protein sequences from the Apis genus as reference. download protein and transcript models from three available species from the link `https://www.ncbi.nlm.nih.gov/genome/?term=txid7459[Organism:exp]`\n",
    "* Apis mellifera\n",
    "* Apis cerana\n",
    "* Apis dorsata\n",
    "* Apis florea\n",
    "\n",
    "for hornet, choose protein sequences from the Vespidae family as references. download protein and transcript sequences of available species from the link `https://www.ncbi.nlm.nih.gov/genome/?term=txid7438[Organism:exp]`\n",
    "* Polistes dominula\n",
    "* Polistes canadensis\n",
    "\n",
    "\n",
    "reference sequences are \n",
    "```\n",
    "GCF_000184785.2_Aflo_1.0_protein.faa\n",
    "GCF_000184785.2_Aflo_1.0_rna.fna\n",
    "GCF_000469605.1_Apis_dorsata_1.3_protein.faa\n",
    "GCF_000469605.1_Apis_dorsata_1.3_rna.fna\n",
    "GCF_001313835.1_ASM131383v1_protein.faa\n",
    "GCF_001313835.1_ASM131383v1_rna.fna\n",
    "GCF_001442555.1_ACSNU-2.0_protein.faa\n",
    "GCF_001442555.1_ACSNU-2.0_rna.fna\n",
    "GCF_001465965.1_Pdom_r1.2_protein.faa\n",
    "GCF_001465965.1_Pdom_r1.2_rna.fna\n",
    "GCF_003254395.2_Amel_HAv3.1_protein.faa\n",
    "GCF_003254395.2_Amel_HAv3.1_rna.fna\n",
    "te_proteins.fasta\n",
    "uniprot_sprot.fasta\n",
    "```\n",
    "\n",
    "combine the protein sequences to file `/gpfs/gpfs/staging/jx76-003/2019Bee/ref/ref.proteins.faa` and rna sequences to `/gpfs/gpfs/staging/jx76-003/2019Bee/ref/ref.rna.faa`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TE sequences (transposobale elements)\n",
    "`https://github.com/Yandell-Lab/RepeatRunner/blob/master/sample_data/te_proteins.fasta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean sequences, some nt sequences contains unwanted letters\n",
    "combine reference protein and rna sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/'\n",
    "files_pr = '''GCF_000184785.2_Aflo_1.0_protein.faa\n",
    "GCF_000469605.1_Apis_dorsata_1.3_protein.faa\n",
    "GCF_001313835.1_ASM131383v1_protein.faa\n",
    "GCF_001442555.1_ACSNU-2.0_protein.faa\n",
    "GCF_001465965.1_Pdom_r1.2_protein.faa\n",
    "GCF_003254395.2_Amel_HAv3.1_protein.faa\n",
    "uniprot_sprot.fasta\n",
    "'''.split()\n",
    "os.chdir(folder)\n",
    "\n",
    "file_pr = 'ref.proteins.faa'\n",
    "from Bio import SeqIO\n",
    "fout = open(file_pr,'w')\n",
    "for f in files_pr:\n",
    "    for s in SeqIO.parse(f,'fasta'):\n",
    "        if 'X' in str(s.seq):\n",
    "            continue\n",
    "        else:\n",
    "            fout.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "files_nt = '''GCF_000184785.2_Aflo_1.0_rna.fna\n",
    "GCF_000469605.1_Apis_dorsata_1.3_rna.fna\n",
    "GCF_001313835.1_ASM131383v1_rna.fna\n",
    "GCF_001442555.1_ACSNU-2.0_rna.fna\n",
    "GCF_001465965.1_Pdom_r1.2_rna.fna\n",
    "GCF_003254395.2_Amel_HAv3.1_rna.fna\n",
    "'''.split()\n",
    "file_nt = 'ref.rna.faa'\n",
    "fout = open(file_nt,'w')\n",
    "for f in files_nt:\n",
    "    for s in SeqIO.parse(f,'fasta'):\n",
    "        seq = str(s.seq)\n",
    "        seq = seq.upper()\n",
    "        if seq.count('A')+seq.count('T')+seq.count('C')+seq.count('G')+seq.count('*')+seq.count('N') == len(seq):\n",
    "            fout.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "        else:\n",
    "            print(s.id,'abnormal',s.seq)\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run maker2 for bee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do with the steps listed here `https://reslp.github.io/blog/My-MAKER-Pipeline/`\n",
    "IO is a limitation, run the work in /fastio/xc278/ then copy the data back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1: first round of maker2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "srun -N 1 --partition long --qos long-award   -t 240:00:00 --pty bash #allocate resource from Elf\n",
    "source activate /gpfs/gpfs/scratch/xc278/maker2 #activate environment\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/ # go to the working directory\n",
    "mkdir step1\n",
    "cd step1\n",
    "maker -CTL\n",
    "```\n",
    "\n",
    "modify the maker_opts.ctl file to \n",
    "```\n",
    "#-----Genome (these are always required)\n",
    "genome=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n",
    "\n",
    "#-----Re-annotation Using MAKER Derived GFF3\n",
    "maker_gff= #MAKER derived GFF3 file\n",
    "est_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\n",
    "altest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\n",
    "protein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\n",
    "rm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\n",
    "model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\n",
    "pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\n",
    "other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n",
    "\n",
    "#-----EST Evidence (for best results provide a file for at least one)\n",
    "est=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/GCF_000469605.1_Apis_dorsata_1.3_rna.fna #set of ESTs or assembled mRNA-seq in fasta format\n",
    "altest=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.rna.faa #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\n",
    "altest_gff= #aligned ESTs from a closly relate species in GFF3 format\n",
    "\n",
    "#-----Protein Homology Evidence (for best results provide a file for at least one)\n",
    "protein=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.proteins.faa  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "protein_gff=  #aligned protein homology evidence from an external GFF3 file\n",
    "\n",
    "#-----Repeat Masking (leave values blank to skip repeat masking)\n",
    "model_org=all #select a model organism for RepBase masking in RepeatMasker\n",
    "rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\n",
    "repeat_protein=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\n",
    "rm_gff= #pre-identified repeat elements from an external GFF3 file\n",
    "prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\n",
    "softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n",
    "\n",
    "#-----Gene Prediction\n",
    "snaphmm= #SNAP HMM file\n",
    "gmhmm= #GeneMark HMM file\n",
    "augustus_species= #Augustus gene prediction species model\n",
    "fgenesh_par_file= #FGENESH parameter file\n",
    "pred_gff= #ab-initio predictions from an external GFF3 file\n",
    "model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\n",
    "est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no\n",
    "trna=1 #find tRNAs with tRNAscan, 1 = yes, 0 = no\n",
    "snoscan_rrna= #rRNA file to have Snoscan find snoRNAs\n",
    "unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n",
    "\n",
    "#-----Other Annotation Feature Types (features MAKER doesn't recognize)\n",
    "other_gff= #extra features to pass-through to final MAKER generated GFF3 file\n",
    "\n",
    "#-----External Application Behavior Options\n",
    "alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\n",
    "cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n",
    "\n",
    "#-----MAKER Behavior Options\n",
    "max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\n",
    "min_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n",
    "\n",
    "pred_flank=200 #flank for extending evidence clusters sent to gene predictors\n",
    "pred_stats=0 #report AED and QI statistics for all predictions as well as models\n",
    "AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\n",
    "min_protein=0 #require at least this many amino acids in predicted proteins\n",
    "alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\n",
    "always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\n",
    "map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\n",
    "keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n",
    "\n",
    "split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\n",
    "single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\n",
    "single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\n",
    "correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n",
    "\n",
    "tries=2 #number of times to try a contig if there is a failure for some reason\n",
    "clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\n",
    "clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\n",
    "TMP= #specify a directory other than the system default temporary directory for temporary files\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Note, bee is Apis dorsata  \n",
    "Hornet is Vespa mandarinia  \n",
    "changed part:\n",
    "* genome=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "* est=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/GCF_000469605.1_Apis_dorsata_1.3_rna.fna #set of ESTs or assembled mRNA-seq in fasta format\n",
    "* altest=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.rna.faa #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "* protein=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.proteins.faa  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "* est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "* protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maker_exe.ctl\n",
    "```\n",
    "#-----Location of Executables Used by MAKER/EVALUATOR\n",
    "makeblastdb=/gpfs/gpfs/scratch/xc278/maker2/bin/makeblastdb #location of NCBI+ makeblastdb executable\n",
    "blastn=/gpfs/gpfs/scratch/xc278/maker2/bin/blastn #location of NCBI+ blastn executable\n",
    "blastx=/gpfs/gpfs/scratch/xc278/maker2/bin/blastx #location of NCBI+ blastx executable\n",
    "tblastx=/gpfs/gpfs/scratch/xc278/maker2/bin/tblastx #location of NCBI+ tblastx executable\n",
    "formatdb= #location of NCBI formatdb executable\n",
    "blastall= #location of NCBI blastall executable\n",
    "xdformat= #location of WUBLAST xdformat executable\n",
    "blasta= #location of WUBLAST blasta executable\n",
    "RepeatMasker=/gpfs/gpfs/scratch/xc278/maker2/bin/RepeatMasker #location of RepeatMasker executable\n",
    "exonerate=/gpfs/gpfs/scratch/xc278/maker2/bin/exonerate #location of exonerate executable\n",
    "\n",
    "#-----Ab-initio Gene Prediction Algorithms\n",
    "snap=/gpfs/gpfs/scratch/xc278/maker2/bin/snap #location of snap executable\n",
    "gmhmme3=/gpfs/gpfs/scratch/xc278/maker2/bin/gmhmme3 #location of eukaryotic genemark executable\n",
    "gmhmmp= #location of prokaryotic genemark executable\n",
    "augustus=/gpfs/gpfs/scratch/xc278/maker2/bin/augustus #location of augustus executable\n",
    "fgenesh= #location of fgenesh executable\n",
    "tRNAscan-SE=/gpfs/gpfs/scratch/xc278/maker2/bin/tRNAscan-SE #location of trnascan executable\n",
    "snoscan=/gpfs/gpfs/scratch/xc278/maker2/bin/snoscan #location of snoscan executable\n",
    "\n",
    "#-----Other Algorithms\n",
    "probuild=/gpfs/gpfs/scratch/xc278/p/gm_et_linux_64/gmes_petap/probuild #location of probuild executable (required for genemark)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the genome to pieces ~100kb and run maker2, generate small scripts to run together\n",
    "```python\n",
    "\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/' #folder of oringal maker\n",
    "threads = 24 # number of threads\n",
    "\n",
    "pre_cmd = 'source activate /gpfs/gpfs/scratch/xc278/maker2 ' # commond to run before each individual commands\n",
    "pyMultiple = '/home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py'\n",
    "\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "#get setting files\n",
    "file_maker_exe = os.path.join(folder,'maker_exe.ctl')\n",
    "file_maker_opts = os.path.join(folder, 'maker_opts.ctl')\n",
    "file_maker_bopts = os.path.join(folder,'maker_bopts.ctl')\n",
    "\n",
    "#generate workfolder\n",
    "workfolder = os.path.join(folder,'maker_split_run')\n",
    "if not os.path.exists(workfolder):\n",
    "    os.makedirs(workfolder)\n",
    "\n",
    "#get genome location\n",
    "for line in open(file_maker_opts):\n",
    "    if line.startswith('genome='):\n",
    "        break\n",
    "file_genome = line[7:].split('#')[0].strip()\n",
    "\n",
    "#split genome sequences to parts so that each parts contains is longer than 100kb\n",
    "#remove contigs shorter than 200bp\n",
    "seqfolder = os.path.join(workfolder,'seq')\n",
    "if not os.path.exists(seqfolder):\n",
    "    os.makedirs(seqfolder)\n",
    "\n",
    "n = 0\n",
    "l = 0\n",
    "outfolder = os.path.join(seqfolder,str(n))\n",
    "if not os.path.exists(outfolder):\n",
    "    os.makedirs(outfolder)\n",
    "outfile = open(os.path.join(outfolder,str(n)),'w')\n",
    "for s in SeqIO.parse(file_genome,'fasta'):\n",
    "    slen = len(s.seq)\n",
    "    if slen <=200:\n",
    "        continue\n",
    "    l += slen\n",
    "    outfile.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "    if l >= 100000:\n",
    "        outfile.close()\n",
    "        n += 1\n",
    "        l = 0\n",
    "        outfolder = os.path.join(seqfolder,str(n))\n",
    "        if not os.path.exists(outfolder):\n",
    "            os.makedirs(outfolder)\n",
    "        outfile = open(os.path.join(outfolder,str(n)),'w')\n",
    "outfile.close()\n",
    "\n",
    "#prepare to run maker for each part\n",
    "total_seg = n+1\n",
    "commands = os.path.join(workfolder,'cmds')\n",
    "fout = open(commands,'w')\n",
    "for n in range(total_seg):\n",
    "    for f in [file_maker_exe, file_maker_opts,file_maker_bopts]:\n",
    "        outfolder = os.path.join(seqfolder,str(n))\n",
    "        genome = os.path.join(outfolder,str(n))\n",
    "        os.system(f'cp {f} {outfolder}/')\n",
    "    fout.write(pre_cmd + '  &&  ' + f'cp -af {outfolder} /home/scratch/ && cd /home/scratch/{n} && maker -genome {genome} -cpus 1  && gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *all.gff {outfolder}/ && rm -rf /home/scratch/{n} \\n')\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the scripts manually in multiple nodes\n",
    "\n",
    "```bash\n",
    "ssh  -o \"ServerAliveInterval 60\" xc278@elf.rdi2.rutgers.edu\n",
    "srun -N 16 --partition long --qos long-award   -t 240:00:00 --pty bash #run twice to get 32 working nodes\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 36 -n e3c-262,e3c-263,e3c-264,e3c-265,e3c-266,e3c-267,e3c-268,e3c-269,e3c-270,e3c-271,e3c-272,e3c-273,e3c-274,e3c-275,e3c-276 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/maker_split_run/cmds &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine the result (discard. use python scripts below)\n",
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1\n",
    "for file in $(ls maker_split_run/seq/*/*.gff)\n",
    "do\n",
    "    cat $file >> step1.all.gff\n",
    "done\n",
    "\n",
    "```\n",
    "\n",
    "Note, to be compatible with the following step, use python to combine the result\n",
    "\n",
    "```python\n",
    "import glob\n",
    "files = glob.glob('/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/maker_split_run/seq/*/*.gff')\n",
    "outfile = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/step1.all.gff'\n",
    "\n",
    "ls_gff = []\n",
    "ls_fasta = []\n",
    "for f in files:\n",
    "    txt = open(f).read()\n",
    "    txt = txt.replace('##gff-version 3\\n','',1)\n",
    "    txt_gff, txt_fa = txt.split('##FASTA\\n')\n",
    "    ls_gff.append(txt_gff)\n",
    "    ls_fasta.append(txt_fa)\n",
    "\n",
    "fout = open(outfile,'w')\n",
    "fout.write('##gff-version 3\\n')\n",
    "fout.write(''.join(ls_gff))\n",
    "fout.write('##FASTA\\n')\n",
    "fout.write(''.join(ls_fasta))\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2 training SNAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1\n",
    "maker2zff step1.all.gff\n",
    "fathom genome.ann genome.dna -validate > snap_validate_output.txt\n",
    "cat snap_validate_output.txt | grep \"error\" #MODEL5240 with error, remove it\n",
    "grep -vwE \"MODEL5240\" genome.ann > genome.ann2\n",
    "cat genome.ann2 |grep \"MODEL5240\"\n",
    "cat genome.ann |grep \"MODEL5240\"\n",
    "fathom genome.ann2 genome.dna -validate\n",
    "fathom genome.ann genome.dna -categorize 1000\n",
    "fathom uni.ann uni.dna -export 1000 -plus \n",
    "forge export.ann export.dna\n",
    "hmm-assembler.pl my_genome . > my_genome.hmm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3 Run MAKER with the training results from Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following line in the maker_opts.ctl file:\n",
    "\n",
    "snaphmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/my_genome.hmm #SNAP HMM file\n",
    "\n",
    "To base the predictions in the second MAKER run only on SNAP remove the filepaths to the protein and est evidence or set the flags for est2genome=0 and protein2genome=0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3\n",
    "maker -CTL\n",
    "```\n",
    "\n",
    "change maker_opts.ctl to\n",
    "```\n",
    "#-----Genome (these are always required)\n",
    "genome=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n",
    "\n",
    "#-----Re-annotation Using MAKER Derived GFF3\n",
    "maker_gff= #MAKER derived GFF3 file\n",
    "est_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\n",
    "altest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\n",
    "protein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\n",
    "rm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\n",
    "model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\n",
    "pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\n",
    "other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n",
    "\n",
    "#-----EST Evidence (for best results provide a file for at least one)\n",
    "est=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/GCF_000469605.1_Apis_dorsata_1.3_rna.fna #set of ESTs or assembled mRNA-seq in fasta format\n",
    "altest=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.rna.faa #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\n",
    "altest_gff= #aligned ESTs from a closly relate species in GFF3 format\n",
    "\n",
    "#-----Protein Homology Evidence (for best results provide a file for at least one)\n",
    "protein=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.proteins.faa  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "protein_gff=  #aligned protein homology evidence from an external GFF3 file\n",
    "\n",
    "#-----Repeat Masking (leave values blank to skip repeat masking)\n",
    "model_org=all #select a model organism for RepBase masking in RepeatMasker\n",
    "rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\n",
    "repeat_protein=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\n",
    "rm_gff= #pre-identified repeat elements from an external GFF3 file\n",
    "prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\n",
    "softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n",
    "\n",
    "#-----Gene Prediction\n",
    "snaphmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/my_genome.hmm #SNAP HMM file\n",
    "gmhmm= #GeneMark HMM file\n",
    "augustus_species= #Augustus gene prediction species model\n",
    "fgenesh_par_file= #FGENESH parameter file\n",
    "pred_gff= #ab-initio predictions from an external GFF3 file\n",
    "model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\n",
    "est2genome=0 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "protein2genome=0 #infer predictions from protein homology, 1 = yes, 0 = no\n",
    "trna=1 #find tRNAs with tRNAscan, 1 = yes, 0 = no\n",
    "snoscan_rrna= #rRNA file to have Snoscan find snoRNAs\n",
    "unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n",
    "\n",
    "#-----Other Annotation Feature Types (features MAKER doesn't recognize)\n",
    "other_gff= #extra features to pass-through to final MAKER generated GFF3 file\n",
    "\n",
    "#-----External Application Behavior Options\n",
    "alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\n",
    "cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n",
    "\n",
    "#-----MAKER Behavior Options\n",
    "max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\n",
    "min_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n",
    "\n",
    "pred_flank=200 #flank for extending evidence clusters sent to gene predictors\n",
    "pred_stats=0 #report AED and QI statistics for all predictions as well as models\n",
    "AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\n",
    "min_protein=0 #require at least this many amino acids in predicted proteins\n",
    "alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\n",
    "always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\n",
    "map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\n",
    "keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n",
    "\n",
    "split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\n",
    "single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\n",
    "single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\n",
    "correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n",
    "\n",
    "tries=2 #number of times to try a contig if there is a failure for some reason\n",
    "clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\n",
    "clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\n",
    "TMP= #specify a directory other than the system default temporary directory for temporary files\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate scripts\n",
    "```python\n",
    "total_seg = 1940\n",
    "commands = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/cmds.txt'\n",
    "fout = open(commands,'w')\n",
    "for n in range(1940):\n",
    "    cmd = f'source activate /gpfs/gpfs/scratch/xc278/maker2 && cd /home/scratch && mkdir {n} && cd {n} && cp /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/maker*.ctl ./ && maker -genome /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/maker_split_run/seq/{n}/{n} -cpus 1 &&  gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *.gff /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/maker_split_run/ && rm -rf /home/scratch/{n} \\n'\n",
    "    fout.write(cmd)\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scripts\n",
    "```bash\n",
    "srun -N 16 --partition long --qos long-award   -t 240:00:00 --pty bash #run twice to get 32 working nodes\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 36 -n e3c-113,e3c-114,e3c-115,e3c-116,e3c-117,e3c-118,e3c-119,e3c-120,e3c-121,e3c-122,e3c-123,e3c-124,e3c-125,e3c-126,e3c-127,e3c-128,e3c-262,e3c-263,e3c-264,e3c-265,e3c-266,e3c-267,e3c-268,e3c-269,e3c-270,e3c-271,e3c-272,e3c-273,e3c-274,e3c-275,e3c-276,e3c-277 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/cmds.txt &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the caliburn HPC is not working normally. Some jobs died. Found the dead jobs and run them again with Elf\n",
    "\n",
    "```python\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/maker_split_run'\n",
    "cmds = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/cmds_missing.txt'\n",
    "\n",
    "import os\n",
    "finished = os.listdir(folder)\n",
    "#change output.all.gff to 0.all.gff\n",
    "finished = [0] + [int(e.split('.')[0]) for e in finished]\n",
    "missing = [e for e in range(1940) if e not in finished]\n",
    "\n",
    "fout = open(cmds,'w')\n",
    "for n in missing:\n",
    "    cmd = f'source activate /gpfs/gpfs/scratch/xc278/maker2 && cd /home/scratch && mkdir bee{n} && cd bee{n} && cp /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/maker*.ctl ./ && maker -genome /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/maker_split_run/seq/{n}/{n} -cpus 6 &&  gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *.gff /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/maker_split_run/ && rm -rf /home/scratch/bee{n} \\n'\n",
    "    fout.write(cmd)\n",
    "fout.close()\n",
    "```\n",
    "\n",
    "run the scripts\n",
    "```bash\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 16 -n e1c-051,e1c-052,e1c-053,e1c-054,e1c-055,e1c-056,e1c-057,e1c-058,e1c-059,e1c-060,e1c-061,e1c-062,e1c-063,e1c-064,e1c-065,e1c-066,e1c-109,e1c-110,e1c-111,e1c-112,e1c-113,e1c-114,e1c-115,e1c-116,e1c-117,e1c-118,e1c-119,e1c-120,e1c-121,e1c-122,e1c-123,e1c-124 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/cmds_missing.txt &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect data\n",
    "\n",
    "```python\n",
    "import glob\n",
    "files = glob.glob('/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/maker_split_run/*.gff')\n",
    "outfile = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/step3.all.gff'\n",
    "\n",
    "ls_gff = []\n",
    "ls_fasta = []\n",
    "for f in files:\n",
    "    txt = open(f).read()\n",
    "    txt = txt.replace('##gff-version 3\\n','',1)\n",
    "    txt_gff, txt_fa = txt.split('##FASTA\\n')\n",
    "    ls_gff.append(txt_gff)\n",
    "    ls_fasta.append(txt_fa)\n",
    "\n",
    "fout = open(outfile,'w')\n",
    "fout.write('##gff-version 3\\n')\n",
    "fout.write(''.join(ls_gff))\n",
    "fout.write('##FASTA\\n')\n",
    "fout.write(''.join(ls_fasta))\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step4 Train SNAP a second time with results from Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3\n",
    "maker2zff step3.all.gff\n",
    "fathom genome.ann genome.dna -validate > snap_validate_output.txt\n",
    "cat snap_validate_output.txt | grep \"error\" #MODEL1963 MODEL5311 with error, remove them\n",
    "\n",
    "grep -vwE \"MODEL1963\" genome.ann > genome.ann2\n",
    "grep -vwE \"MODEL5311\" genome.ann2 >genome.ann3\n",
    "fathom genome.ann3 genome.dna -validate\n",
    "fathom genome.ann3 genome.dna -categorize 1000\n",
    "fathom uni.ann uni.dna -export 1000 -plus \n",
    "forge export.ann export.dna\n",
    "hmm-assembler.pl my_genome . > my_genome.hmm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step6 train augustus\n",
    "download the zff2augustus_gbk.pl from `https://github.com/hyphaltip/genome-scripts/blob/master/gene_prediction/zff2augustus_gbk.pl`. install bioperl with `cpanm Bio::Perl`\n",
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3\n",
    "perl /gpfs/gpfs/scratch/xc278/maker2/bin/zff2augustus_gbk.pl > augustus.gbk\n",
    "randomSplit.pl augustus.gbk 100\n",
    "new_species.pl --species=bee20190616\n",
    "etraining --species=bee20190616 augustus.gbk.train\n",
    "augustus --species=bee20190616 augustus.gbk.test | tee first_training.out\n",
    "optimize_augustus.pl --species=bee20190616 augustus.gbk.train --cpus=34 --kfold=34\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 8 train geneMark\n",
    "\n",
    "```\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step8/\n",
    "\n",
    "#install required module if geneMark does not work\n",
    "source activate /gpfs/gpfs/scratch/xc278/maker2\n",
    "cpan install Logger::Simple\n",
    "cpan install YAML::XS\n",
    "export PERL5LIB=/gpfs/gpfs/scratch/xc278/maker2/lib/site_perl/5.26.2\n",
    "export PERL5LIB=/gpfs/gpfs/scratch/xc278/p/braker2/lib/site_perl/5.26.2\n",
    "\n",
    "/gpfs/gpfs/scratch/xc278/maker2/bin/perl -I /gpfs/gpfs/scratch/xc278/maker2/lib/site_perl/5.26.2 /gpfs/gpfs/scratch/xc278/p/gm_et_linux_64/gmes_petap/gmes_petap.pl --cores 36 --ES --sequence /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta\n",
    "```\n",
    "\n",
    "\n",
    "tried several hours. cannot get genemark work on caliburn. Tested on ALU and it works.\n",
    "install the required perl packages and genemark\n",
    "\n",
    "```bash\n",
    "cd /lab02/Data_Raw/Xiaolong/20190616CooperationBeeGenome/GeneMark\n",
    "export PERL5LIB=/home/xcao/p/anaconda3/lib/site_perl/5.26.2/\n",
    "#install the required software and perl libs.\n",
    "perl /home/xcao/p/gm_et_linux_64/gmes_petap/gmes_petap.pl --cores 48 --ES --sequence /lab02/Data_Raw/Xiaolong/20190616CooperationBeeGenome/Genome/hornetScaffolds.fasta\n",
    "#after finished, transfer the file to caliburn\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 9 final run\n",
    "\n",
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9\n",
    "maker -CTL\n",
    "```\n",
    "\n",
    "modifly the maker_opts.ctl to\n",
    "```\n",
    "#-----Genome (these are always required)\n",
    "genome=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n",
    "\n",
    "#-----Re-annotation Using MAKER Derived GFF3\n",
    "maker_gff=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/maker_split_run/GENOME_GFF.all.gff #MAKER derived GFF3 file\n",
    "est_pass=1 #use ESTs in maker_gff: 1 = yes, 0 = no\n",
    "altest_pass=1 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\n",
    "protein_pass=1 #use protein alignments in maker_gff: 1 = yes, 0 = no\n",
    "rm_pass=1 #use repeats in maker_gff: 1 = yes, 0 = no\n",
    "model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\n",
    "pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\n",
    "other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n",
    "\n",
    "#-----EST Evidence (for best results provide a file for at least one)\n",
    "est= #set of ESTs or assembled mRNA-seq in fasta format\n",
    "altest= #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\n",
    "altest_gff= #aligned ESTs from a closly relate species in GFF3 format\n",
    "\n",
    "#-----Protein Homology Evidence (for best results provide a file for at least one)\n",
    "protein=  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "protein_gff=  #aligned protein homology evidence from an external GFF3 file\n",
    "\n",
    "#-----Repeat Masking (leave values blank to skip repeat masking)\n",
    "model_org=all #select a model organism for RepBase masking in RepeatMasker\n",
    "rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\n",
    "repeat_protein= #provide a fasta file of transposable element proteins for RepeatRunner\n",
    "rm_gff= #pre-identified repeat elements from an external GFF3 file\n",
    "prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\n",
    "softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n",
    "\n",
    "#-----Gene Prediction\n",
    "snaphmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/my_genome.hmm #SNAP HMM file\n",
    "gmhmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step8/gmhmm.mod #GeneMark HMM file\n",
    "augustus_species=bee20190616 #Augustus gene prediction species model\n",
    "fgenesh_par_file= #FGENESH parameter file\n",
    "pred_gff= #ab-initio predictions from an external GFF3 file\n",
    "model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\n",
    "est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no\n",
    "trna=1 #find tRNAs with tRNAscan, 1 = yes, 0 = no\n",
    "snoscan_rrna= #rRNA file to have Snoscan find snoRNAs\n",
    "unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n",
    "\n",
    "#-----Other Annotation Feature Types (features MAKER doesn't recognize)\n",
    "other_gff= #extra features to pass-through to final MAKER generated GFF3 file\n",
    "\n",
    "#-----External Application Behavior Options\n",
    "alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\n",
    "cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n",
    "\n",
    "#-----MAKER Behavior Options\n",
    "max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\n",
    "min_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n",
    "\n",
    "pred_flank=200 #flank for extending evidence clusters sent to gene predictors\n",
    "pred_stats=1 #report AED and QI statistics for all predictions as well as models\n",
    "AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\n",
    "min_protein=0 #require at least this many amino acids in predicted proteins\n",
    "alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\n",
    "always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\n",
    "map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\n",
    "keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n",
    "\n",
    "split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\n",
    "single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\n",
    "single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\n",
    "correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n",
    "\n",
    "tries=2 #number of times to try a contig if there is a failure for some reason\n",
    "clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\n",
    "clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\n",
    "TMP= #specify a directory other than the system default temporary directory for temporary files\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate scripts\n",
    "```python\n",
    "total_seg = 1940\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/'\n",
    "commands = f'{folder}cmds.txt'\n",
    "fout = open(commands,'w')\n",
    "for n in range(total_seg):\n",
    "    genome_frag = f'/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/maker_split_run/{n}.all.gff'\n",
    "    cmd = f'''source activate /gpfs/gpfs/scratch/xc278/maker2 && cd /home/scratch && mkdir beebee{n} && cd beebee{n} && cp {folder}maker*.ctl ./ && sed  -i 's/GENOME_GFF/{n}/g' maker_opts.ctl && maker -genome /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step1/maker_split_run/seq/{n}/{n} -cpus 1 &&  gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *.gff {folder}maker_split_run/ && fasta_merge -d *.maker.output/*master_datastore_index.log && mv *.fasta {folder}/maker_result_seqs && rm -rf /home/scratch/beebee{n} \\n'''\n",
    "    fout.write(cmd)\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scripts\n",
    "```bash\n",
    "srun -N 16 --partition long --qos long-award   -t 240:00:00 --pty bash #run twice to get 32 working nodes\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 24 -n e1c-051,e1c-052,e1c-053,e1c-054,e1c-055,e1c-056,e1c-057,e1c-058,e1c-059,e1c-060,e1c-061,e1c-062,e1c-063,e1c-064,e1c-065,e1c-066,e1c-109,e1c-110,e1c-111,e1c-112,e1c-113,e1c-114,e1c-115,e1c-116,e1c-117,e1c-118,e1c-119,e1c-120,e1c-121,e1c-122,e1c-123,e1c-124 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/cmds.txt \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect data\n",
    "\n",
    "```python\n",
    "import glob\n",
    "files = glob.glob('/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/maker_split_run/*.gff')\n",
    "outfile = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/step9.all.gff'\n",
    "\n",
    "ls_gff = []\n",
    "ls_fasta = []\n",
    "for f in files:\n",
    "    txt = open(f).read()\n",
    "    txt = txt.replace('##gff-version 3\\n','',1)\n",
    "    txt_gff, txt_fa = txt.split('##FASTA\\n')\n",
    "    ls_gff.append(txt_gff)\n",
    "    ls_fasta.append(txt_fa)\n",
    "\n",
    "fout = open(outfile,'w')\n",
    "fout.write('##gff-version 3\\n')\n",
    "fout.write(''.join(ls_gff))\n",
    "fout.write('##FASTA\\n')\n",
    "fout.write(''.join(ls_fasta))\n",
    "fout.close()\n",
    "```\n",
    "\n",
    "collect protein and transcript sequence\n",
    "```python\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/'\n",
    "files_pr = glob.glob(f'{folder}maker_result_seqs/*.maker.proteins.fasta')\n",
    "files_dna = glob.glob(f'{folder}maker_result_seqs/*.maker.transcripts.fasta')\n",
    "outfile_pr = f'{folder}step9.maker.proteins.fasta'\n",
    "outfile_dna = f'{folder}step9.maker.transcripts.fasta'\n",
    "def combineFa(files,outfile):\n",
    "    '''\n",
    "    combine fasta files and write outfile\n",
    "    '''\n",
    "    fout = open(outfile,'w')\n",
    "    for f in files:\n",
    "        for s in SeqIO.parse(f,'fasta'):\n",
    "            fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "    fout.close()\n",
    "\n",
    "combineFa(files_pr, outfile_pr)\n",
    "combineFa(files_dna, outfile_dna)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run maker2 for hornet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1: first round of maker2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "srun -N 1 --partition long --qos long-award   -t 240:00:00 --pty bash #allocate resource from Elf\n",
    "source activate /gpfs/gpfs/scratch/xc278/maker2 #activate environment\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/ # go to the working directory\n",
    "mkdir step1\n",
    "cd step1\n",
    "maker -CTL\n",
    "```\n",
    "\n",
    "modify the maker_opts.ctl file to \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "#-----Genome (these are always required)\n",
    "genome=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/hornetScaffolds.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n",
    "\n",
    "#-----Re-annotation Using MAKER Derived GFF3\n",
    "maker_gff= #MAKER derived GFF3 file\n",
    "est_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\n",
    "altest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\n",
    "protein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\n",
    "rm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\n",
    "model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\n",
    "pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\n",
    "other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n",
    "\n",
    "#-----EST Evidence (for best results provide a file for at least one)\n",
    "est=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/Trinity/Vespa_mandarinia_SRR2664950_Trinity.fa #set of ESTs or assembled mRNA-seq in fasta format\n",
    "altest=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.rna.faa #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\n",
    "altest_gff= #aligned ESTs from a closly relate species in GFF3 format\n",
    "\n",
    "#-----Protein Homology Evidence (for best results provide a file for at least one)\n",
    "protein=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/ref.proteins.faa  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "protein_gff=  #aligned protein homology evidence from an external GFF3 file\n",
    "\n",
    "#-----Repeat Masking (leave values blank to skip repeat masking)\n",
    "model_org=all #select a model organism for RepBase masking in RepeatMasker\n",
    "rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\n",
    "repeat_protein=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/ref/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\n",
    "rm_gff= #pre-identified repeat elements from an external GFF3 file\n",
    "prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\n",
    "softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n",
    "\n",
    "#-----Gene Prediction\n",
    "snaphmm= #SNAP HMM file\n",
    "gmhmm= #GeneMark HMM file\n",
    "augustus_species= #Augustus gene prediction species model\n",
    "fgenesh_par_file= #FGENESH parameter file\n",
    "pred_gff= #ab-initio predictions from an external GFF3 file\n",
    "model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\n",
    "est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no\n",
    "trna=1 #find tRNAs with tRNAscan, 1 = yes, 0 = no\n",
    "snoscan_rrna= #rRNA file to have Snoscan find snoRNAs\n",
    "unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n",
    "\n",
    "#-----Other Annotation Feature Types (features MAKER doesn't recognize)\n",
    "other_gff= #extra features to pass-through to final MAKER generated GFF3 file\n",
    "\n",
    "#-----External Application Behavior Options\n",
    "alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\n",
    "cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n",
    "\n",
    "#-----MAKER Behavior Options\n",
    "max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\n",
    "min_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n",
    "\n",
    "pred_flank=200 #flank for extending evidence clusters sent to gene predictors\n",
    "pred_stats=0 #report AED and QI statistics for all predictions as well as models\n",
    "AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\n",
    "min_protein=0 #require at least this many amino acids in predicted proteins\n",
    "alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\n",
    "always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\n",
    "map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\n",
    "keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n",
    "\n",
    "split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\n",
    "single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\n",
    "single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\n",
    "correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n",
    "\n",
    "tries=2 #number of times to try a contig if there is a failure for some reason\n",
    "clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\n",
    "clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\n",
    "TMP= #specify a directory other than the system default temporary directory for temporary files\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the genome to pieces ~100kb\n",
    "```python\n",
    "file_genome = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/hornetScaffolds.fasta'\n",
    "\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "n = 0\n",
    "l = 0\n",
    "outfolder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/genome_split/'\n",
    "if not os.path.exists(outfolder):\n",
    "    os.makedirs(outfolder)\n",
    "outfile = open(os.path.join(outfolder,str(n)),'w')\n",
    "for s in SeqIO.parse(file_genome,'fasta'):\n",
    "    slen = len(s.seq)\n",
    "    if slen <=200:\n",
    "        continue\n",
    "    l += slen\n",
    "    outfile.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "    if l >= 100000:\n",
    "        outfile.close()\n",
    "        n += 1\n",
    "        l = 0\n",
    "        outfile = open(os.path.join(outfolder,str(n)),'w')\n",
    "outfile.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate scripts\n",
    "```python\n",
    "total_seg = 2213\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/'\n",
    "commands = f'{folder}cmds.txt'\n",
    "fout = open(commands,'w')\n",
    "for n in range(total_seg):\n",
    "    cmd = f'source activate /gpfs/gpfs/scratch/xc278/maker2 && cd /home/scratch && mkdir {n} && cd {n} && cp {folder}/maker*.ctl ./ && maker -genome /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/genome_split/{n} -cpus 4 &&  gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *.gff {folder}/maker_split_run/ && rm -rf /home/scratch/{n} \\n'\n",
    "    fout.write(cmd)\n",
    "fout.close()\n",
    "```\n",
    "\n",
    "Note: change cpus to 4, to speed up a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the scripts manually in multiple nodes. Run on elf\n",
    "\n",
    "```bash\n",
    "ssh  -o \"ServerAliveInterval 60\" xc278@elf.rdi2.rutgers.edu\n",
    "srun -N 16 --partition long --qos long-award   -t 240:00:00 --pty bash #run twice to get 32 working nodes\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 24 -n e1c-051,e1c-052,e1c-053,e1c-054,e1c-055,e1c-056,e1c-057,e1c-058,e1c-059,e1c-060,e1c-061,e1c-062,e1c-063,e1c-064,e1c-065,e1c-066,e1c-109,e1c-110,e1c-111,e1c-112,e1c-113,e1c-114,e1c-115,e1c-116,e1c-117,e1c-118,e1c-119,e1c-120,e1c-121,e1c-122,e1c-123,e1c-124 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/cmds.txt \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for some reason, the scripts stopped. find the unfinished fragements and re-run\n",
    "\n",
    "```python\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/maker_split_run'\n",
    "cmds = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/cmds_missing.txt'\n",
    "\n",
    "import os\n",
    "finished = os.listdir(folder)\n",
    "#change output.all.gff to 0.all.gff\n",
    "finished = [0] + [int(e.split('.')[0]) for e in finished]\n",
    "missing = [e for e in range(2213) if e not in finished]\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/'\n",
    "fout = open(cmds,'w')\n",
    "for n in missing:\n",
    "    cmd = f'source activate /gpfs/gpfs/scratch/xc278/maker2 && cd /home/scratch && mkdir {n} && cd {n} && cp {folder}/maker*.ctl ./ && maker -genome /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/genome_split/{n} -cpus 4 &&  gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *.gff {folder}/maker_split_run/ && rm -rf /home/scratch/{n} \\n'\n",
    "    fout.write(cmd)\n",
    "fout.close()\n",
    "\n",
    "```\n",
    "\n",
    "run scripts\n",
    "\n",
    "```bash\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 12 -n e1c-067,e1c-068,e1c-069,e1c-070,e1c-071,e1c-072,e1c-073,e1c-074,e1c-075,e1c-076,e1c-077,e1c-078,e1c-079,e1c-080,e1c-081,e1c-082 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/cmds_missing.txt &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, to be compatible with the following step, use python to combine the result\n",
    "\n",
    "```python\n",
    "import glob\n",
    "files = glob.glob('/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/maker_split_run/*.gff')\n",
    "outfile = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/step1.all.gff'\n",
    "\n",
    "ls_gff = []\n",
    "ls_fasta = []\n",
    "for f in files:\n",
    "    txt = open(f).read()\n",
    "    txt = txt.replace('##gff-version 3\\n','',1)\n",
    "    txt_gff, txt_fa = txt.split('##FASTA\\n')\n",
    "    ls_gff.append(txt_gff)\n",
    "    ls_fasta.append(txt_fa)\n",
    "\n",
    "fout = open(outfile,'w')\n",
    "fout.write('##gff-version 3\\n')\n",
    "fout.write(''.join(ls_gff))\n",
    "fout.write('##FASTA\\n')\n",
    "fout.write(''.join(ls_fasta))\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2 train SNAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1\n",
    "maker2zff step1.all.gff\n",
    "fathom genome.ann genome.dna -validate > snap_validate_output.txt\n",
    "cat snap_validate_output.txt | grep \"error\" #MODEL293 MODEL377 MODEL5879 with error, remove it\n",
    "cat genome.ann | grep -vwE \"MODEL293\" |grep -vwE \"MODEL377\" |grep -vwE \"MODEL5879\" > genome.ann2\n",
    "cat genome.ann2 |grep \"MODEL293\\|MODEL377\\|MODEL5879\"\n",
    "cat genome.ann |grep \"MODEL293\\|MODEL377\\|MODEL5879\"\n",
    "fathom genome.ann2 genome.dna -validate\n",
    "fathom genome.ann2 genome.dna -categorize 1000\n",
    "fathom uni.ann uni.dna -export 1000 -plus \n",
    "forge export.ann export.dna\n",
    "hmm-assembler.pl my_genome . > my_genome.hmm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3 Run MAKER with training results from Step2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following line in the maker_opts.ctl file:\n",
    "\n",
    "snaphmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/my_genome.hmm #SNAP HMM file\n",
    "\n",
    "To base the predictions in the second MAKER run only on SNAP remove the filepaths to the protein and est evidence or set the flags for est2genome=0 and protein2genome=0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3\n",
    "maker -CTL\n",
    "```\n",
    "\n",
    "change maker_opts.ctl to\n",
    "```\n",
    "#-----Genome (these are always required)\n",
    "genome=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/hornetScaffolds.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n",
    "\n",
    "#-----Re-annotation Using MAKER Derived GFF3\n",
    "maker_gff=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/maker_split_run/GENOME_GFF.all.gff #MAKER derived GFF3 file\n",
    "est_pass=1 #use ESTs in maker_gff: 1 = yes, 0 = no\n",
    "altest_pass=1 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\n",
    "protein_pass=1 #use protein alignments in maker_gff: 1 = yes, 0 = no\n",
    "rm_pass=1 #use repeats in maker_gff: 1 = yes, 0 = no\n",
    "model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\n",
    "pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\n",
    "other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n",
    "\n",
    "#-----EST Evidence (for best results provide a file for at least one)\n",
    "est= #set of ESTs or assembled mRNA-seq in fasta format\n",
    "altest= #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\n",
    "altest_gff= #aligned ESTs from a closly relate species in GFF3 format\n",
    "\n",
    "#-----Protein Homology Evidence (for best results provide a file for at least one)\n",
    "protein=  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "protein_gff=  #aligned protein homology evidence from an external GFF3 file\n",
    "\n",
    "#-----Repeat Masking (leave values blank to skip repeat masking)\n",
    "model_org=all #select a model organism for RepBase masking in RepeatMasker\n",
    "rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\n",
    "repeat_protein= #provide a fasta file of transposable element proteins for RepeatRunner\n",
    "rm_gff= #pre-identified repeat elements from an external GFF3 file\n",
    "prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\n",
    "softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n",
    "\n",
    "#-----Gene Prediction\n",
    "snaphmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/my_genome.hmm #SNAP HMM file #SNAP HMM file\n",
    "gmhmm= #GeneMark HMM file\n",
    "augustus_species= #Augustus gene prediction species model\n",
    "fgenesh_par_file= #FGENESH parameter file\n",
    "pred_gff= #ab-initio predictions from an external GFF3 file\n",
    "model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\n",
    "est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no\n",
    "trna=1 #find tRNAs with tRNAscan, 1 = yes, 0 = no\n",
    "snoscan_rrna= #rRNA file to have Snoscan find snoRNAs\n",
    "unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n",
    "\n",
    "#-----Other Annotation Feature Types (features MAKER doesn't recognize)\n",
    "other_gff= #extra features to pass-through to final MAKER generated GFF3 file\n",
    "\n",
    "#-----External Application Behavior Options\n",
    "alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\n",
    "cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n",
    "\n",
    "#-----MAKER Behavior Options\n",
    "max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\n",
    "min_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n",
    "\n",
    "pred_flank=200 #flank for extending evidence clusters sent to gene predictors\n",
    "pred_stats=0 #report AED and QI statistics for all predictions as well as models\n",
    "AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\n",
    "min_protein=0 #require at least this many amino acids in predicted proteins\n",
    "alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\n",
    "always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\n",
    "map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\n",
    "keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n",
    "\n",
    "split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\n",
    "single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\n",
    "single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\n",
    "correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n",
    "\n",
    "tries=2 #number of times to try a contig if there is a failure for some reason\n",
    "clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\n",
    "clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\n",
    "TMP= #specify a directory other than the system default temporary directory for temporary files\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate scripts\n",
    "```python\n",
    "total_seg = 2213\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/'\n",
    "commands = f'{folder}cmds.txt'\n",
    "fout = open(commands,'w')\n",
    "for n in range(total_seg):\n",
    "    genome_frag = f'/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step1/maker_split_run/{n}.all.gff'\n",
    "    cmd = f'''source activate /gpfs/gpfs/scratch/xc278/maker2 && cd /home/scratch && mkdir hornet{n} && cd hornet{n} && cp {folder}maker*.ctl ./ && sed  -i 's/GENOME_GFF/{n}/g' maker_opts.ctl && maker -genome /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/genome_split/{n} -cpus 1 &&  gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *.gff {folder}maker_split_run/ && fasta_merge -d *.maker.output/*master_datastore_index.log && mv *.fasta {folder}/maker_result_seqs && rm -rf /home/scratch/hornet{n} \\n'''\n",
    "    fout.write(cmd)\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scripts\n",
    "```bash\n",
    "srun -N 16 --partition long --qos long-award   -t 240:00:00 --pty bash #run twice to get 32 working nodes\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 24 -n e1c-051,e1c-052,e1c-053,e1c-054,e1c-055,e1c-056,e1c-057,e1c-058,e1c-059,e1c-060,e1c-061,e1c-062,e1c-063,e1c-064,e1c-065,e1c-066,e1c-109,e1c-110,e1c-111,e1c-112,e1c-113,e1c-114,e1c-115,e1c-116,e1c-117,e1c-118,e1c-119,e1c-120,e1c-121,e1c-122,e1c-123,e1c-124 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/cmds.txt \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect data\n",
    "\n",
    "```python\n",
    "import glob\n",
    "files = glob.glob('/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/maker_split_run/*.gff')\n",
    "outfile = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/step3.all.gff'\n",
    "\n",
    "ls_gff = []\n",
    "ls_fasta = []\n",
    "for f in files:\n",
    "    txt = open(f).read()\n",
    "    txt = txt.replace('##gff-version 3\\n','',1)\n",
    "    txt_gff, txt_fa = txt.split('##FASTA\\n')\n",
    "    ls_gff.append(txt_gff)\n",
    "    ls_fasta.append(txt_fa)\n",
    "\n",
    "fout = open(outfile,'w')\n",
    "fout.write('##gff-version 3\\n')\n",
    "fout.write(''.join(ls_gff))\n",
    "fout.write('##FASTA\\n')\n",
    "fout.write(''.join(ls_fasta))\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step4 Train SNAP a second time with results from Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3\n",
    "maker2zff step3.all.gff\n",
    "fathom genome.ann genome.dna -validate > snap_validate_output.txt\n",
    "cat snap_validate_output.txt | grep \"error\" #MODEL1963 MODEL6048 with error, remove them\n",
    "\n",
    "grep -vwE \"MODEL6048\" genome.ann > genome.ann2\n",
    "fathom genome.ann2 genome.dna -validate\n",
    "fathom genome.ann2 genome.dna -categorize 1000\n",
    "fathom uni.ann uni.dna -export 1000 -plus \n",
    "forge export.ann export.dna\n",
    "hmm-assembler.pl my_genome . > my_genome.hmm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step6 train augustus\n",
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3\n",
    "perl /gpfs/gpfs/scratch/xc278/maker2/bin/zff2augustus_gbk.pl > augustus.gbk\n",
    "randomSplit.pl augustus.gbk 100\n",
    "new_species.pl --species=hornet20190616\n",
    "etraining --species=hornet20190616 augustus.gbk.train\n",
    "augustus --species=hornet20190616 augustus.gbk.test | tee first_training.out\n",
    "optimize_augustus.pl --species=hornet20190616 augustus.gbk.train --cpus=36 --kfold=36\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 8 train GeneMark\n",
    "\n",
    "```bash\n",
    "/home/xcao/p/gm_et_linux_64/gmes_petap/gmes_petap.pl --cores 48 --ES --sequence /lab02/Data_Raw/Xiaolong/20190616C                            ooperationBeeGenome/Genome/hornetScaffolds.fasta\n",
    "```\n",
    "Then move file to caliburn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 9 final run\n",
    "\n",
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/\n",
    "cp /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/maker*.ctl ./\n",
    "mkdir maker_result_seqs\n",
    "mkdir maker_split_run\n",
    "```\n",
    "\n",
    "modifly the maker_opts.ctl to\n",
    "```\n",
    "#-----Genome (these are always required)\n",
    "genome=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/hornetScaffolds.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n",
    "\n",
    "#-----Re-annotation Using MAKER Derived GFF3\n",
    "maker_gff=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/maker_split_run/GENOME_GFF.all.gff #MAKER derived GFF3 file\n",
    "est_pass=1 #use ESTs in maker_gff: 1 = yes, 0 = no\n",
    "altest_pass=1 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\n",
    "protein_pass=1 #use protein alignments in maker_gff: 1 = yes, 0 = no\n",
    "rm_pass=1 #use repeats in maker_gff: 1 = yes, 0 = no\n",
    "model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\n",
    "pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\n",
    "other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n",
    "\n",
    "#-----EST Evidence (for best results provide a file for at least one)\n",
    "est= #set of ESTs or assembled mRNA-seq in fasta format\n",
    "altest= #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\n",
    "altest_gff= #aligned ESTs from a closly relate species in GFF3 format\n",
    "\n",
    "#-----Protein Homology Evidence (for best results provide a file for at least one)\n",
    "protein=  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "protein_gff=  #aligned protein homology evidence from an external GFF3 file\n",
    "\n",
    "#-----Repeat Masking (leave values blank to skip repeat masking)\n",
    "model_org=all #select a model organism for RepBase masking in RepeatMasker\n",
    "rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\n",
    "repeat_protein= #provide a fasta file of transposable element proteins for RepeatRunner\n",
    "rm_gff= #pre-identified repeat elements from an external GFF3 file\n",
    "prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\n",
    "softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n",
    "\n",
    "#-----Gene Prediction\n",
    "snaphmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/my_genome.hmm #SNAP HMM file #SNAP HMM file\n",
    "gmhmm=/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step8/gmhmm.mod #GeneMark HMM file\n",
    "augustus_species=hornet20190616 #Augustus gene prediction species model\n",
    "fgenesh_par_file= #FGENESH parameter file\n",
    "pred_gff= #ab-initio predictions from an external GFF3 file\n",
    "model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\n",
    "est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no\n",
    "trna=1 #find tRNAs with tRNAscan, 1 = yes, 0 = no\n",
    "snoscan_rrna= #rRNA file to have Snoscan find snoRNAs\n",
    "unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n",
    "\n",
    "#-----Other Annotation Feature Types (features MAKER doesn't recognize)\n",
    "other_gff= #extra features to pass-through to final MAKER generated GFF3 file\n",
    "\n",
    "#-----External Application Behavior Options\n",
    "alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\n",
    "cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n",
    "\n",
    "#-----MAKER Behavior Options\n",
    "max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\n",
    "min_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n",
    "\n",
    "pred_flank=200 #flank for extending evidence clusters sent to gene predictors\n",
    "pred_stats=0 #report AED and QI statistics for all predictions as well as models\n",
    "AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\n",
    "min_protein=0 #require at least this many amino acids in predicted proteins\n",
    "alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\n",
    "always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\n",
    "map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\n",
    "keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n",
    "\n",
    "split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\n",
    "single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\n",
    "single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\n",
    "correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n",
    "\n",
    "tries=2 #number of times to try a contig if there is a failure for some reason\n",
    "clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\n",
    "clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\n",
    "TMP= #specify a directory other than the system default temporary directory for temporary files\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate scripts\n",
    "```python\n",
    "total_seg = 2213\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/'\n",
    "commands = f'{folder}cmds.txt'\n",
    "fout = open(commands,'w')\n",
    "for n in range(total_seg):\n",
    "    cmd = f'''source activate /gpfs/gpfs/scratch/xc278/maker2 && cd /home/scratch && mkdir hornet{n} && cd hornet{n} && cp {folder}maker*.ctl ./ && sed  -i 's/GENOME_GFF/{n}/g' maker_opts.ctl && maker -genome /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/genome_split/{n} -cpus 4 &&  gff3_merge -d *.maker.output/*master_datastore_index.log &&  mv *.gff {folder}maker_split_run/ && fasta_merge -d *.maker.output/*master_datastore_index.log && mv *.fasta {folder}/maker_result_seqs && rm -rf /home/scratch/hornet{n} \\n'''\n",
    "    fout.write(cmd)\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scripts\n",
    "```bash\n",
    "srun -N 16 --partition long --qos long-award   -t 240:00:00 --pty bash #run twice to get 32 working nodes\n",
    "python /home1/xc278/w/GitHub/xiaolongTools/multiThreadSlurm.py -t 24 -n e1c-051,e1c-052,e1c-053,e1c-054,e1c-055,e1c-056,e1c-057,e1c-058,e1c-059,e1c-060,e1c-061,e1c-062,e1c-063,e1c-064,e1c-065,e1c-066,e1c-109,e1c-110,e1c-111,e1c-112,e1c-113,e1c-114,e1c-115,e1c-116,e1c-117,e1c-118,e1c-119,e1c-120,e1c-121,e1c-122,e1c-123,e1c-124 -s 60 -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/cmds.txt \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect data\n",
    "\n",
    "```python\n",
    "import glob\n",
    "files = glob.glob('/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/maker_split_run/*.gff')\n",
    "outfile = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/step9.all.gff'\n",
    "\n",
    "ls_gff = []\n",
    "ls_fasta = []\n",
    "for f in files:\n",
    "    txt = open(f).read()\n",
    "    txt = txt.replace('##gff-version 3\\n','',1)\n",
    "    txt_gff, txt_fa = txt.split('##FASTA\\n')\n",
    "    ls_gff.append(txt_gff)\n",
    "    ls_fasta.append(txt_fa)\n",
    "\n",
    "fout = open(outfile,'w')\n",
    "fout.write('##gff-version 3\\n')\n",
    "fout.write(''.join(ls_gff))\n",
    "fout.write('##FASTA\\n')\n",
    "fout.write(''.join(ls_fasta))\n",
    "fout.close()\n",
    "```\n",
    "\n",
    "collect protein and transcript sequence\n",
    "```python\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "folder = '/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/'\n",
    "files_pr = glob.glob(f'{folder}maker_result_seqs/*.maker.proteins.fasta')\n",
    "files_dna = glob.glob(f'{folder}maker_result_seqs/*.maker.transcripts.fasta')\n",
    "outfile_pr = f'{folder}step9.maker.proteins.fasta'\n",
    "outfile_dna = f'{folder}step9.maker.transcripts.fasta'\n",
    "def combineFa(files,outfile):\n",
    "    '''\n",
    "    combine fasta files and write outfile\n",
    "    '''\n",
    "    fout = open(outfile,'w')\n",
    "    for f in files:\n",
    "        for s in SeqIO.parse(f,'fasta'):\n",
    "            fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "    fout.close()\n",
    "\n",
    "combineFa(files_pr, outfile_pr)\n",
    "combineFa(files_dna, outfile_dna)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUSCO\n",
    "\n",
    "install BUSCO\n",
    "\n",
    "do the setting according to the manual\n",
    "\n",
    "download the data set `wget http://busco.ezlab.org/v2/datasets/insecta_odb9.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run BUSCO for genome\n",
    "\n",
    "```bash\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/BUSCO/\n",
    "python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -c 36 -m genome -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta -o 20190614beeGenome\n",
    "python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -c 36 -m genome -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/hornetScaffolds.fasta -o 20190614HornetGenome\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result:\n",
    "\n",
    "```\n",
    "# BUSCO version is: 3.1.0 \n",
    "# The lineage dataset is: insecta_odb9 (Creation date: 2016-02-13, number of species: 42, number of BUSCOs: 1658)\n",
    "# To reproduce this run: python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta -o 20190614beeGenome -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -m genome -c 36 -sp fly\n",
    "#\n",
    "# Summarized benchmarking in BUSCO notation for file /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/beeScaffolds.fasta\n",
    "# BUSCO was run in mode: genome\n",
    "\n",
    "\tC:98.9%[S:98.8%,D:0.1%],F:1.0%,M:0.1%,n:1658\n",
    "\n",
    "\t1639\tComplete BUSCOs (C)\n",
    "\t1638\tComplete and single-copy BUSCOs (S)\n",
    "\t1\tComplete and duplicated BUSCOs (D)\n",
    "\t16\tFragmented BUSCOs (F)\n",
    "\t3\tMissing BUSCOs (M)\n",
    "\t1658\tTotal BUSCO groups searched\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BUSCO version is: 3.1.0 \n",
    "# The lineage dataset is: insecta_odb9 (Creation date: 2016-02-13, number of species: 42, number of BUSCOs: 1658)\n",
    "# To reproduce this run: python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/hornetScaffolds.fasta -o 20190614HornetGenome -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -m genome -c 36 -sp fly\n",
    "#\n",
    "# Summarized benchmarking in BUSCO notation for file /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/genome/hornetScaffolds.fasta\n",
    "# BUSCO was run in mode: genome\n",
    "\n",
    "\tC:96.0%[S:95.0%,D:1.0%],F:3.0%,M:1.0%,n:1658\n",
    "\n",
    "\t1592\tComplete BUSCOs (C)\n",
    "\t1575\tComplete and single-copy BUSCOs (S)\n",
    "\t17\tComplete and duplicated BUSCOs (D)\n",
    "\t49\tFragmented BUSCOs (F)\n",
    "\t17\tMissing BUSCOs (M)\n",
    "\t1658\tTotal BUSCO groups searched\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run BUSCO for maker result\n",
    "\n",
    "cd /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/BUSCO/\n",
    "python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -c 36 -m prot -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/step9.maker.proteins.fasta -o 20190614beeMaker\n",
    "python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -c 36 -m prot -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/step9.maker.proteins.fasta -o 20190614HornetMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result:\n",
    "\n",
    "```\n",
    "# BUSCO version is: 3.1.0 \n",
    "# The lineage dataset is: insecta_odb9 (Creation date: 2016-02-13, number of species: 42, number of BUSCOs: 1658)\n",
    "# To reproduce this run: python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/step9.maker.proteins.fasta -o 20190614beeMaker -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -m proteins -c 36\n",
    "#\n",
    "# Summarized benchmarking in BUSCO notation for file /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/step9.maker.proteins.fasta\n",
    "# BUSCO was run in mode: proteins\n",
    "\n",
    "\tC:96.7%[S:96.6%,D:0.1%],F:1.1%,M:2.2%,n:1658\n",
    "\n",
    "\t1603\tComplete BUSCOs (C)\n",
    "\t1602\tComplete and single-copy BUSCOs (S)\n",
    "\t1\tComplete and duplicated BUSCOs (D)\n",
    "\t19\tFragmented BUSCOs (F)\n",
    "\t36\tMissing BUSCOs (M)\n",
    "\t1658\tTotal BUSCO groups searched\n",
    "\n",
    "\n",
    "# BUSCO version is: 3.1.0 \n",
    "# The lineage dataset is: insecta_odb9 (Creation date: 2016-02-13, number of species: 42, number of BUSCOs: 1658)\n",
    "# To reproduce this run: python /home1/xc278/p/BUSCO/busco-master/scripts/run_BUSCO.py -i /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/step9.maker.proteins.fasta -o 20190614HornetMaker -l /home1/xc278/p/BUSCO/insecta/insecta_odb9/ -m proteins -c 36\n",
    "#\n",
    "# Summarized benchmarking in BUSCO notation for file /gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/step9.maker.proteins.fasta\n",
    "# BUSCO was run in mode: proteins\n",
    "\n",
    "\tC:92.4%[S:90.7%,D:1.7%],F:2.9%,M:4.7%,n:1658\n",
    "\n",
    "\t1531\tComplete BUSCOs (C)\n",
    "\t1503\tComplete and single-copy BUSCOs (S)\n",
    "\t28\tComplete and duplicated BUSCOs (D)\n",
    "\t48\tFragmented BUSCOs (F)\n",
    "\t79\tMissing BUSCOs (M)\n",
    "\t1658\tTotal BUSCO groups searched\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the results to ALU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on ALU server\n",
    "```bash\n",
    "cd /lab02/Data_Raw/Xiaolong/20190616CooperationBeeGenome\n",
    "scp -r xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/BUSCO/ ./\n",
    "scp  xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/Trinity/Vespa_mandarinia_SRR2664950_Trinity.fa ./TrinityHornet/\n",
    "scp  xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step8/gmhmm.mod ./GeneMark/bee.gmhmm.mod\n",
    "scp  xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step8/gmhmm.mod ./GeneMark/hornet.gmhmm.mod\n",
    "scp  xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step3/my_genome.hmm ./snapHmm/bee.snap.gmhmm.mod\n",
    "scp  xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step3/my_genome.hmm ./snapHmm/hornet.snap.gmhmm.mod\n",
    "#augustus\n",
    "scp -r xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/scratch/xc278/maker2/config/species/bee20190616/ ./AugustusHmm/\n",
    "scp -r xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/scratch/xc278/maker2/config/species/hornet20190616/ ./AugustusHmm/\n",
    "\n",
    "#maker\n",
    "scp xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/step9.maker.proteins.fasta ./maker/20190617bee.maker.protein.fasta\n",
    "scp xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/step9.maker.transcripts.fasta ./maker/20190617bee.maker.transcripts.fasta\n",
    "scp xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/bee/step9/step9.all.gff ./maker/20190617bee.maker.gff\n",
    "\n",
    "scp xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/step9.maker.proteins.fasta ./maker/20190617hornet.maker.protein.fasta\n",
    "scp xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/step9.maker.transcripts.fasta ./maker/20190617hornet.maker.transcripts.fasta\n",
    "scp xc278@caliburn.rdi2.rutgers.edu:/gpfs/gpfs/staging/jx76-003/xc/20190613cooperationBeeGenomes/maker2/hornet/step9/step9.all.gff ./maker/20190617hornet.maker.gff\n",
    "\n",
    "cd maker/\n",
    "pigz -k -9 *\n",
    "\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
