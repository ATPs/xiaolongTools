{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hermeuptychia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate Wenlin's assembly 20181205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Jing's description and Wenlin's notes, the final assemblies for 3303 (Hermeuptychia sosybius) and 3318 (Hermeuptychia intricata) is stored in `/work0/wenlin/sequencing/3303_round2/7_platanus/3303_careful_ass0.3_t1_scaffold.fa`, `/home/xcao/w/20181205Hermeuptychia/20181205wenlin/3303newAll_scaffold.fa` and `/work0/wenlin/sequencing/3318_with_3312_round2/10_improve_assembly/3318_careful_ass0.3_t1_merged_t2_gapClosed_v1.fa`. Copy the file to `/home/xcao/w/20181205Hermeuptychia/20181205wenlin/`.  \n",
    "Evaluate the quality of the genomes with Quast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "/home/xcao/p/quast/quast-5.0.2/quast.py -t 32 --eukaryote --large --k-mer-stats --circos  --gene-finding --rna-finding --conserved-genes-finding --use-all-alignments /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3303_careful_ass0.3_t1_scaffold.fa /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3303newAll_scaffold.fa  /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3318_careful_ass0.3_t1_merged_t2_gapClosed_v1.fa -o /home/xcao/w/20181205Hermeuptychia/20181205evaluate_wenlin/ --no-gzip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare reads for 3303\n",
    "20181205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on job scripts `/work0/wenlin/sequencing/3303_round2/7_platanus/assemble.job`, 91 files were used as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get some information about the input fastq files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run fastqc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "files = open('/home/xcao/w/20181205Hermeuptychia/20181205Reads3303/wenlinInput/files.txt').read().split()\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181205Reads3303/wenlinInput/fastqc/'\n",
    "fastqc = '/home/xcao/p/fastqc/FastQC/fastqc'\n",
    "import os\n",
    "file_cmds = '/home/xcao/w/20181205Hermeuptychia/scripts/20181205_fastqc.cmds'\n",
    "open(file_cmds,'w').write('\\n'.join('{fastqc} {file} -o {outfolder} -t 1'.format(fastqc=fastqc,outfolder=outfolder,file=file) for file in files))\n",
    "os.system('python /home/xcao/p/xiaolongTools/multiThread.py 48 '+file_cmds)\n",
    "os.system('cd  '+outfolder+'&& unzip \"*.zip\"')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summarize result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import glob\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181205Reads3303/wenlinInput/fastqc/'\n",
    "file_fastqc_data = glob.glob(folder+'**/fastqc_data.txt',recursive=True)\n",
    "print(len(file_fastqc_data))\n",
    "\n",
    "import os\n",
    "import math\n",
    "def fastqc2readsinfo(filename):\n",
    "    l = open(filename).readlines()\n",
    "    sample_id_full = os.path.basename(os.path.dirname(filename))\n",
    "    sample_id = sample_id_full.split('_cor_')[0]\n",
    "    if '_R1_' in sample_id_full:\n",
    "        sample_reads_type = 'R1'\n",
    "    elif '_R2_' in sample_id_full:\n",
    "        sample_reads_type = 'R2'\n",
    "    else:\n",
    "        sample_reads_type = 'singleton'\n",
    "    if 'combMate' in sample_id_full:\n",
    "        sample_reads_type = 'combMate'+sample_reads_type\n",
    "    if 'pairedM' in sample_id_full:\n",
    "        sample_reads_type = 'pairedM'+sample_reads_type\n",
    "    reads_count = l[6].split()[2]\n",
    "    GC_percentage = int(l[9].split()[1])\n",
    "    n = 0\n",
    "    while n < len(l):\n",
    "        if '>>Sequence Length Distribution' in l[n]:\n",
    "            break\n",
    "        else:\n",
    "            n = n+1\n",
    "    n = n+2\n",
    "    reads_len_info = []\n",
    "    while n < len(l):\n",
    "        if l[n][0] != '>':\n",
    "            _reads_len_range, _reads_count = l[n].strip().split('\\t')\n",
    "            if '-' in _reads_len_range:\n",
    "                _rs,_re = _reads_len_range.split('-')\n",
    "                _rl = (float(_rs) + float(_re))/2\n",
    "            else:\n",
    "                _rl = float(_reads_len_range)\n",
    "            _reads_count = float(_reads_count)\n",
    "            reads_len_info.append([_rl,_reads_count])\n",
    "            n += 1\n",
    "        else:\n",
    "            break\n",
    "    reads_count = sum(e[1] for e in reads_len_info)\n",
    "    reads_len_mean = sum(e[0]*e[1] for e in reads_len_info)/reads_count\n",
    "    reads_len_sd = math.sqrt(sum(number*number*count for number, count in reads_len_info) / reads_count - reads_len_mean * reads_len_mean)\n",
    "    #print('total reads', reads_count,'reads length mean', reads_len_mean, 'reads length sd', reads_len_sd, GC_percentage)\n",
    "    return sample_id, sample_reads_type, reads_count, reads_len_mean, reads_len_sd, GC_percentage,sample_id_full\n",
    "\n",
    "import pandas as pd\n",
    "df_fastqc = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "for f in file_fastqc_data:\n",
    "    sample_id, sample_reads_type, reads_count, reads_len_mean, reads_len_sd, GC_percentage,sample_id_full= fastqc2readsinfo(f)\n",
    "    df_fastqc.loc[sample_id,'reads_count_'+sample_reads_type] = reads_count\n",
    "    df_fastqc.loc[sample_id,'GC_percentage_'+sample_reads_type] = GC_percentage\n",
    "    df_fastqc.loc[sample_id,'reads_len_mean_'+sample_reads_type] = reads_len_mean\n",
    "    df_fastqc.loc[sample_id,'reads_len_sd_'+sample_reads_type] = reads_len_sd\n",
    "    df2.loc[sample_id_full, 'sample_id'] = sample_id\n",
    "    df2.loc[sample_id_full, 'sample_reads_type'] = sample_reads_type\n",
    "    df2.loc[sample_id_full, 'reads_count'] = reads_count\n",
    "    df2.loc[sample_id_full, 'GC_percentage'] = GC_percentage\n",
    "    df2.loc[sample_id_full, 'reads_len_mean'] = reads_len_mean\n",
    "    df2.loc[sample_id_full, 'reads_len_sd'] = reads_len_sd\n",
    "    \n",
    "print(df_fastqc.shape)\n",
    "df_fastqc.head()\n",
    "\n",
    "df_fastqc.to_excel('/home/xcao/w/20181205Hermeuptychia/20181205Reads3303/wenlinInput/3303fasta_qc.xlsx')\n",
    "df2.to_excel('/home/xcao/w/20181205Hermeuptychia/20181205Reads3303/wenlinInput/3303fasta_qcList.xlsx')\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test SPAdes with 3303\n",
    "20181205  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on previous experience with bacteria genome, SPAdes works pretty well: correcting errors in reads, merge assemblies of different kmer length. The eukaryote genome might be too huge for it, but still want to test it.  \n",
    "It seems the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run Qian's pipeline to Assemble 3303\n",
    "20181208  \n",
    "Understanding the pipelines.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get files that belongs to 3303\n",
    "\n",
    "there are two batches of data, one is used by Qian, the second batch in in Wenlin's folder.  \n",
    "Separate the files to 3 types: file_pairEnd, file_singleEnd, file_MatePair. \n",
    "\n",
    "Store the locations of these files in `/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/`\n",
    "\n",
    "Since the files have duplicated names, create softlinks to them by renaming them with the folder name +filename\n",
    "Store in `/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/raw`\n",
    "\n",
    "```\n",
    "import os\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/raw/'\n",
    "file_locs = '''/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/file_MatePair\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/file_PairEnd\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/file_SingleEnd\n",
    "'''.split()\n",
    "files = []\n",
    "for f in file_locs:\n",
    "    files += open(f).read().split()\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    foldername = os.path.dirname(file)\n",
    "    foldername = os.path.basename(foldername)\n",
    "    outname = foldername + basename\n",
    "    commandline = 'ln -s {f} {outfolder}{outname}'.format(f=file,outfolder=outfolder, outname=outname)\n",
    "    os.system(commandline)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after this step, the content in these files were changed to those soft link path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repair one file\n",
    "file cannot parse fastqc. Some lines contain errors. remove three lines.\n",
    "```\n",
    "filename = '/export/home11/congqian/satyrs/denovo/3303/2_filter/3303ac_single.fq'\n",
    "from Bio import SeqIO\n",
    "fo = open(filename)\n",
    "n=0\n",
    "line = fo.readline()\n",
    "while line:\n",
    "    if n%4 == 0:\n",
    "        if line[0] != '@':\n",
    "            print(line)\n",
    "            break\n",
    "    n += 1\n",
    "    line = fo.readline()\n",
    "\n",
    "filename = '/export/home11/congqian/satyrs/denovo/3303/2_filter/3303ac_single.fq'\n",
    "fout = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/raw/2_filter3303ac_single.fq'\n",
    "fout = open(fout,'w')\n",
    "remove_lines = [62028608,62028609,62028610]\n",
    "for n, line in enumerate(open(filename)):\n",
    "    if n in remove_lines:\n",
    "        print(n, line)\n",
    "    else:\n",
    "        fout.write(line)\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run fastqc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os,glob\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/raw/'\n",
    "files = glob.glob(folder+'*')\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/fastqc/'\n",
    "fastqc = '/home/xcao/p/fastqc/FastQC/fastqc'\n",
    "file_cmds = '/home/xcao/w/20181205Hermeuptychia/scripts/20181205_fastqc.cmds'\n",
    "open(file_cmds,'w').write('\\n'.join('{fastqc} {file} -o {outfolder} -t 1'.format(fastqc=fastqc,outfolder=outfolder,file=file) for file in files))\n",
    "os.system('python /home/xcao/p/xiaolongTools/multiThread.py 32 '+file_cmds)\n",
    "os.system('cd  '+outfolder+'&& unzip \"*.zip\"')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summarize fastqc result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import glob\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/fastqc/'\n",
    "file_fastqc_data = glob.glob(folder+'**/fastqc_data.txt',recursive=True)\n",
    "print(len(file_fastqc_data))\n",
    "\n",
    "import os\n",
    "import math\n",
    "def fastqc2readsinfo(filename):\n",
    "    l = open(filename).readlines()\n",
    "    sample_id_full = os.path.basename(os.path.dirname(filename))\n",
    "    sample_id = sample_id_full.split('_cor_')[0]\n",
    "    if '_R1_' in sample_id_full:\n",
    "        sample_reads_type = 'R1'\n",
    "    elif '_R2_' in sample_id_full:\n",
    "        sample_reads_type = 'R2'\n",
    "    else:\n",
    "        sample_reads_type = 'singleton'\n",
    "    if 'combMate' in sample_id_full:\n",
    "        sample_reads_type = 'combMate'+sample_reads_type\n",
    "    if 'pairedM' in sample_id_full:\n",
    "        sample_reads_type = 'pairedM'+sample_reads_type\n",
    "    reads_count = l[6].split()[2]\n",
    "    GC_percentage = int(l[9].split()[1])\n",
    "    n = 0\n",
    "    while n < len(l):\n",
    "        if '>>Sequence Length Distribution' in l[n]:\n",
    "            break\n",
    "        else:\n",
    "            n = n+1\n",
    "    n = n+2\n",
    "    reads_len_info = []\n",
    "    while n < len(l):\n",
    "        if l[n][0] != '>':\n",
    "            _reads_len_range, _reads_count = l[n].strip().split('\\t')\n",
    "            if '-' in _reads_len_range:\n",
    "                _rs,_re = _reads_len_range.split('-')\n",
    "                _rl = (float(_rs) + float(_re))/2\n",
    "            else:\n",
    "                _rl = float(_reads_len_range)\n",
    "            _reads_count = float(_reads_count)\n",
    "            reads_len_info.append([_rl,_reads_count])\n",
    "            n += 1\n",
    "        else:\n",
    "            break\n",
    "    reads_count = sum(e[1] for e in reads_len_info)\n",
    "    reads_len_mean = sum(e[0]*e[1] for e in reads_len_info)/reads_count\n",
    "    reads_len_sd = math.sqrt(sum(number*number*count for number, count in reads_len_info) / reads_count - reads_len_mean * reads_len_mean)\n",
    "    #print('total reads', reads_count,'reads length mean', reads_len_mean, 'reads length sd', reads_len_sd, GC_percentage)\n",
    "    return sample_id, sample_reads_type, reads_count, reads_len_mean, reads_len_sd, GC_percentage,sample_id_full\n",
    "\n",
    "import pandas as pd\n",
    "df_fastqc = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "for f in file_fastqc_data:\n",
    "    sample_id, sample_reads_type, reads_count, reads_len_mean, reads_len_sd, GC_percentage,sample_id_full= fastqc2readsinfo(f)\n",
    "    df_fastqc.loc[sample_id,'reads_count_'+sample_reads_type] = reads_count\n",
    "    df_fastqc.loc[sample_id,'GC_percentage_'+sample_reads_type] = GC_percentage\n",
    "    df_fastqc.loc[sample_id,'reads_len_mean_'+sample_reads_type] = reads_len_mean\n",
    "    df_fastqc.loc[sample_id,'reads_len_sd_'+sample_reads_type] = reads_len_sd\n",
    "    df2.loc[sample_id_full, 'sample_id'] = sample_id\n",
    "    df2.loc[sample_id_full, 'sample_reads_type'] = sample_reads_type\n",
    "    df2.loc[sample_id_full, 'reads_count'] = reads_count\n",
    "    df2.loc[sample_id_full, 'GC_percentage'] = GC_percentage\n",
    "    df2.loc[sample_id_full, 'reads_len_mean'] = reads_len_mean\n",
    "    df2.loc[sample_id_full, 'reads_len_sd'] = reads_len_sd\n",
    "\n",
    "print(df_fastqc.shape)\n",
    "df_fastqc.head()\n",
    "\n",
    "df2.to_excel('/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/3303_ori_fasta_qcList.xlsx')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delox mate pair reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/file_MatePair'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/3_delox/'\n",
    "files = open(filename).read().split()\n",
    "dc_pairs = {}\n",
    "import os\n",
    "delox = '/home/xcao/p/xiaolongTools/utils/seq/run_delox.py'\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    foldername = os.path.dirname(file)\n",
    "    foldername = os.path.basename(foldername)\n",
    "    key = foldername+basename.split('_R')[0]\n",
    "    if key not in dc_pairs:\n",
    "        dc_pairs[key] = []\n",
    "    dc_pairs[key].append(file)\n",
    "for k,v in dc_pairs.items():\n",
    "    commondline = 'python {delox} -f {read1} -r {read2} -p {outfolder}{prefix}'.format(delox=delox, read1 = v[0], read2=v[1],outfolder=outfolder, prefix=k)\n",
    "    os.system(commondline)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trim reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "commandline_pair = '''java -jar /home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/trinity-plugins/Trimmomatic-0.36/trimmomatic-0.36.jar PE -phred33 {input_forward} {input_reverse} {output_forward_paired} {output_forward_unpaired} {output_reverse_paired} {output_reverse_unpaired} ILLUMINACLIP:/home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/trinity-plugins/Trimmomatic-0.36/adapters/all.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 -threads 4 -trimlog {trimlog}'''\n",
    "\n",
    "commandline_single = '''java -jar /home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/trinity-plugins/Trimmomatic-0.36/trimmomatic-0.36.jar SE -phred33 {file_input} {file_output} ILLUMINACLIP:/home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/trinity-plugins/Trimmomatic-0.36/adapters/all.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 -threads 4 -trimlog {trimlog}'''\n",
    "\n",
    "import os\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/raw/'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/'\n",
    "folder_delox = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/3_delox/'\n",
    "file_locs = '''/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/file_MatePair\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/file_PairEnd\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/2_filter/file_SingleEnd\n",
    "'''.split()\n",
    "\n",
    "commandlines = []\n",
    "file_singleEnd = '2_filter3303 2_filter3303ac'.split()\n",
    "for f in file_singleEnd:\n",
    "    file_input = os.path.join(folder, f+'_single.fq')\n",
    "    file_output = os.path.join(outfolder,f+'_single.Trim.fq')\n",
    "    trimlog = os.path.join(outfolder,f+'.trimlog')\n",
    "    commandline = commandline_single.format(file_input=file_input, file_output=file_output, trimlog=trimlog)\n",
    "    commandlines.append(commandline)\n",
    "\n",
    "file_pairEnd = '2_filter3303_250b 2_filter3303_250s 2_filter3303lp_250 2_filter3303lp_250b 2_filter3303pb_250 2_filter3303_500s 2_filter3303lp_500 2_filter3303pb_500'.split()\n",
    "\n",
    "for f in file_pairEnd:\n",
    "    input_forward = os.path.join(folder,f+'_R1.fq')\n",
    "    input_reverse = os.path.join(folder,f+'_R2.fq')\n",
    "    output_forward_paired = os.path.join(outfolder,f+'_R1.TrimP.fq')\n",
    "    output_forward_unpaired = os.path.join(outfolder,f+'_R1.TrimS.fq')\n",
    "    output_reverse_paired = os.path.join(outfolder,f+'_R2.TrimP.fq')\n",
    "    output_reverse_unpaired = os.path.join(outfolder,f+'_R2.TrimS.fq')\n",
    "    trimlog = os.path.join(outfolder,f+'.trimlog')\n",
    "    commandline = commandline_pair.format(input_forward=input_forward, input_reverse=input_reverse, output_forward_paired=output_forward_paired, output_forward_unpaired=output_forward_unpaired, output_reverse_paired=output_reverse_paired, output_reverse_unpaired=output_reverse_unpaired, trimlog=trimlog)\n",
    "    commandlines.append(commandline)\n",
    "\n",
    "import glob\n",
    "files = glob.glob(folder_delox+'*')\n",
    "dc_key2pair = {}\n",
    "for f in files:\n",
    "    basename = os.path.basename(f)\n",
    "    if basename.endswith('.single.fastq'):\n",
    "        file_input = f\n",
    "        file_output = os.path.join(outfolder, basename+'.Trim.fq')\n",
    "        trimlog = os.path.join(outfolder,basename+'.trimlog')\n",
    "        commandline = commandline_single.format(file_input=file_input, file_output=file_output, trimlog=trimlog)\n",
    "        commandlines.append(commandline)\n",
    "    else:\n",
    "        key = basename.split('_read')[0]\n",
    "        if 'matepaired' in basename:\n",
    "            key = key+'matepaired'\n",
    "            if key not in dc_key2pair:\n",
    "                dc_key2pair[key] = []\n",
    "            dc_key2pair[key].append(f)\n",
    "        else:\n",
    "            key = key+'paired'\n",
    "            if key not in dc_key2pair:\n",
    "                dc_key2pair[key] = []\n",
    "            dc_key2pair[key].append(f)\n",
    "\n",
    "for key, values in dc_key2pair.items():\n",
    "    input_forward = values[0]\n",
    "    input_reverse = values[1]\n",
    "    output_forward_paired = os.path.join(outfolder,key+'_R1.TrimP.fq')\n",
    "    output_forward_unpaired = os.path.join(outfolder,key+'_R1.TrimS.fq')\n",
    "    output_reverse_paired = os.path.join(outfolder,key+'_R2.TrimP.fq')\n",
    "    output_reverse_unpaired = os.path.join(outfolder,key+'_R2.TrimS.fq')\n",
    "    trimlog = os.path.join(outfolder,key+'.trimlog')\n",
    "    commandline = commandline_pair.format(input_forward=input_forward, input_reverse=input_reverse, output_forward_paired=output_forward_paired, output_forward_unpaired=output_forward_unpaired, output_reverse_paired=output_reverse_paired, output_reverse_unpaired=output_reverse_unpaired, trimlog=trimlog)\n",
    "    commandlines.append(commandline)\n",
    "\n",
    "file_cmds = '/home/xcao/w/20181205Hermeuptychia/scripts/20181210_Trimmomatics.cmds'\n",
    "open(file_cmds,'w').write('\\n'.join(commandlines))\n",
    "#os.system('python /home/xcao/p/xiaolongTools/multiThread.py 8 '+file_cmds)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine reads and run SPAdes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "import glob\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/'\n",
    "files = glob.glob(folder+'*.fq')\n",
    "print(len(files))\n",
    "\n",
    "files_single = [e for e in files if 'single' in e or 'TrimS' in e]\n",
    "files_mate = [e for e in files if 'matepaired' in e and 'TrimP' in e]\n",
    "files_pair = [e for e in files if 'TrimP' in e and e not in files_mate]\n",
    "\n",
    "outfile = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/single.fq'\n",
    "command = ' '.join(['cat'] + files_single) + '>' + outfile\n",
    "print(command)\n",
    "#os.system(command)\n",
    "files_single2 = [outfile]\n",
    "\n",
    "files_pair2 = [e for e in files_pair if 'paired' not in e]\n",
    "files_pair_frommate = [e for e in files_pair if 'paired' in e]\n",
    "files_pair_frommate.sort()\n",
    "outfile = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/paired_from_mate_R1.fq'\n",
    "command = ' '.join(['cat'] + [e for e in files_pair_frommate if '_R1' in e]) + '>' + outfile\n",
    "files_pair2.append(outfile)\n",
    "print(command)\n",
    "#os.system(command)\n",
    "outfile = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/paired_from_mate_R2.fq'\n",
    "command = ' '.join(['cat'] + [e for e in files_pair_frommate if '_R2' in e]) + '>' + outfile\n",
    "print(command)\n",
    "#os.system(command)\n",
    "files_pair2.append(outfile)\n",
    "\n",
    "matelen = [e+'K' for e in '2 6 8 3 14 15 20'.split()]\n",
    "files_mate2 = []\n",
    "for e in matelen:\n",
    "    matelen_files = [i for i in files_mate if e in i]\n",
    "    matelen_files.sort()\n",
    "    print(e, len(matelen_files))\n",
    "    outfile = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate'+e+'_R1.fq'\n",
    "    files_mate2.append(outfile)\n",
    "    command = ' '.join(['cat'] + [e for e in matelen_files if '_R1' in e]) + '>' + outfile\n",
    "    #os.system(command)\n",
    "    outfile = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate'+e+'_R2.fq'\n",
    "    files_mate2.append(outfile)\n",
    "    command = ' '.join(['cat'] + [e for e in matelen_files if '_R2' in e]) + '>' + outfile\n",
    "    #os.system(command)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "dc_mate = defaultdict(list)\n",
    "dc_pair = defaultdict(list)\n",
    "for e in files_mate2:\n",
    "    key = e.replace('_R1','').replace('_R2','')\n",
    "    dc_mate[key].append(e)\n",
    "for e in files_pair2:\n",
    "    key = e.replace('_R1','').replace('_R2','')\n",
    "    dc_pair[key].append(e)\n",
    "\n",
    "commands = ['python /home/xcao/p/SPAdes/SPAdes-3.13.0-Linux/bin/spades.py -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/ -t 32 -m 5200 ']\n",
    "for n, e in enumerate(files_single2):\n",
    "    command = '--s{n} {file}'.format(n=n+1, file=e)\n",
    "    commands.append(command)\n",
    "for n, e in enumerate(dc_mate.values()):\n",
    "    command = '--mp{n}-1 {f1} --mp{n}-2 {f2}'.format(n=n+1,f1=e[0],f2=e[1])\n",
    "    commands.append(command)\n",
    "for n, e in enumerate(dc_pair.values()):\n",
    "    command = '--pe{n}-1 {f1} --pe{n}-2 {f2}'.format(n=n+1,f1=e[0],f2=e[1])\n",
    "    commands.append(command)\n",
    "print(' '.join(commands))\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/files.tab','w')\n",
    "for e in files_single2:\n",
    "    fout.write(os.path.basename(e)+'\\t'+e+'\\n')\n",
    "for k, e in dc_mate.items():\n",
    "    fout.write(os.path.basename(k)+'\\t'+','.join(e)+'\\n')\n",
    "for k,e in dc_pair.items():\n",
    "    fout.write(os.path.basename(k)+'\\t'+','.join(e)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### improve genome with redundance for 3303\n",
    "20181213\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should have use only mate pairs\n",
    "```\n",
    "/home/xcao/p/anaconda2/bin/python2 /home/xcao/p/redundans/redundans-master/redundans.py -t 32 -m 240 --iters 2 --usebwa -o /home/xcao/w/20181205Hermeuptychia/20181212redundans/3303 -f /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3303_careful_ass0.3_t1_contig.fa -i /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate2K_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate2K_R2.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate6K_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate6K_R2.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate8K_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate8K_R2.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate3K_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate3K_R2.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate14K_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate14K_R2.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate15K_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate15K_R2.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate20K_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/mate20K_R2.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303_500s_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303_500s_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303lp_500_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303lp_500_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303_250b_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303_250b_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303_250s_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303_250s_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303pb_250_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303pb_250_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303lp_250_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303lp_250_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303pb_500_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303pb_500_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303lp_250b_R1.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4_trim/2_filter3303lp_250b_R2.TrimP.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/paired_from_mate_R1.fq  /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/paired_from_mate_R2.fq\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAdes run failed. De novo assembly with redundance for 3303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nohup /home/xcao/p/anaconda2/bin/python2 /home/xcao/p/redundans/redundans-master/redundans.py -t 32 -m 690 --iters 4 --tmp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/tmp/ --usebwa -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/6_redundans  -i /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250b_R_unpaired.00.9_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250b_R1.TrimP.00.9_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250b_R2.TrimP.00.9_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250s_R_unpaired.00.10_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250s_R1.TrimP.00.10_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250s_R2.TrimP.00.10_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_500s_R_unpaired.00.7_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_500s_R1.TrimP.00.7_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_500s_R2.TrimP.00.7_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250_R_unpaired.00.12_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250_R1.TrimP.00.12_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250_R2.TrimP.00.12_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250b_R_unpaired.00.14_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250b_R1.TrimP.00.14_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250b_R2.TrimP.00.14_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_500_R_unpaired.00.8_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_500_R1.TrimP.00.8_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_500_R2.TrimP.00.8_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_250_R_unpaired.00.11_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_250_R1.TrimP.00.11_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_250_R2.TrimP.00.11_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_500_R_unpaired.00.13_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_500_R1.TrimP.00.13_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_500_R2.TrimP.00.13_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate2K_R_unpaired.00.0_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate2K_R1.00.0_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate2K_R2.00.0_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate3K_R_unpaired.00.3_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate3K_R1.00.3_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate3K_R2.00.3_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate6K_R_unpaired.00.1_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate6K_R1.00.1_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate6K_R2.00.1_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate8K_R_unpaired.00.2_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate8K_R1.00.2_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate8K_R2.00.2_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate14K_R_unpaired.00.4_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate14K_R1.00.4_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate14K_R2.00.4_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate15K_R_unpaired.00.5_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate15K_R1.00.5_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate15K_R2.00.5_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate20K_R_unpaired.00.6_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate20K_R1.00.6_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate20K_R2.00.6_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/paired_from_mate_R_unpaired.00.15_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/paired_from_mate_R1.00.15_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/paired_from_mate_R2.00.15_0.cor.fastq.gz \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/single.00.16_0.cor.fastq.gz >/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/6_redundans.logs &\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### de novo assembly with platanus\n",
    "20181213 de novo assembly with redundance failed. Try to run Plantunus directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nohup /home/xcao/p/redundans/redundans-master/bin/platanus assemble -t 32 -tmp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/tmp/ -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/6_platanus/ -m 768 -u 0.3 -a 5 -d 0.3 -f /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250b_R_unpaired.00.9_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250b_R1.TrimP.00.9_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250b_R2.TrimP.00.9_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250s_R_unpaired.00.10_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250s_R1.TrimP.00.10_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_250s_R2.TrimP.00.10_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_500s_R_unpaired.00.7_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_500s_R1.TrimP.00.7_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303_500s_R2.TrimP.00.7_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250_R_unpaired.00.12_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250_R1.TrimP.00.12_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250_R2.TrimP.00.12_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250b_R_unpaired.00.14_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250b_R1.TrimP.00.14_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_250b_R2.TrimP.00.14_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_500_R_unpaired.00.8_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_500_R1.TrimP.00.8_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303lp_500_R2.TrimP.00.8_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_250_R_unpaired.00.11_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_250_R1.TrimP.00.11_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_250_R2.TrimP.00.11_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_500_R_unpaired.00.13_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_500_R1.TrimP.00.13_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/2_filter3303pb_500_R2.TrimP.00.13_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate2K_R_unpaired.00.0_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate2K_R1.00.0_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate2K_R2.00.0_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate3K_R_unpaired.00.3_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate3K_R1.00.3_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate3K_R2.00.3_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate6K_R_unpaired.00.1_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate6K_R1.00.1_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate6K_R2.00.1_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate8K_R_unpaired.00.2_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate8K_R1.00.2_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate8K_R2.00.2_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate14K_R_unpaired.00.4_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate14K_R1.00.4_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate14K_R2.00.4_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate15K_R_unpaired.00.5_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate15K_R1.00.5_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate15K_R2.00.5_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate20K_R_unpaired.00.6_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate20K_R1.00.6_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/mate20K_R2.00.6_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/paired_from_mate_R_unpaired.00.15_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/paired_from_mate_R1.00.15_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/paired_from_mate_R2.00.15_0.cor.fastq \\\n",
    "/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/single.00.16_0.cor.fastq >/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/6_platanus.logs &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run Qian's pipeline for Assemble 3318\n",
    "20181213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### improve genome with redundans for 3318 of wenlin\n",
    "```\n",
    "nohup /home/xcao/p/anaconda2/bin/python2 /home/xcao/p/redundans/redundans-master/redundans.py -t 32 -m 240 --iters 2 --tmp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/tmp/ --usebwa -o /home/xcao/w/20181205Hermeuptychia/20181212redundans/3318 -f /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3318_careful_ass0.3_t1_contig.fa -i /work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_3KM_cor_R1.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_3KM_cor_R2.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_6KM_merged_R1.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_6KM_merged_R2.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_8KM_merged_R1.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_8KM_merged_R2.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_14KM_merged_R1.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_14KM_merged_R2.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_15KM_merged_R1.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_15KM_merged_R2.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_20KM_merged_R1.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318_20KM_merged_R2.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318ac_2KM_cor_R1.fastq \\\n",
    "/work0/wenlin/sequencing/3318_with_3312_round2/7.1_fastq_merged4scaffolding/3318ac_2KM_cor_R2.fastq >/home/xcao/w/20181205Hermeuptychia/20181212redundans/3318.log &\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quast check the difference\n",
    "20181214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "/home/xcao/p/quast/quast-5.0.2/quast.py -t 32 --eukaryote --large --k-mer-stats --circos  --conserved-genes-finding /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3318_careful_ass0.3_t1_contig.fa /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3318_careful_ass0.3_t1_merged_t2_gapClosed_v1.fa /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3318_redundans.scaffold.fa  -o /home/xcao/w/20181205Hermeuptychia/20181205evaluate_wenlin/20181214Improved3318 --no-gzip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems that Wenlin's result is better, based on N50\n",
    "```\n",
    "1  3318_careful_ass0.3_t1_contig, N50 = 5041, L50 = 22965, Total length = 343332627, GC % = undefined, # N's per 100 kbp =  0.00\n",
    "    2  3318_careful_ass0.3_t1_merged_t2_gapClosed_v1, N50 = 304870, L50 = 811, Total length = 922282021, GC % = undefined, # N's per 100 kbp =  7396.64\n",
    "    3  3318_redundans.scaffold, N50 = 13277, L50 = 15667, Total length = 713010486, GC % = undefined, # N's per 100 kbp =  2783.77\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run Trinity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trinity doesn't run well\n",
    "`Thursday, December 13, 2018: 02:13:11\tCMD: cat 3352_RNA_R2.fq.PwU.qtrim.fq | seqtk-trinity seq -A - >> right.fa\n",
    "Error, not recognizing read name formatting: [DJDP2NM1:317:HKMT5ADXX:2:1101:1237:2193]`\n",
    "\n",
    "correct read names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/'\n",
    "files_left = '''/alea/home11/congqian/satyrs/RNAseq/3072_RNA_R1.fq /alea/home11/congqian/satyrs/RNAseq/3305_RNA_R1.fq /alea/home11/congqian/satyrs/RNAseq/3320_RNA_R1.fq /alea/home11/congqian/satyrs/RNAseq/3352_RNA_R1.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/3305_R1.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/3320_R1.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/3352_R1.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/4003_R1.fq'''.split()\n",
    "files_right = '''/alea/home11/congqian/satyrs/RNAseq/3072_RNA_R2.fq /alea/home11/congqian/satyrs/RNAseq/3305_RNA_R2.fq /alea/home11/congqian/satyrs/RNAseq/3320_RNA_R2.fq /alea/home11/congqian/satyrs/RNAseq/3352_RNA_R2.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/3305_R2.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/3320_R2.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/3352_R2.fq /alea/local/Qian_biohpc_backup/project/96_RNA/step2_fix/4003_R2.fq'''.split()\n",
    "\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def correctName(f,addon='/1'):\n",
    "    outfile = os.path.join(outfolder,os.path.basename(f))\n",
    "    fout = open(outfile,'w')\n",
    "    for n,l in enumerate(open(f)):\n",
    "        if n%4 == 0:\n",
    "            fout.write(l.replace(' ','_').replace('\\n',addon+'\\n'))\n",
    "        else:\n",
    "            fout.write(l)\n",
    "    fout.close()\n",
    "\n",
    "\n",
    "pool = Pool(16)\n",
    "commands = [[e,'/1'] for e in files_left] + [[e,'/2'] for e in files_right]\n",
    "pool.starmap(correctName,commands)\n",
    "pool.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nohup /home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/Trinity  --seqType fq  --max_memory 240G --CPU 32 --trimmomatic --no_normalize_reads --output /home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity/ \\\n",
    "    --left /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3072_RNA_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_RNA_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_RNA_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_RNA_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/4003_R1.fq \\\n",
    "    --right /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3072_RNA_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_RNA_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_RNA_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_RNA_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/4003_R2.fq \\\n",
    "    >/home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity/trinity.log &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correct trinity errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change `/home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/util/support_scripts/../../Trinity --single \"/home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity/read_partitions/Fb_0/CBin_0/c4.trinity.reads.fa\" --output \"/home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity/read_partitions/Fb_0/CBin_0/c4.trinity.reads.fa.out\" --CPU 1 --max_memory 1G --run_as_paired --seqType fa --trinity_complete --full_cleanup /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_RNA_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_RNA_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_RNA_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/4003_R1.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_RNA_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_RNA_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_RNA_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3305_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3320_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/3352_R2.fq /home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/4003_R2.fq` to `/home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/util/support_scripts/../../Trinity --single \"/home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity/read_partitions/Fb_0/CBin_0/c4.trinity.reads.fa\" --output \"/home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity/read_partitions/Fb_0/CBin_0/c4.trinity.reads.fa.out\" --CPU 1 --max_memory 1G --run_as_paired --seqType fa --trinity_complete --full_cleanup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "filein = '/home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity/recursive_trinity.cmds'\n",
    "os.rename(filein, filein+'.backup')\n",
    "fout = open(filein,'w')\n",
    "for line in open(filein+'.backup'):\n",
    "    fout.write(line.split('--full_cleanup')[0]+' --full_cleanup\\n')\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run Trinity, genome guided 3303\n",
    "20181214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nohup /home/xcao/p/trinity/trinityrnaseq-Trinity-v2.8.4/Trinity   --max_memory 240G --CPU 32  --no_normalize_reads --output /home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity_3303GenomeGuided/ --genome_guided_bam /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/merged.bam --genome_guided_max_intron 100000 >/home/xcao/w/20181205Hermeuptychia/20181212Annotation/Trinity_3303GenomeGuided/trinity.log &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  step 7 align reads to wenlin's 3303\n",
    "20181213  \n",
    "/home/xcao/w/20181205Hermeuptychia/20181205wenlin/3303_careful_ass0.3_t1_scaffold.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter and keep scaffolds longer than 200bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "filein = '/home/xcao/w/20181205Hermeuptychia/20181205wenlin/3303_careful_ass0.3_t1_scaffold.fa'\n",
    "fileout = '/home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa'\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "total_scaffold = 0\n",
    "keep_scaffold = 0\n",
    "fout = open(fileout,'w')\n",
    "for s in SeqIO.parse(filein,'fasta'):\n",
    "    total_scaffold += 1\n",
    "    if len(s.seq)>=200:\n",
    "        fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "        keep_scaffold += 1\n",
    "fout.close()\n",
    "print(total_scaffold,'scaffolds before. After filtering:', keep_scaffold)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bwa index\n",
    "```\n",
    "bwa index /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### align reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scripts for generate SPAdes command line. we got dc_single, dc_pair and dc_mate. Generate bwa running scripts based on that. save a file with like\n",
    "`ID seq1,seq2`\n",
    "```\n",
    "import os\n",
    "\n",
    "commandline = '/home/xcao/p/bin/bwa mem -t 48 /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa {filein} >{fileout}.sam && /home/xcao/p/bin/samtools sort -@48 -o {fileout} {fileout}.sam  && rm {fileout}.sam '\n",
    "qsub = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "'''\n",
    "\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/'\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.bam')\n",
    "    filein = v.replace(',',' ')\n",
    "    c = commandline.format(filein=filein, fileout=fileout)\n",
    "    commandlines.append(c)\n",
    "    open(os.path.join(outfolder,'cmds/qsub_'+k),'w').write(qsub+c)\n",
    "f.close()\n",
    "#open(os.path.join(outfolder,'commands'),'w').write('\\n'.join(commandlines))\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303_250b.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303_250s.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303_500s.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303lp_250.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303lp_250b.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303lp_500.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303pb_250.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_2_filter3303pb_500.TrimP.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_mate2K.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_mate3K.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_mate6K.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_mate8K.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_mate14K.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_mate15K.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_mate20K.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_paired_from_mate.fq\n",
    "qsub -pe mpi 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/cmds/qsub_single.fq\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jing's scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index fasta file\n",
    "```\n",
    "samtools faidx /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "samtools faidx /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa\n",
    "java -jar /home/xcao/p/picard/picard2.18.20.jar CreateSequenceDictionary R=/home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads\n",
    "samtools merge merged.tmp.bam 2_filter3303_250b.TrimP.fq.bam 2_filter3303_250s.TrimP.fq.bam 2_filter3303_500s.TrimP.fq.bam 2_filter3303lp_250.TrimP.fq.bam 2_filter3303lp_250b.TrimP.fq.bam 2_filter3303lp_500.TrimP.fq.bam 2_filter3303pb_250.TrimP.fq.bam 2_filter3303pb_500.TrimP.fq.bam mate2K.fq.bam mate3K.fq.bam mate6K.fq.bam mate8K.fq.bam mate14K.fq.bam mate15K.fq.bam mate20K.fq.bam paired_from_mate.fq.bam single.fq.bam\n",
    "samtools sort merged.tmp.bam -o merged.bam\n",
    "rm merged.tmp.bam\n",
    "java -Djava.io.tmpdir=merged_tmp -jar /home/xcao/p/picard/picard2.18.20.jar MarkDuplicates INPUT=merged.bam OUTPUT=merged_dedup.bam METRICS_FILE=merged.metrics.txt >& merged.markdup.log\n",
    "java -Djava.io.tmpdir=merged_tmp -jar /home/xcao/p/picard/picard2.18.20.jar  AddOrReplaceReadGroups  INPUT=merged_dedup.bam  OUTPUT=merged_addrg.bam SORT_ORDER=coordinate RGID=group1 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=merged CREATE_INDEX=True >& merged.add_readgroup.log\n",
    "java -Djava.io.tmpdir=merged_tmp -jar /home/xcao/p/picard/picard2.18.20.jar  BuildBamIndex INPUT=merged_addrg.bam >& merged.index.log\n",
    "nohup java -Djava.io.tmpdir=merged_tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T RealignerTargetCreator -R /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -I merged_addrg.bam -o merged_realignment_targets.list >& merged_prepare_realign.log &\n",
    "nohup java -Djava.io.tmpdir=merged_tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T IndelRealigner  -R /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -I  merged_addrg.bam -targetIntervals merged_realignment_targets.list -o  merged_realigned.bam >& 1185.realign.log &&\\\n",
    "nohup java -Djava.io.tmpdir=merged_tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T  UnifiedGenotyper -nct 32 -R /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa  -stand_call_conf 30  -I merged_realigned.bam -o merged_snp.vcf --heterozygosity 0.02 --indel_heterozygosity 0.0025 --output_mode EMIT_ALL_SITES >& merged.snp.log &\n",
    "rm -rf merged_tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run for 3318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181205wenlin/3318_careful_ass0.3_t1_merged_t2_gapClosed_v1.fa ./3318_genome.fa\n",
    "bwa index 3318_genome.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "filein = '/home/xcao/w/20181205Hermeuptychia/20181205wenlin/3318_careful_ass0.3_t1_merged_t2_gapClosed_v1.fa'\n",
    "fileout = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/3318_genome.fa'\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "total_scaffold = 0\n",
    "keep_scaffold = 0\n",
    "fout = open(fileout,'w')\n",
    "for s in SeqIO.parse(filein,'fasta'):\n",
    "    total_scaffold += 1\n",
    "    if len(s.seq)>=200:\n",
    "        fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "        keep_scaffold += 1\n",
    "fout.close()\n",
    "print(total_scaffold,'scaffolds before. After filtering:', keep_scaffold)\n",
    "\n",
    "#conclusion: all scaffolds for 3318 longer than 200bp\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "genome_ref = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/3318_genome.fa'\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/'\n",
    "\n",
    "commandline = 'cd {outfolder} && /home/xcao/p/bin/bwa mem -t 48 {genome_ref} {filein} >{fileout}.sam && /home/xcao/p/bin/samtools sort -@48 -o {fileout} {fileout}.sam  && rm {fileout}.sam '\n",
    "qsub = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "'''\n",
    "\n",
    "\n",
    "if not os.path.exists(outfolder+'cmds'):\n",
    "    os.makedirs(outfolder+'cmds')\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.bam')\n",
    "    filein = v.replace(',',' ')\n",
    "    c = commandline.format(filein=filein, fileout=fileout, outfolder=outfolder, genome_ref=genome_ref)\n",
    "    commandlines.append(c)\n",
    "    print(c)\n",
    "    open(os.path.join(outfolder,'cmds/qsub_'+k),'w').write(qsub+c)\n",
    "f.close()\n",
    "open(os.path.join(outfolder,'commands'),'w').write('\\n'.join(commandlines))\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads\n",
    "samtools merge merged.tmp.bam 2KM.bam 3KM.bam 6KM.bam 8KM.bam 14KM.bam 15KM.bam 20KM.bam 200bp.bam 250bp.bam 500bp.bam\n",
    "samtools sort merged.tmp.bam -o merged.bam\n",
    "rm merged.tmp.bam\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 8 improve assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some codes\n",
    "```\n",
    "import os\n",
    "\n",
    "commandline = '/home/xcao/p/bin/bwa mem -t 48 /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa {filein} >{fileout}.sam && /home/xcao/p/bin/samtools sort -@48 -o {fileout} {fileout}.sam  && rm {fileout}.sam '\n",
    "qsub = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "'''\n",
    "\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/'\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.bam')\n",
    "    filein = v.replace(',',' ')\n",
    "    c = commandline.format(filein=filein, fileout=fileout)\n",
    "    commandlines.append(c)\n",
    "    open(os.path.join(outfolder,'cmds/qsub_'+k),'w').write(qsub+c)\n",
    "f.close()\n",
    "\n",
    "commandline = '''/home/xcao/p/bin/samtools merge -@ 48 {outfolder}merged.tmp.bam {outfolder}*.bam\n",
    "/home/xcao/p/bin/samtools sort -@ 48 {outfolder}merged.tmp.bam -o {outfolder}merged.bam\n",
    "rm {outfolder}merged.tmp.bam\n",
    "\n",
    "java -Djava.io.tmpdir={outfolder}merged_tmp -jar /home/xcao/p/picard/picard2.18.20.jar MarkDuplicates INPUT={outfolder}merged.bam OUTPUT={outfolder}merged_dedup.bam METRICS_FILE={outfolder}merged.metrics.txt >& {outfolder}merged.markdup.log\n",
    "java -Djava.io.tmpdir={outfolder}merged_tmp -jar /home/xcao/p/picard/picard2.18.20.jar  AddOrReplaceReadGroups  INPUT={outfolder}merged_dedup.bam  OUTPUT={outfolder}merged_addrg.bam SORT_ORDER=coordinate RGID=group1 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM={outfolder}merged CREATE_INDEX=True >& {outfolder}merged.add_readgroup.log\n",
    "java -Djava.io.tmpdir={outfolder}merged_tmp -jar /home/xcao/p/picard/picard2.18.20.jar  BuildBamIndex INPUT={outfolder}merged_addrg.bam >& {outfolder}merged.index.log\n",
    "\n",
    "java -Djava.io.tmpdir={outfolder}merged_tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T RealignerTargetCreator -R /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -I {outfolder}merged_addrg.bam -o {outfolder}merged_realignment_targets.list >& {outfolder}merged_prepare_realign.log\n",
    "java -Djava.io.tmpdir={outfolder}merged_tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T IndelRealigner -R /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -I  {outfolder}merged_addrg.bam -targetIntervals {outfolder}merged_realignment_targets.list -o  {outfolder}merged_realigned.bam >& {outfolder}merged.realign.log\n",
    "java -Djava.io.tmpdir={outfolder}merged_tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -nct 32 -R /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -T  UnifiedGenotyper -stand_call_conf 30 -stand_emit_conf 10 -I {outfolder}merged_realigned.bam -o {outfolder}merged_snp.vcf --heterozygosity 0.02 --indel_heterozygosity 0.0025 --output_mode EMIT_ALL_SITES >& {outfolder}merged.snp.log\n",
    "rm -rf {outfolder}merged_tmp\n",
    "'''.format(outfolder=outfolder)\n",
    "print(commandline)\n",
    "\n",
    "import glob\n",
    "import os\n",
    "files = glob.glob('/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/5_SPAdes/corrected/*.gz')\n",
    "for f in files:\n",
    "    print('pigz -d -p 32 ',f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get reads count per scaffold\n",
    "```\n",
    "source activate bio\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/\n",
    "cp /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa ./\n",
    "samtools index ../7_align_reads/merged.bam\n",
    "samtools idxstats ../7_align_reads/merged.bam >merged.idxstats\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get coverage and plot to select depth min\n",
    "set depth min to 30\n",
    "```\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_coverage_histogram.py -g /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa  -r /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.idxstats\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run blast to compare the genome with itself\n",
    "```\n",
    "makeblastdb -in wenlin3303min200.fa -input_type fasta -dbtype nucl -parse_seqid\n",
    "blastn -query wenlin3303min200.fa -db wenlin3303min200.fa -out all.blast2 -outfmt '6 qseqid sseqid pident evalue qlen qstart qend slen sstart send' -num_threads 48 -word_size 36 -evalue 0.0000000001\n",
    "```\n",
    "\n",
    "It is slow to run in single node. split to 14 parts\n",
    "```\n",
    "python /home/xcao/p/xiaolongTools/utils/seq/splitFasta2Nparts.py -s /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200.fa -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/blast/seq -N 14\n",
    "```\n",
    "\n",
    "run blast\n",
    "```\n",
    "workfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/'\n",
    "txt = '''source activate bio && cd {workfolder} &&blastn -query ./blast/seq{n} -db wenlin3303min200.fa -out ./blast/seq{n}.blast -outfmt '6 qseqid sseqid pident evalue qlen qstart qend slen sstart send' -num_threads 48 -word_size 36 -evalue 0.0000000001 &'''\n",
    "fout = open(workfolder+'blast.cmds','w')\n",
    "fout.write('\\n'.join([txt.format(workfolder=workfolder, n=n) for n in range(14)]))\n",
    "fout.close()\n",
    "```\n",
    "combine\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/ && cat ./blast/*.blast >all.blast &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter the genome\n",
    "```\n",
    "file_genome=\"/home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa\"\n",
    "file_stats=\"/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.stats\"\n",
    "file_blast = \"/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/all.blast\"\n",
    "depth_min=100\n",
    "outfile=\"/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa\"\n",
    "identity_min = 90\n",
    "\n",
    " python /home/xcao/p/xiaolongTools/utils/annotation/improve_scaffold_threads.py -i /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -s /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.stats -b /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/all.blast -d 100 -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa -m 90 -t 32\n",
    " \n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/improve_scaffold_threads.py -i /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -s /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.stats -b /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/all.blast -d 120 -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter2.fa -m 85 -t 32 & \n",
    "\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/improve_scaffold_threads.py -i /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa -s /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.stats -b /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/all.blast -d 100 -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter3.fa -m 95 -t 32 -M 500 & \n",
    "\n",
    "#get depth hist\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_coverage_histogram.py -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa  -r /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.idxstats -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.filter\n",
    "\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_coverage_histogram.py -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa  -r /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.idxstats -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.filter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get depth for each base\n",
    "```\n",
    "samtools depth -a /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/merged.bam >/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/9_identify_repeats_by_coverage/merged.depth &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run for 3318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get reads count per scaffold\n",
    "```\n",
    "source activate bio\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/\n",
    "ln -s ../7_align_reads/3318_genome.fa ./\n",
    "samtools index ../7_align_reads/merged.bam\n",
    "samtools idxstats ../7_align_reads/merged.bam >merged.idxstats\n",
    "```\n",
    "get coverage and plot to select depth min\n",
    "```\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_coverage_histogram.py -g 3318_genome.fa  -r merged.idxstats\n",
    "```\n",
    "run blast to compare the genome with itself\n",
    "```\n",
    "makeblastdb -in 3318_genome.fa -input_type fasta -dbtype nucl \n",
    "blastn -query 3318_genome.fa -db 3318_genome.fa -out all.blast -outfmt '6 qseqid sseqid pident evalue qlen qstart qend slen sstart send' -num_threads 48 -word_size 36 -evalue 0.0000000001 &\n",
    "```\n",
    "\n",
    "\n",
    "split to 14 parts\n",
    "```\n",
    "python /home/xcao/p/xiaolongTools/utils/seq/splitFasta2Nparts.py -s /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genome.fa -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/blast/seq -N 14\n",
    "```\n",
    "\n",
    "run blast\n",
    "```\n",
    "workfolder = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/'\n",
    "txt = '''source activate bio && cd {workfolder} &&blastn -query ./blast/seq{n} -db 3318_genome.fa -out ./blast/seq{n}.blast -outfmt '6 qseqid sseqid pident evalue qlen qstart qend slen sstart send' -num_threads 48 -word_size 36 -evalue 0.0000000001 &'''\n",
    "fout = open(workfolder+'blast.cmds','w')\n",
    "fout.write('\\n'.join([txt.format(workfolder=workfolder, n=n) for n in range(14)]))\n",
    "fout.close()\n",
    "```\n",
    "combine\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/ && cat ./blast/*.blast >all.blast &\n",
    "```\n",
    "\n",
    "get depth for each base\n",
    "```\n",
    "samtools depth -a /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/merged.bam >/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318//9_identify_repeats_by_coverage/merged.depth &\n",
    "```\n",
    "\n",
    "filter the genome\n",
    "```\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/improve_scaffold_threads.py -i /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/3318_genome.fa -s /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/merged.stats -b /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/all.blast -d 120 -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter1.fa -m 90  -t 32 &\n",
    "\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/improve_scaffold_threads.py -i /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/3318_genome.fa -s /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/merged.stats -b /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/all.blast -d 130 -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter2.fa -m 85  -t 32 &\n",
    "\n",
    " python /home/xcao/p/xiaolongTools/utils/annotation/improve_scaffold_threads.py -i /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/3318_genome.fa -s /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/merged.stats -b /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/all.blast -d 120 -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter3.fa -m 95  -t 32 -M 500 &\n",
    " \n",
    "#get depth hist\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_coverage_histogram.py -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa  -r /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.idxstats -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.filter\n",
    "\n",
    "\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_coverage_histogram.py -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter2.fa  -r /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.idxstats -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/merged.filter2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 identify repeats by coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "python2 partition_scafs_step1.py /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa.scaf_size ../8_improve_assembly/wenlin3303min200filter.fa  > partition_scafs_1\n",
    "python2 partition_scafs_step2.py partition_scafs_1 > partition_scafs_2\n",
    "scp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/merged.bam ks2073@ls5.tacc.utexas.edu:/scratch/05920/ks2073/20181206Junonia/9_identify_repeats_by_coverage/\n",
    "scp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/7_align_reads/merged.bam.bai ks2073@ls5.tacc.utexas.edu:/scratch/05920/ks2073/20181206Junonia/9_identify_repeats_by_coverage/\n",
    "scp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/9_identify_repeats_by_coverage/get_coverage_cmds ks2073@ls5.tacc.utexas.edu:/scratch/05920/ks2073/20181206Junonia/9_identify_repeats_by_coverage/\n",
    "mkdir run\n",
    "mkdir run_result\n",
    "python \n",
    "split get_coverage_cmds ./run/cmd_ -d -l 50000 -a 10\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after finish running the commands, combine the result\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/9_identify_repeats_by_coverage\n",
    "cat ./run_result/* > get_coverage_result\n",
    "paste partition_scafs_2 get_coverage_result > segment_readcount_100\n",
    "python2 get_readcount_histogram.py segment_readcount_100 > segment_readcount_100.hist\n",
    "#check the segment_readcount_100.hist to get the peak coverage and modify the paramter in get_potential_repeats_step1.py\n",
    "cat segment_readcount_100 | awk '{printf \"%s\\t%s\\t%s\\t%s\\n\",$1,$2,$3,$3*100/$2}' > segment_coverage_100\n",
    "python2 get_potential_repeats_step1.py > potential_repeats_1\n",
    "python2 get_potential_repeats_step2.py potential_repeats_1 ../8_improve_assembly/wenlin3303min200.fa\n",
    "cat potential_repeats/scaffold* > repeats.fa #too many input, do not work\n",
    "python combine_files.py\n",
    "```\n",
    "\n",
    "combine_files.py\n",
    "```\n",
    "import glob\n",
    "import os\n",
    "files = glob.glob('./potential_repeats/scaffold*')\n",
    "print('number of files to combine', len(files))\n",
    "results = [open(f).read() for f in files]\n",
    "open('repeats.fa','w').write(''.join(results))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/9_identify_repeats_by_coverage\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_genome_scaf_size.py ../8_improve_assembly/3318_genomefilter1.fa \n",
    "python2 /home/xcao/p/xiaolongTools/utils/annotation/partition_scafs_step1.py genome.scf_size ../8_improve_assembly/3318_genomefilter1.fa  > partition_scafs_1\n",
    "python2 /home/xcao/p/xiaolongTools/utils/annotation/partition_scafs_step2.py partition_scafs_1 > partition_scafs_2\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/get_segment_coverage_with_depth_file.py partition_scafs_2 merged.depth\n",
    "python2 /home/xcao/p/xiaolongTools/utils/annotation/get_readcount_histogram.py segment_coverage_100 > segment_coverage_100.hist\n",
    "\n",
    "#set CUTOFF to 530 in get_potential_repeats_step1.py\n",
    "python2 get_potential_repeats_step1.py > potential_repeats_1\n",
    "python2 get_potential_repeats_step2.py potential_repeats_1 ../8_improve_assembly/3318_genomefilter1.fa\n",
    "python combine_files.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  step 10 run RepeatModeler\n",
    "```\n",
    "scp /home/xcao/w/genomes/Hermeuptychia/wenlin3303min200.fa s185491@nucleus.biohpc.swmed.edu:/work/biophysics/s185491/2018Hermeuptychia/20181219RepeatModeler/\n",
    "\n",
    "#bioHPC\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=repeatModeler\n",
    "#SBATCH --partition=32GB\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=32\n",
    "#SBATCH --time=10-00:00:00\n",
    "#SBATCH --output=0.%j.out\n",
    "#SBATCH --mail-user=xiaolong.cao@utsouthwestern.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "cd /work/biophysics/s185491/2018Hermeuptychia/20181219RepeatModeler/\n",
    "module add repeatModeler/1.0.11\n",
    "module add repeatMasker/4.0.7\n",
    "ln -s /usr/lib64/libgnutls.so.28.43.0 /home2/s185491/p/lib/libgnutls.so.26\n",
    "export LD_LIBRARY_PATH=/home2/s185491/p/lib/\n",
    "/cm/shared/apps/repeatModeler/1.0.11/1.0.11/RepeatModeler-open-1.0.11/BuildDatabase -name 3303 wenlin3303min200.fa\n",
    "/cm/shared/apps/repeatModeler/1.0.11/1.0.11/RepeatModeler-open-1.0.11/RepeatModeler  -database 3303 -engine ncbi -pa 31\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 3318\n",
    "```\n",
    "scp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/3318_genome.fa s185491@nucleus.biohpc.swmed.edu:/work/biophysics/s185491/2018Hermeuptychia/20181219RepeatModeler/\n",
    "\n",
    "#bioHPC\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=repeatModeler\n",
    "#SBATCH --partition=32GB\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=32\n",
    "#SBATCH --time=10-00:00:00\n",
    "#SBATCH --output=0.%j.out\n",
    "#SBATCH --mail-user=xiaolong.cao@utsouthwestern.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "cd /work/biophysics/s185491/2018Hermeuptychia/20181219RepeatModeler/\n",
    "module add repeatModeler/1.0.11\n",
    "module add repeatMasker/4.0.7\n",
    "ln -s /usr/lib64/libgnutls.so.28.43.0 /home2/s185491/p/lib/libgnutls.so.26\n",
    "export LD_LIBRARY_PATH=/home2/s185491/p/lib/\n",
    "/cm/shared/apps/repeatModeler/1.0.11/1.0.11/RepeatModeler-open-1.0.11/BuildDatabase -name 3318 3318_genome.fa\n",
    "/cm/shared/apps/repeatModeler/1.0.11/1.0.11/RepeatModeler-open-1.0.11/RepeatModeler  -database 3318 -engine ncbi -pa 31\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  step 11_classify_repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/11_classify_repeats\n",
    "cp ../9_identify_repeats_by_coverage/repeats.fa ./repeats_by_coverage.fa\n",
    "cp ../10_identify_repeats_by_repeatmodeller/3303-families.fa ./repeats_by_repeatmodeller.fa\n",
    "split -l 7000 -d repeats_by_coverage.fa repeats_\n",
    "# split repeats_by_repeatmodeller.fa manually and submit through the webstie http://www.girinst.org/censor/ \n",
    "\n",
    "wget -O repeats_00.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=11429&lib=root\"      &\n",
    "wget -O repeats_01.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=31832&lib=root\"      &\n",
    "wget -O repeats_02.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=32555&lib=root\"      &\n",
    "wget -O repeats_03.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=33141&lib=root\"      &\n",
    "wget -O repeats_04.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=34724&lib=root\"      &\n",
    "wget -O repeats_05.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=36084&lib=root\"      &\n",
    "wget -O repeats_06.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=37207&lib=root\"      &\n",
    "wget -O repeats_07.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=112585&lib=root\"      &\n",
    "wget -O repeats_08.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=112593&lib=root\"      &\n",
    "wget -O repeats_09.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=113052&lib=root\"      &\n",
    "wget -O repeats_10.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=113243&lib=root\"      &\n",
    "wget -O repeats_11.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=114978&lib=root\"      &\n",
    "wget -O repeats_12.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=12106&lib=root\"      &\n",
    "wget -O repeats_13.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=58051&lib=root\"      &\n",
    "wget -O repeats_14.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=58869&lib=root\"      &\n",
    "wget -O repeats_15.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=59701&lib=root\"      &\n",
    "wget -O repeats_16.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=60263&lib=root\"      &\n",
    "wget -O repeats_17.html    \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=60833&lib=root\"      &\n",
    "\n",
    "cat *.html >repeats_results.html\n",
    "grep '^<table' repeats_results.html | grep 'MAP-NAME' > repeats_results_step0\n",
    "python2 parse_CENSOR_step1.py repeats_results_step0 > repeats_results_step1\n",
    "python2 parse_CENSOR_step2.py repeats_results_step1 > repeats_results_step2\n",
    "cat repeats_by_coverage.fa repeats_by_repeatmodeller.fa >repeats_both.fa\n",
    "\n",
    "python2 count_aa.py repeats_both.fa > repeats.size\n",
    "python2 parse_CENSOR_step3.py repeats_results_step2 repeats.size > repeats_results_step3\n",
    "python2 rename_repeats.py repeats_both.fa repeats_results_step3 3303_repeats.fa 3303_lib.fa Psen\n",
    "cp /export/home5/qc_4/protein_annotation_glaucus/get_repeat_lib/common_lib.fa ./\n",
    "cat 3303_lib.fa common_lib.fa > common_lib_new.fa\n",
    "cat 3303_repeats.fa common_lib.fa > 3303_replib_final.fa\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/11_classify_repeats/\n",
    "cp ../9_identify_repeats_by_coverage/repeats.fa ./repeats_by_coverage.fa\n",
    "cp ../10_identify_repeats_by_repeatmodeller/3318-families.fa ./repeats_by_repeatmodeller.fa\n",
    "split -l 6000 -d repeats_by_coverage.fa repeats_\n",
    "\n",
    "wget -O repeats_00.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=73174&lib=root\" &\n",
    "wget -O repeats_01.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=73197&lib=root\" &\n",
    "wget -O repeats_02.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=73410&lib=root\" &\n",
    "wget -O repeats_03.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=73835&lib=root\" &\n",
    "wget -O repeats_04.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=74226&lib=root\" &\n",
    "wget -O repeats_05.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=74875&lib=root\" &\n",
    "wget -O repeats_06.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=80225&lib=root\" &\n",
    "wget -O repeats_07.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=84706&lib=root\" &\n",
    "wget -O repeats_08.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=85666&lib=root\" &\n",
    "wget -O repeats_09.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=86231&lib=root\" &\n",
    "wget -O repeats_10.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=86560&lib=root\" &\n",
    "wget -O repeats_11.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=87427&lib=root\" &\n",
    "wget -O repeats_12.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=87822&lib=root\" &\n",
    "wget -O repeats_13.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=88463&lib=root\" &\n",
    "wget -O repeats_14.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=95194&lib=root\" &\n",
    "wget -O repeats_15.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=95725&lib=root\" &\n",
    "wget -O repeats_16.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=96178&lib=root\" &\n",
    "wget -O repeats_17.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=96834&lib=root\" &\n",
    "wget -O repeats_18.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=97883&lib=root\" &\n",
    "wget -O repeats_19.html  \"https://www.girinst.org/cgi-bin/censor/show_results.cgi?id=98282&lib=root\" &\n",
    "\n",
    "cat *.html >repeats_results.html\n",
    "grep '^<table' repeats_results.html | grep 'MAP-NAME' > repeats_results_step0\n",
    "python2 parse_CENSOR_step1.py repeats_results_step0 > repeats_results_step1\n",
    "python2 parse_CENSOR_step2.py repeats_results_step1 > repeats_results_step2\n",
    "cat repeats_by_coverage.fa repeats_by_repeatmodeller.fa >repeats_both.fa\n",
    "\n",
    "python2 count_aa.py repeats_both.fa > repeats.size\n",
    "python2 parse_CENSOR_step3.py repeats_results_step2 repeats.size > repeats_results_step3\n",
    "python2 rename_repeats.py repeats_both.fa repeats_results_step3 3318_repeats.fa 3318_lib.fa Psen\n",
    "cp /export/home5/qc_4/protein_annotation_glaucus/get_repeat_lib/common_lib.fa ./\n",
    "cat 3318_lib.fa common_lib.fa > common_lib_new.fa\n",
    "cat 3318_repeats.fa common_lib.fa > 3318_replib_final.fa\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 12_mask_repeats\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/12_mask_repeats\n",
    "cp /export/home11/congqian/3314/12_mask_repeats/*.py ./\n",
    "cp ../11_classify_repeats/3303_replib_final.fa ./\n",
    "cp ../8_improve_assembly/wenlin3303min200filter.fa ./\n",
    "/export/home5/qc_4/software/repeatmasker/RepeatMasker -lib 3303_replib_final.fa -pa 32 -div 30 wenlin3303min200filter.fa >& repeatmasker1.log\n",
    "/export/home5/qc_4/software/repeatmasker/RepeatMasker -species all -pa 32 -div 30 wenlin3303min200filter.fa.masked >& repeatmasker2.log\n",
    "cat wenlin3303min200filter.fa.masked.out >> wenlin3303min200filter.fa.out\n",
    "python2 merge_repeats_step1.py wenlin3303min200filter.fa.out 3303_repeats_step1\n",
    "python2 merge_repeats_step2.py 3303_repeats_step1 3303_repeats.gff\n",
    "python2 get_repeat_counts_and_covs.py 3303_repeats.gff > 3303_repeats.sum\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/12_mask_repeats\n",
    "cp /export/home11/congqian/3314/12_mask_repeats/*.py ./\n",
    "cp ../11_classify_repeats/3318_replib_final.fa ./\n",
    "cp ../8_improve_assembly/3318_genomefilter1.fa ./\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/RepeatMasker -lib 3318_replib_final.fa -pa 32 -div 30 3318_genomefilter1.fa >& repeatmasker1.log\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/RepeatMasker -species all -pa 32 -div 30 3318_genomefilter1.fa.masked >& repeatmasker2.log\n",
    "cat 3318_genomefilter1.fa.masked.out >>3318_genomefilter1.fa.out\n",
    "python2 merge_repeats_step1.py 3318_genomefilter1.fa.out 3318_repeats_step1\n",
    "python2 merge_repeats_step2.py 3318_repeats_step1 3318_repeats.gff\n",
    "python2 get_repeat_counts_and_covs.py 3318_repeats.gff > 3318_repeats.sum\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 13_align_reads_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/13_align_reads_v1/\n",
    "ln -s ../8_improve_assembly/wenlin3303min200filter.fa ./\n",
    "bwa index wenlin3303min200filter.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "\n",
    "commandline = 'cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/13_align_reads_v1/ && /home/xcao/p/bin/bwa mem -t 48 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/13_align_reads_v1/wenlin3303min200filter.fa {filein} >{fileout}.sam && /home/xcao/p/bin/samtools sort -@48 -o {fileout} {fileout}.sam  && rm {fileout}.sam '\n",
    "qsub = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "'''\n",
    "\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/4.1InputSPAdes/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/13_align_reads_v1/'\n",
    "if not os.path.exists(outfolder+'cmds'):\n",
    "    os.makedirs(outfolder+'cmds')\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.bam')\n",
    "    filein = v.replace(',',' ')\n",
    "    c = commandline.format(filein=filein, fileout=fileout)\n",
    "    commandlines.append(c)\n",
    "    print(c)\n",
    "    open(os.path.join(outfolder,'cmds/qsub_'+k),'w').write(qsub+c)\n",
    "f.close()\n",
    "open(os.path.join(outfolder,'commands'),'w').write('\\n'.join(commandlines))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/13_align_reads_v1 && \\\n",
    "samtools merge merged.tmp.bam 2_filter3303_250b.TrimP.fq.bam 2_filter3303_250s.TrimP.fq.bam 2_filter3303_500s.TrimP.fq.bam 2_filter3303lp_250.TrimP.fq.bam 2_filter3303lp_250b.TrimP.fq.bam 2_filter3303lp_500.TrimP.fq.bam 2_filter3303pb_250.TrimP.fq.bam 2_filter3303pb_500.TrimP.fq.bam mate2K.fq.bam mate3K.fq.bam mate6K.fq.bam mate8K.fq.bam mate14K.fq.bam mate15K.fq.bam mate20K.fq.bam paired_from_mate.fq.bam single.fq.bam &&\\\n",
    "samtools sort -@ 32 merged.tmp.bam -o merged.bam &&\\\n",
    "rm merged.tmp.bam &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/13_align_reads_v1\n",
    "ln -s ../8_improve_assembly/3318_genomefilter1.fa ./genome.fa\n",
    "bwa index genome.fa\n",
    "```\n",
    "```\n",
    "import os\n",
    "\n",
    "commandline = 'cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/13_align_reads_v1/ && /home/xcao/p/bin/bwa mem -t 48 /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/13_align_reads_v1/genome.fa {filein} >{fileout}.sam && /home/xcao/p/bin/samtools sort -@48 -o {fileout} {fileout}.sam  && rm {fileout}.sam '\n",
    "qsub = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "'''\n",
    "\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/7_align_reads/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/13_align_reads_v1/'\n",
    "if not os.path.exists(outfolder+'cmds'):\n",
    "    os.makedirs(outfolder+'cmds')\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.bam')\n",
    "    filein = v.replace(',',' ')\n",
    "    c = commandline.format(filein=filein, fileout=fileout)\n",
    "    commandlines.append(c)\n",
    "    print(c)\n",
    "    open(os.path.join(outfolder,'cmds/qsub_'+k),'w').write(qsub+c)\n",
    "f.close()\n",
    "open(os.path.join(outfolder,'commands'),'w').write('\\n'.join(commandlines))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/13_align_reads_v1 && \\\n",
    "samtools merge merged.tmp.bam 2KM.bam 3KM.bam 6KM.bam 8KM.bam 14KM.bam 15KM.bam 20KM.bam 200bp.bam 250bp.bam 500bp.bam  &&\\\n",
    "samtools sort -@ 32 merged.tmp.bam -o merged.bam &&\\\n",
    "rm merged.tmp.bam &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### samtools depth\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/13_align_reads_v1 && samtools index merged.bam && samtools depth -a merged.bam >merged.depth &\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/13_align_reads_v1 && samtools index merged.bam &&  samtools depth -a merged.bam >merged.depth &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steo 14 annotate_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trinity is finished in previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StringTie Histat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# activate bio to use histat and stringtie\n",
    "source activate bio\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/hisat2-build -f /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa -p 32 3303histat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histat\n",
    "```\n",
    "\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/'\n",
    "histat = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/hisat2'\n",
    "genome_ref = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/3303histat'\n",
    "commandline = 'cd {outfolder} && {histat} -p 48 -x {genome_ref} -1 {reads1} -2 {reads2} -S {fileout}.sam && /home/xcao/p/bin/samtools sort -@48 -o {fileout} {fileout}.sam  && rm {fileout}.sam >{fileout}.log'\n",
    "if not os.path.exists(outfolder+'cmds'):\n",
    "    os.makedirs(outfolder+'cmds')\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.bam')\n",
    "    reads1, reads2 = v.strip().split(',')\n",
    "    c = commandline.format(histat=histat, reads1=reads1, reads2=reads2,fileout=fileout, outfolder=outfolder, genome_ref=genome_ref)\n",
    "    commandlines.append(c)\n",
    "    print(c)\n",
    "    open(os.path.join(outfolder,'cmds/qsub_'+k),'w').write(qsub+c)\n",
    "f.close()\n",
    "open(os.path.join(outfolder,'commands'),'w').write('\\n'.join(commandlines))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stringtie\n",
    "\n",
    "```\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/'\n",
    "stringtie = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/stringtie'\n",
    "genome_ref = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/3303histat'\n",
    "commandline = 'cd {outfolder} && {stringtie} {filein} -o {fileout} -p 48 &'\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.gtf')\n",
    "    filein = os.path.join(outfolder,k+'.bam')\n",
    "    c = commandline.format(stringtie=stringtie, filein=filein,fileout=fileout, outfolder=outfolder, genome_ref=genome_ref)\n",
    "    commandlines.append(c)\n",
    "    print(c)\n",
    "f.close()\n",
    "open(os.path.join(outfolder,'commands_stringtie'),'w').write('\\n'.join(commandlines))\n",
    "```\n",
    "\n",
    "```\n",
    "ls /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/*.gtf >/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/gtf_list\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/stringtie --merge -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/merged.gtf /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/gtf_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get sequence\n",
    "```\n",
    "gffread -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa -w /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/stringtie.transcript.fa /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie_hisat/merged.gtf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASA\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript\n",
    "cat Trinity.fasta Trinity-GG.fasta >Trinity.all.fa\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript\n",
    "cat Trinity.fasta Trinity-GG.fasta >Trinity.all.fa\n",
    "perl /home/xcao/p/pasa/PASApipeline-v2.3.3/bin/seqclean Trinity.all.fa -c 16 #max 16 for -c option\n",
    "perl /home/xcao/p/pasa/PASApipeline-v2.3.3/misc_utilities/accession_extractor.pl < Trinity.all.fa > tdn.accs\n",
    "docker run --rm -it -v /tmp:/tmp -v /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript:/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript      pasapipeline/pasapipeline:latest      bash -c 'cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript && /usr/local/src/PASApipeline/Launch_PASA_pipeline.pl      -c alignAssembly.config -C -R --ALIGNER blat,gmap -g wenlin3303min200filter.fa -t Trinity.all.fa.clean -T -u Trinity.all.fa --TDN tdn.accs --trans_gtf stringtie.merged.gtf --CPU 32'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StringTieHistat 3318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# activate bio to use histat and stringtie\n",
    "source activate bio\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/hisat2-build -f /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter1.fa -p 32 3318histat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histat\n",
    "```\n",
    "\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/'\n",
    "histat = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/hisat2'\n",
    "genome_ref = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/3318histat'\n",
    "commandline = 'cd {outfolder} && {histat} -p 48 -x {genome_ref} -1 {reads1} -2 {reads2} -S {fileout}.sam && /home/xcao/p/bin/samtools sort -@48 -o {fileout} {fileout}.sam  && rm {fileout}.sam '\n",
    "if not os.path.exists(outfolder+'cmds'):\n",
    "    os.makedirs(outfolder+'cmds')\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.bam')\n",
    "    reads1, reads2 = v.strip().split(',')\n",
    "    c = commandline.format(histat=histat, reads1=reads1, reads2=reads2,fileout=fileout, outfolder=outfolder, genome_ref=genome_ref)\n",
    "    commandlines.append(c)\n",
    "    print(c)\n",
    "    open(os.path.join(outfolder,'cmds/qsub_'+k),'w').write(qsub+c)\n",
    "f.close()\n",
    "open(os.path.join(outfolder,'commands'),'w').write('\\n'.join(commandlines))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stringtie\n",
    "\n",
    "```\n",
    "files_info = '/home/xcao/w/20181205Hermeuptychia/20181212Annotation/RNA/files.tab'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/'\n",
    "stringtie = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/stringtie'\n",
    "genome_ref = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/3318histat'\n",
    "commandline = 'cd {outfolder} && {stringtie} {filein} -o {fileout} -p 48 &'\n",
    "f = open(files_info)\n",
    "commandlines = []\n",
    "for line in f:\n",
    "    k,v = line.split()\n",
    "    fileout = os.path.join(outfolder,k+'.gtf')\n",
    "    filein = os.path.join(outfolder,k+'.bam')\n",
    "    c = commandline.format(stringtie=stringtie, filein=filein,fileout=fileout, outfolder=outfolder, genome_ref=genome_ref)\n",
    "    commandlines.append(c)\n",
    "    print(c)\n",
    "f.close()\n",
    "open(os.path.join(outfolder,'commands_stringtie'),'w').write('\\n'.join(commandlines))\n",
    "```\n",
    "\n",
    "```\n",
    "ls /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/*.gtf >/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/gtf_list\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/stringtie --merge -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/merged.gtf /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/gtf_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASA 3318\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie_hisat/merged.gtf stringtie.merged.gtf\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter1.fa ./\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/Trinity* ./\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/alignAssembly.config ./\n",
    "\n",
    "perl /home/xcao/p/pasa/PASApipeline-v2.3.3/bin/seqclean Trinity.all.fa -c 16\n",
    "perl /home/xcao/p/pasa/PASApipeline-v2.3.3/misc_utilities/accession_extractor.pl < Trinity.all.fa > tdn.accs\n",
    "docker run --rm -it -v /tmp:/tmp -v /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript://home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript      pasapipeline/pasapipeline:latest      bash -c 'cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript && /usr/local/src/PASApipeline/Launch_PASA_pipeline.pl      -c alignAssembly.config -C -R --ALIGNER blat,gmap -g 3318_genomefilter1.fa -t Trinity.all.fa.clean -T -u Trinity.all.fa --TDN tdn.accs --trans_gtf stringtie.merged.gtf --CPU 32'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 15 annotate homologs\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/15_annotate_homolog/\n",
    "ln -s /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa genome.fa\n",
    "export ALN_TAB=/home/xcao/p/spaln/spaln2.3.2b\n",
    "export ALN_DBS=/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/15_annotate_homolog/\n",
    "/home/xcao/p/spaln/spaln2.3.2b/perl/makeidx.pl genome.fa\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Drosophila/dmel-all-translation-r6.24.fasta >spaln.Drosophila_melanogaster.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Bombyx_mori/GCF_000151625.1_ASM15162v1_protein.faa >spaln.Bombyx_mori.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Anopheles_gambiae/Anopheles-gambiae-PEST_PEPTIDES_AgamP4.10.fa >spaln.Anopheles_gambiae.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Manduca_sexta/MCOT30303.protein.fa >spaln.Manduca_sexta.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Danaus_plexippus/Dp_geneset_OGS2_pep.fasta >spaln.Danaus_plexippus.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Heliconius_melpomene/Heliconius_melpomene_melpomene_Hmel2.5.proteins.fa >spaln.Heliconius_melpomene.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Lerema_accius/Lerema_accius_v1.1_-_proteins.fa >spaln.Lerema_accius.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Papilio_polytes/Papilio_polytes_Ppol_1.0_Refseq_-_proteins.fa >spaln.Papilio_polytes.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Papilio_xuthus/Papilio_xuthus_Pxut_1.0_Refseq_-_proteins.fa >spaln.Papilio_xuthus.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Spodoptera_litura/GCF_002706865.1_ASM270686v1_protein.faa >spaln.Spodoptera_litura.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Megathymus_ursus_violae/mvi_1504_pr.fa >spaln.Megathymus_ursus_violae.gff &\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "workfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/15_annotate_homolog/'\n",
    "query_genome = 'genome.fa'\n",
    "txt = '''/home/xcao/p/bin/spaln -Q7  -O0 {query_genome} {ref_genome} >{output} &'''\n",
    "\n",
    "dc_ref = {}\n",
    "dc_ref['Drosophila_melanogaster'] = '/home/xcao/w/genomes/Drosophila/dmel-all-translation-r6.24.fasta'\n",
    "dc_ref['Bombyx_mori'] = '/home/xcao/w/genomes/Bombyx_mori/GCF_000151625.1_ASM15162v1_protein.faa'\n",
    "dc_ref['Anopheles_gambiae'] = '/home/xcao/w/genomes/Anopheles_gambiae/Anopheles-gambiae-PEST_PEPTIDES_AgamP4.10.fa'\n",
    "dc_ref['Manduca_sexta'] = '/home/xcao/w/genomes/Manduca_sexta/MCOT30303.protein.fa'\n",
    "dc_ref['Danaus_plexippus'] = '/home/xcao/w/genomes/Danaus_plexippus/Dp_geneset_OGS2_pep.fasta'\n",
    "dc_ref['Heliconius_melpomene'] = '/home/xcao/w/genomes/Heliconius_melpomene/Heliconius_melpomene_melpomene_Hmel2.5.proteins.fa'\n",
    "dc_ref['Lerema_accius'] = '/home/xcao/w/genomes/Lerema_accius/Lerema_accius_v1.1_-_proteins.fa'\n",
    "dc_ref['Papilio_polytes'] = '/home/xcao/w/genomes/Papilio_polytes/Papilio_polytes_Ppol_1.0_Refseq_-_proteins.fa'\n",
    "dc_ref['Papilio_xuthus'] = '/home/xcao/w/genomes/Papilio_xuthus/Papilio_xuthus_Pxut_1.0_Refseq_-_proteins.fa'\n",
    "dc_ref['Spodoptera_litura'] = '/home/xcao/w/genomes/Spodoptera_litura/GCF_002706865.1_ASM270686v1_protein.faa'\n",
    "dc_ref['Megathymus_ursus_violae'] = '/home/xcao/w/genomes/Megathymus_ursus_violae/mvi_1504_pr.fa'\n",
    "\n",
    "for species, ref_genome in dc_ref.items():\n",
    "    print(txt.format(workfolder=workfolder, query_genome=query_genome, ref_genome=ref_genome, output = 'spaln.'+species+'.gff'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine and rename geneIDs\n",
    "```\n",
    "files = '''spaln.Anopheles_gambiae.gff\n",
    "spaln.Bombyx_mori.gff\n",
    "spaln.Danaus_plexippus.gff\n",
    "spaln.Drosophila_melanogaster.gff\n",
    "spaln.Heliconius_melpomene.gff\n",
    "spaln.Lerema_accius.gff\n",
    "spaln.Manduca_sexta.gff\n",
    "spaln.Megathymus_ursus_violae.gff\n",
    "spaln.Papilio_polytes.gff\n",
    "spaln.Papilio_xuthus.gff\n",
    "spaln.Spodoptera_litura.gff\n",
    "'''.split()\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/15_annotate_homolog/'\n",
    "fout = open(folder+'spaln.all.rename.gff','w')\n",
    "for f in files:\n",
    "    txt = open(folder + f).read()\n",
    "    species = f.split('.')[1]\n",
    "    txt = txt.replace('ID=','ID='+species+'_')\n",
    "    txt = txt.replace('Parent=','Parent='+species+'_')\n",
    "    fout.write(txt)\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/15_annotate_homolog/\n",
    "ln -s /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter1.fa genome.fa\n",
    "export ALN_TAB=/home/xcao/p/spaln/spaln2.3.2b/table/\n",
    "export ALN_DBS=/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/15_annotate_homolog\n",
    "/home/xcao/p/spaln/spaln2.3.2b/perl/makeidx.pl genome.fa\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Drosophila/dmel-all-translation-r6.24.fasta >spaln.Drosophila_melanogaster.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Bombyx_mori/GCF_000151625.1_ASM15162v1_protein.faa >spaln.Bombyx_mori.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Anopheles_gambiae/Anopheles-gambiae-PEST_PEPTIDES_AgamP4.10.fa >spaln.Anopheles_gambiae.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Manduca_sexta/MCOT30303.protein.fa >spaln.Manduca_sexta.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Danaus_plexippus/Dp_geneset_OGS2_pep.fasta >spaln.Danaus_plexippus.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Heliconius_melpomene/Heliconius_melpomene_melpomene_Hmel2.5.proteins.fa >spaln.Heliconius_melpomene.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Lerema_accius/Lerema_accius_v1.1_-_proteins.fa >spaln.Lerema_accius.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Papilio_polytes/Papilio_polytes_Ppol_1.0_Refseq_-_proteins.fa >spaln.Papilio_polytes.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Papilio_xuthus/Papilio_xuthus_Pxut_1.0_Refseq_-_proteins.fa >spaln.Papilio_xuthus.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Spodoptera_litura/GCF_002706865.1_ASM270686v1_protein.faa >spaln.Spodoptera_litura.gff &\n",
    "/home/xcao/p/bin/spaln -Q7  -O0 genome.fa /home/xcao/w/genomes/Megathymus_ursus_violae/mvi_1504_pr.fa >spaln.Megathymus_ursus_violae.gff &\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with qian's script\n",
    "```\n",
    "ls -1d /work/biophysics/jshen3/annotation/3639/15_annotate_homolog/exonerate/*_prots | awk '{printf \"cp -r %s . &\\n\", $1}' | bash\n",
    "wait\n",
    "ls -1 *_prots/*.fa | awk '{split($1, a, \"/\"); split(a[1], b, \"_\"); printf \"exonerate --model protein2genome --refine region -q %s -t genome.fa -Q protein -T dna --showtargetgff yes --showalignment yes --percent 30 > %s_aligns/%s.exonerate\\n\", $1, b[1], a[2]}' > input\n",
    "wc -l input\n",
    "split -l 7673 input input_ # Divide input file into 15 parts to allocate to 15 jobs, get the number by divide input lines to 15.\n",
    "ls -1d *_prots | awk '{split($1, a, \"_\"); printf \"mkdir %s_aligns\\n\", a[1]}' | bash\n",
    "ls -1 input_?? | awk '{split($1, a, \"_\"); printf \"%s\\n\", a[2]}' > list\n",
    "python2 prepare_exenorate_jobs.py genome\n",
    "ls -1 genome_??.job | awk '{printf \"sbatch %s\\n\", $1}' | bash\n",
    "ls -1d *_aligns | awk '{split($1, a, \"_\"); printf \"cat %s/*.exonerate > %s.exonerate &\\n\", $1, a[1]}' | bash\n",
    "wait\n",
    "ls -1d *_aligns | awk '{split($1, a, \"_\"); printf \"python2 process_exonerate_out_to_prediction.py %s.exonerate homolog_%s.gff &\\n\", a[1], a[1]}' | bash\n",
    "wait\n",
    "ls -1 *_prots/*.fa | awk '{split($1, a, \"_\"); printf \"python2 fasta_letter_count.py %s >> %s_lens \\n\", $1, a[1]}' | bash\n",
    "wait\n",
    "ls -1d *_aligns | awk '{split($1, a, \"_\"); printf \"python2 select_complete_aligns.py %s &\\n\", a[1]}' | bash\n",
    "wait\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 16_prepare_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/16_prepare_train_data/\n",
    "cp /export/home11/congqian/3314/16_prepare_train_data/*.py ./\n",
    "\n",
    "cp ../14_annotate_transcript/stringtie.merged.gtf ./\n",
    "cp ../14_annotate_transcript/sample_mydb_pasa.sqlite.pasa_assemblies.gtf ./3303_pasa.gtf\n",
    "cp ../15_annotate_homolog/*.gff ./\n",
    "cat spaln.*.gff > spaln.homolog.gff\n",
    "cat stringtie.merged.gtf 3303_pasa.gtf > genome_based.gff\n",
    "\n",
    "#python rewrite_pasa_gff.py 3303_pasa.gtf > 3303_pasa.gff #this one not needed here\n",
    "#run step16_prepare_training_data.py in ipython, and change some parts accordingly\n",
    "```\n",
    "\n",
    "final result is   \n",
    "good_transcript_genome_homology.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/16_prepare_train_data\n",
    "cp /export/home11/congqian/3314/16_prepare_train_data/*.py ./\n",
    "cp ../14_annotate_transcript/stringtie.merged.gtf ./\n",
    "cp ../14_annotate_transcript/3318_genomefilter1.fa.sqlite.pasa_assemblies.gtf ./3318_pasa.gtf\n",
    "cp ../15_annotate_homolog/*.gff ./\n",
    "cat spaln.*.gff > spaln.homolog.gff\n",
    "cat 3318_pasa.gtf stringtie.merged.gtf >genome_based.gff\n",
    "#run step16_prepare_training_data.py in ipython, and change some parts accordingly\n",
    "\n",
    "```\n",
    "\n",
    "final result is   \n",
    "good_transcript_genome_homology.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with Qian's scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "gffread ../14_annotate_transcript/stringtie.merged.gtf -o stringtie.gff3\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/sample_mydb_pasa.sqlite.pasa_assemblies.gtf -o pasa.gff3\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/3318_genomefilter1.fa.sqlite.pasa_assemblies.gtf -o pasa.gff3\n",
    "python2 rewrite_pasa_gff.py pasa.gff3 > pasa.gff\n",
    "cp ../15_annotate_homolog/*_good.gff ./\n",
    "sed -i 's/gene/transcript/g' *_good.gff\n",
    "\n",
    "#Note: memory consumption huge.\n",
    "python2 select_good_transcripts_step1.py bmo_good.gff pasa.gff > good_transcripts_bmo_pasa &\n",
    "python2 select_good_transcripts_step1.py bmo_good.gff stringtie.gff3 > good_transcripts_bmo_tophat &\n",
    "python2 select_good_transcripts_step1.py cne_good.gff pasa.gff > good_transcripts_cne_pasa &\n",
    "python2 select_good_transcripts_step1.py cne_good.gff stringtie.gff3 > good_transcripts_cne_tophat &\n",
    "python2 select_good_transcripts_step1.py dme_good.gff pasa.gff > good_transcripts_dme_pasa &\n",
    "python2 select_good_transcripts_step1.py dme_good.gff stringtie.gff3 > good_transcripts_dme_tophat &\n",
    "python2 select_good_transcripts_step1.py dpl_good.gff pasa.gff > good_transcripts_dpl_pasa &\n",
    "python2 select_good_transcripts_step1.py dpl_good.gff stringtie.gff3 > good_transcripts_dpl_tophat &\n",
    "python2 select_good_transcripts_step1.py hme_good.gff pasa.gff > good_transcripts_hme_pasa &\n",
    "python2 select_good_transcripts_step1.py hme_good.gff stringtie.gff3 > good_transcripts_hme_tophat &\n",
    "python2 select_good_transcripts_step1.py lac_good.gff pasa.gff > good_transcripts_lac_pasa &\n",
    "python2 select_good_transcripts_step1.py lac_good.gff stringtie.gff3 > good_transcripts_lac_tophat &\n",
    "python2 select_good_transcripts_step1.py pgl_good.gff pasa.gff > good_transcripts_pgl_pasa &\n",
    "python2 select_good_transcripts_step1.py pgl_good.gff stringtie.gff3 > good_transcripts_pgl_tophat &\n",
    "python2 select_good_transcripts_step1.py ppo_good.gff pasa.gff > good_transcripts_ppo_pasa &\n",
    "python2 select_good_transcripts_step1.py ppo_good.gff stringtie.gff3 > good_transcripts_ppo_tophat &\n",
    "python2 select_good_transcripts_step1.py pxu_good.gff pasa.gff > good_transcripts_pxu_pasa &\n",
    "python2 select_good_transcripts_step1.py pxu_good.gff stringtie.gff3 > good_transcripts_pxu_tophat &\n",
    "\n",
    "cat good_transcripts_???_* > good_transcript_step1.gff\n",
    "sed -i 's/StringTie/Cufflinks/g' good_transcript_step1.gff\n",
    "python2 select_good_transcripts_step2.py\n",
    "python2 select_good_transcripts_step3.py ../genome.fa\n",
    "python2 select_good_transcripts_step4.py ../genome.fa\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/12_mask_repeats/3303_repeats.gff ./repeats.gff\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/12_mask_repeats/3318_repeats.gff ./repeats.gff\n",
    "python2 select_good_transcripts_step5.py repeats.gff\n",
    "python2 select_good_transcripts_step6.py \n",
    "python2 select_good_transcripts_step7.py \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train denovo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo\n",
    "cp ../16_prepare_train_data/good_transcript_genome_homology.gff ./train_data_ori.gff\n",
    "\n",
    "# train genemark first, this can be done without a training set\n",
    "mkdir train_genmark \n",
    "cd train_genmark\n",
    "/home/xcao/p/GeneMark/gm_et_linux_64/gmes_petap/gmes_petap.pl --ES --cores 32  --sequence ../../8_improve_assembly/wenlin3303min200filter.fa >& train.log & disown -h\n",
    "# it produces: /export/home10/congqian/3303/17_train_denovo/train_genemark/mod/es.mod, which is a soft link point to /export/home10/congqian/3303/17_train_denovo/train_genemark/run/S7/org_S7_bp.0mtx\n",
    "cp /export/home10/congqian/3303/17_train_denovo/train_genemark/run/S7/org_S7_bp.0mtx /export/home10/congqian/3303/17_train_denovo/train_genemark/3318.mod\n",
    "\n",
    "# train augustus after getting the trainning data\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo\n",
    "mkdir train_augustus\n",
    "cd train_augustus/\n",
    "export AUGUSTUS_CONFIG_PATH=/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/config\n",
    "export PATH=/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin:$PATH\n",
    "/home/xcao/p/gffread/gffread-0.9.12.Linux_x86_64/gffread ../train_data.gff  -g ../../8_improve_assembly/wenlin3303min200filter.fa -w train_data.fa\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/changeGFF2oldNaming.py /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo/train_data_ori.gff >/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo/train_data.gff\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/gff2gbSmallDNA.pl ../train_data.gff ../../8_improve_assembly/wenlin3303min200filter.fa 1000 train_data.gb\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/randomSplit.pl train_data.gb 100\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/new_species.pl --species=3303\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3303 train_data.gb.train\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/augustus --species=3303 train_data.gb.test | tee firsttest.out\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/optimize_augustus.pl --cpus=32 --species=3303 train_data.gb >& optimize.log & disown -h\n",
    "# last step will take long. let in run in the background and train other programs\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3303 train_data.gb\n",
    "\n",
    "# train snap while the optimizing step for augustus is still running\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo\n",
    "mkdir train_snap\n",
    "cd train_snap/\n",
    "sort -k 1,1 -s ../train_data.gff  > train_data.gff\n",
    "sed -i 's/cds/exon/g' train_data.gff\n",
    "cp /alea/home5/qc_4/protein_annotation_accius/train_snap/gff2zff.pl ./\n",
    "perl gff2zff.pl < train_data.gff > 3303.ann\n",
    "grep '>' 3303.ann | awk '{split($1,a,\">\");printf \"%s\\n\",a[2]}' > scaflist\n",
    "cp /alea/home5/qc_4/protein_annotation_accius/train_snap/extract_seqs_in_order.py ./\n",
    "python extract_seqs_in_order.py scaflist ../../8_improve_assembly/wenlin3303min200filter.fa 3303.dna\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom 3303.ann 3303.dna -gene-stats > gene-stats.log 2>&1\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom 3303.ann 3303.dna -validate > validate.log 2>&1\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom 3303.ann 3303.dna -categorize 1000 > categorize.log 2>&1\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom uni.ann uni.dna -export 1000 -plus > uni-plus.log 2>&1\n",
    "mkdir params\n",
    "cd params/\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/forge ../export.ann ../export.dna > ../forge.log 2>&1\n",
    "cd ../\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/hmm-assembler.pl 3303 params/ > 3303.hmm\n",
    "\n",
    "# train glimmer while the optimizing step for augustus is still running\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo\n",
    "mkdir train_glimmer\n",
    "cd train_glimmer\n",
    "cp /alea/home5/qc_4/protein_annotation_accius/train_glimmer/zff2glim.py ./\n",
    "cp ../train_snap/3303.dna ./\n",
    "python2 zff2glim.py ../train_snap/3303.ann > 3303.ann\n",
    "/home/xcao/p/GlimmerHMM/GlimmerHMM/train/trainGlimmerHMM 3303.dna 3303.ann -b 2 -d 3303 >& train.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/17_train_denovo\n",
    "cp ../16_prepare_train_data/good_transcript_genome_homology.gff ./train_data_ori.gff\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/changeGFF2oldNaming.py train_data_ori.gff >train_data.gff\n",
    "\n",
    "# train genemark first, this can be done without a training set\n",
    "mkdir train_genmark \n",
    "cd train_genmark\n",
    "/home/xcao/p/GeneMark/gm_et_linux_64/gmes_petap/gmes_petap.pl --ES --cores 32  --sequence ../../8_improve_assembly/3318_genomefilter1.fa >& train.log & disown -h\n",
    "# it produces: /export/home10/congqian/3303/17_train_denovo/train_genemark/mod/es.mod, which is a soft link point to /export/home10/congqian/3303/17_train_denovo/train_genemark/run/S7/org_S7_bp.0mtx\n",
    "cp /export/home10/congqian/3303/17_train_denovo/train_genemark/run/S7/org_S7_bp.0mtx /export/home10/congqian/3303/17_train_denovo/train_genemark/3318.mod\n",
    "\n",
    "\n",
    "# train augustus after getting the trainning data\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/17_train_denovo\n",
    "mkdir train_augustus\n",
    "cd train_augustus/\n",
    "export AUGUSTUS_CONFIG_PATH=/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/config\n",
    "export PATH=/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin:$PATH\n",
    "/home/xcao/p/gffread/gffread-0.9.12.Linux_x86_64/gffread ../train_data.gff  -g ../../8_improve_assembly/3318_genomefilter1.fa -w train_data.fa\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/gff2gbSmallDNA.pl ../train_data.gff ../../8_improve_assembly/3318_genomefilter1.fa 1000 train_data.gb\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/randomSplit.pl train_data.gb 100\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/new_species.pl --species=3318\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3318 train_data.gb.train\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/augustus --species=3318 train_data.gb.test | tee firsttest.out\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/optimize_augustus.pl --cpus=32 --species=3318 train_data.gb >& optimize.log & disown -h\n",
    "# last step will take long. let in run in the background and train other programs\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3318 train_data.gb\n",
    "\n",
    "# train snap while the optimizing step for augustus is still running\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/17_train_denovo\n",
    "mkdir train_snap\n",
    "cd train_snap/\n",
    "sort -k 1,1 -s ../train_data.gff  > train_data.gff\n",
    "sed -i 's/cds/exon/g' train_data.gff\n",
    "cp /alea/home5/qc_4/protein_annotation_accius/train_snap/gff2zff.pl ./\n",
    "perl gff2zff.pl < train_data.gff > 3318.ann\n",
    "grep '>' 3318.ann | awk '{split($1,a,\">\");printf \"%s\\n\",a[2]}' > scaflist\n",
    "cp /alea/home5/qc_4/protein_annotation_accius/train_snap/extract_seqs_in_order.py ./\n",
    "python extract_seqs_in_order.py scaflist ../../8_improve_assembly/3318_genomefilter1.fa 3318.dna\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom 3318.ann 3318.dna -gene-stats > gene-stats.log 2>&1\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom 3318.ann 3318.dna -validate > validate.log 2>&1\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom 3318.ann 3318.dna -categorize 1000 > categorize.log 2>&1\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/fathom uni.ann uni.dna -export 1000 -plus > uni-plus.log 2>&1\n",
    "mkdir params\n",
    "cd params/\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/forge ../export.ann ../export.dna > ../forge.log 2>&1\n",
    "cd ../\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/hmm-assembler.pl 3318 params/ > 3318.hmm\n",
    "\n",
    "# train glimmer while the optimizing step for augustus is still running\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/17_train_denovo\n",
    "mkdir train_glimmer\n",
    "cd train_glimmer\n",
    "cp /alea/home5/qc_4/protein_annotation_accius/train_glimmer/zff2glim.py ./\n",
    "cp ../train_snap/3318.dna ./\n",
    "python2 zff2glim.py ../train_snap/3318.ann > 3318.ann\n",
    "/home/xcao/p/GlimmerHMM/GlimmerHMM/train/trainGlimmerHMM 3318.dna 3318.ann -b 2 -d 3318 >& train.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rerun 20190123\n",
    "```\n",
    "cd train_augustus/\n",
    "export AUGUSTUS_CONFIG_PATH=/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/config\n",
    "export PATH=/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin:$PATH\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/gff2gbSmallDNA.pl ../train_data.gff ../../genome.fa 1000 train_data.gb\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/randomSplit.pl train_data.gb 100\n",
    "\n",
    "\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/new_species.pl --species=3303\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3303 train_data.gb.train\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/augustus --species=3303 train_data.gb.test | tee firsttest.out\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/optimize_augustus.pl --cpus=32 --species=3303 train_data.gb >& optimize.log & disown -h\n",
    "# last step will take long. let in run in the background and train other programs\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3303 train_data.gb\n",
    "\n",
    "\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/new_species.pl --species=3318\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3318 train_data.gb.train\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/augustus --species=3318 train_data.gb.test | tee firsttest.out\n",
    "perl /home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/scripts/optimize_augustus.pl --cpus=32 --species=3318 train_data.gb >& optimize.log & disown -h\n",
    "# last step will take long. let in run in the background and train other programs\n",
    "/home/xcao/p/quast/quast-5.0.2/quast_libs/augustus3.2.3/bin/etraining --species=3318 train_data.gb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 18_annotate_denovo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/\n",
    "mkdir maker\n",
    "cd maker\n",
    "source activate bio\n",
    "maker -CTL\n",
    "#edit generated file in the folder\n",
    "maker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the genome to 100 parts and run to increase speed 3303\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/\n",
    "cp ../8_improve_assembly/wenlin3303min200filter.fa ./genome.fa\n",
    "source activate bio\n",
    "gffcompare  ../14_annotate_transcript/stringtie.merged.gtf ../14_annotate_transcript/sample_mydb_pasa.sqlite.pasa_assemblies.gtf -o genomeBased -s genome.fa\n",
    "gffread genomeBased.combined.gtf -o genomeBased.combined.gff3\n",
    "\n",
    "gffcompare ../15_annotate_homolog/*.gff -o homologyBased -p Spaln -X\n",
    "gffread homologyBased.combined.gtf -o homologyBased.combined.gff3\n",
    "\n",
    "grep '>' genome.fa | awk '{split($1,a,\">\");printf \"%s\\n\",a[2]}' > scaflist\n",
    "python2 prepare_repeat_for_maker.py  ../12_mask_repeats/3303_repeats.gff repeats.gff3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "\n",
    "workfolder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo'\n",
    "folder_makers = os.path.join(workfolder, 'maker_split')\n",
    "folder_cmds = os.path.join(workfolder, 'cmds')\n",
    "folder_ref = os.path.join(workfolder,'maker')\n",
    "file_maker_bopts = os.path.join(folder_ref,'maker_bopts.ctl')\n",
    "file_maker_exe = os.path.join(folder_ref,'maker_exe.ctl')#add missing programs to this file\n",
    "file_maker_opts = os.path.join(folder_ref,'maker_opts.ctl')#edit this file so that it works for all. \n",
    "#Basically, since all individual runs have similar input, set \n",
    "## genome=genome_each.fa\n",
    "## est_gff=est_each.gff\n",
    "## protein_gff=protein_each.gff\n",
    "## rm_gff=repeats_each.gff\n",
    "## est2genome=1\n",
    "## protein2genome=1\n",
    "## trna=1 # or 0 depending on whether to find tRNAs\n",
    "# other trained data file need to be changed, too\n",
    "file_genome = os.path.join(workfolder,'genome.fa')\n",
    "gff3_genomeBased = os.path.join(workfolder, 'genomeBased.combined.gff3')\n",
    "gff3_homologyBased = os.path.join(workfolder, 'homologyBased.combined.gff3')\n",
    "gff3_repeats = os.path.join(workfolder,'repeats.gff3')\n",
    "\n",
    "qsub_common = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "source /home/xcao/.bash_profile\n",
    "source /home/xcao/p/anaconda3_5.2.0/bin/activate bio\n",
    "cd {workfolder}\n",
    "maker --ignore_nfs_tmp\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def makefolder(*paths):\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "def writeFasta(seqs,outfile):\n",
    "    '''\n",
    "    seqs is a list of SeqIO sequence, write sequence to outfile\n",
    "    '''\n",
    "    with open(outfile,'w') as f:\n",
    "        for s in seqs:\n",
    "            f.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "    return None\n",
    "\n",
    "def getGffEach(gffall, scaffolds, outfile):\n",
    "    '''\n",
    "    gffall is a filename or a list by reading the gffall file with readlines()\n",
    "    scaffolds is scaffolds to keep in gffall\n",
    "    outfile is where to save the output file\n",
    "    filter the gffall with scaffolds, and save output to outfile\n",
    "    '''\n",
    "    if isinstance(gffall, str):\n",
    "        print('input gffall is a filename. Read it to list')\n",
    "        gffall = open(gffall).readlines()\n",
    "    elif isinstance(gffall,list):\n",
    "        print('input gffall is a list')\n",
    "    else:\n",
    "        print('unknown format for input')\n",
    "        return None\n",
    "    \n",
    "    if isinstance(scaffolds, list):\n",
    "        scaffolds = set(scaffolds)\n",
    "    if not isinstance(scaffolds,set):\n",
    "        print('scaffolds should be a list or set')\n",
    "        return None\n",
    "    \n",
    "    with open(outfile,'w') as f:\n",
    "        for line in gffall:\n",
    "            elements = line.split('\\t')\n",
    "            if len(elements) >8:\n",
    "                if elements[0] in scaffolds:\n",
    "                    f.write(line)\n",
    "    return None\n",
    "\n",
    "N = 1000\n",
    "\n",
    "genome_seqs = list(SeqIO.parse(file_genome,'fasta'))\n",
    "ls_gff3_genomeBased = open(gff3_genomeBased).readlines()\n",
    "ls_gff3_homologyBased = open(gff3_homologyBased).readlines()\n",
    "ls_gff3_repeats = open(gff3_repeats).readlines()\n",
    "\n",
    "#split genome_seqs to N parts\n",
    "ls_genomeIDs = np.array_split(range(len(genome_seqs)),N)\n",
    "ls_genomeSeqs = [[genome_seqs[i] for i in e] for e in ls_genomeIDs]\n",
    "\n",
    "#split genome sequences to each folder\n",
    "# for each folder, create genome_each.fa est_each.gff protein_each.gff repeats_each.gff\n",
    "\n",
    "def processOne(i):\n",
    "    outfolder = os.path.join(folder_makers, str(i))\n",
    "    makefolder(outfolder)\n",
    "    file_each_genome = os.path.join(outfolder,'genome_each.fa')\n",
    "    file_each_est = os.path.join(outfolder,'est_each.gff')\n",
    "    file_each_protein = os.path.join(outfolder,'protein_each.gff')\n",
    "    file_each_repeats = os.path.join(outfolder,'repeats_each.gff')\n",
    "    writeFasta(ls_genomeSeqs[i], file_each_genome)\n",
    "    scaffolds = [e.id for e in ls_genomeSeqs[i]]\n",
    "    getGffEach(gffall=ls_gff3_genomeBased, scaffolds=scaffolds, outfile=file_each_est)\n",
    "    getGffEach(gffall=ls_gff3_homologyBased, scaffolds=scaffolds, outfile=file_each_protein)\n",
    "    getGffEach(gffall=ls_gff3_repeats, scaffolds=scaffolds, outfile=file_each_repeats)\n",
    "    \n",
    "    os.system('cp ' + file_maker_bopts + ' ' + outfolder + '/')\n",
    "    os.system('cp ' + file_maker_exe + ' ' + outfolder + '/')\n",
    "    os.system('cp ' + file_maker_opts + ' ' + outfolder + '/')\n",
    "    \n",
    "    open(os.path.join(folder_cmds,'qsub'+str(i)),'w').write(qsub_common.format(workfolder=outfolder))\n",
    "\n",
    "#for i in range(N):\n",
    "#    processOne(i)\n",
    "#    break\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(32)\n",
    "pool.map(processOne,list(range(N)))\n",
    "pool.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "workfolder=/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/cmds\n",
    "tosub=`ls $workfolder`\n",
    "for onefile in $tosub; do qsub \"$workfolder/$onefile\"; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maker_opts.ctl looks like\n",
    "```\n",
    "#-----Genome (these are always required)\n",
    "genome=genome_each.fa #genome sequence (fasta file or fasta embeded in GFF3 file)\n",
    "organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n",
    "\n",
    "#-----Re-annotation Using MAKER Derived GFF3\n",
    "maker_gff= #MAKER derived GFF3 file\n",
    "est_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\n",
    "altest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\n",
    "protein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\n",
    "rm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\n",
    "model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\n",
    "pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\n",
    "other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n",
    "\n",
    "#-----EST Evidence (for best results provide a file for at least one)\n",
    "est= #set of ESTs or assembled mRNA-seq in fasta format\n",
    "altest= #EST/cDNA sequence file in fasta format from an alternate organism\n",
    "est_gff=est_each.gff #aligned ESTs or mRNA-seq from an external GFF3 file\n",
    "altest_gff= #aligned ESTs from a closly relate species in GFF3 format\n",
    "\n",
    "#-----Protein Homology Evidence (for best results provide a file for at least one)\n",
    "protein=  #protein sequence file in fasta format (i.e. from mutiple oransisms)\n",
    "protein_gff=protein_each.gff  #aligned protein homology evidence from an external GFF3 file\n",
    "\n",
    "#-----Repeat Masking (leave values blank to skip repeat masking)\n",
    "model_org=all #select a model organism for RepBase masking in RepeatMasker\n",
    "rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\n",
    "repeat_protein=/home/xcao/p/maker/maker-3.01.02/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\n",
    "rm_gff=repeats_each.gff #pre-identified repeat elements from an external GFF3 file\n",
    "prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\n",
    "softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n",
    "\n",
    "#-----Gene Prediction\n",
    "snaphmm=/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo/train_snap/3303.hmm #SNAP HMM file\n",
    "gmhmm=/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo/train_genmark/output/gmhmm.mod #GeneMark HMM file\n",
    "augustus_species= #Augustus gene prediction species model\n",
    "fgenesh_par_file= #FGENESH parameter file\n",
    "pred_gff= #ab-initio predictions from an external GFF3 file\n",
    "model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\n",
    "est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\n",
    "protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no\n",
    "trna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no\n",
    "snoscan_rrna= #rRNA file to have Snoscan find snoRNAs\n",
    "unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n",
    "\n",
    "#-----Other Annotation Feature Types (features MAKER doesn't recognize)\n",
    "other_gff= #extra features to pass-through to final MAKER generated GFF3 file\n",
    "\n",
    "#-----External Application Behavior Options\n",
    "alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\n",
    "cpus=32 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n",
    "\n",
    "#-----MAKER Behavior Options\n",
    "max_dna_len=2000000 #length for dividing up contigs into chunks (increases/decreases memory usage)\n",
    "min_contig=100 #skip genome contigs below this length (under 10kb are often useless)\n",
    "\n",
    "pred_flank=200 #flank for extending evidence clusters sent to gene predictors\n",
    "pred_stats=1 #report AED and QI statistics for all predictions as well as models\n",
    "AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\n",
    "min_protein=30 #require at least this many amino acids in predicted proteins\n",
    "alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\n",
    "always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\n",
    "map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\n",
    "keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n",
    "\n",
    "split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\n",
    "single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\n",
    "single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\n",
    "correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n",
    "\n",
    "tries=2 #number of times to try a contig if there is a failure for some reason\n",
    "clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\n",
    "clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\n",
    "TMP=/tmp #specify a directory other than the system default temporary directory for temporary files\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import glob\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/maker_split'\n",
    "files = glob.glob(folder+'/*/genome_each.maker.output/genome_each_datastore/**/scaffold*.gff', recursive=True)\n",
    "fout = open(folder+'/../maker_all.gff3','w')\n",
    "for f in files:\n",
    "    fout.write(open(f).read())\n",
    "fout.close()\n",
    "\n",
    "import os\n",
    "os.system('cd '+folder+'/../ && '+ ''' grep '^scaf' maker_all.gff3 | grep -P '\\tgenemark\\t' > maker_genemark.gff\n",
    "grep '^scaf' maker_all.gff3 | grep -P '\\taugustus_masked\\t' > maker_augustus.gff\n",
    "grep '^scaf' maker_all.gff3 | grep -P '\\tsnap_masked\\t' > maker_snap.gff\n",
    "grep '^scaf' maker_all.gff3 | grep -P '\\tmaker\\t' > maker_maker.gff\n",
    "grep '^scaf' maker_all.gff3 | grep -P '\\trepeatrunner\\t' > maker_repeatrunner.gff ''')\n",
    "\n",
    "import glob\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/maker_split/'\n",
    "files = glob.glob(folder+'/*/genome_each.maker.output/genome_each_datastore/**/scaffold*.gff', recursive=True)\n",
    "fout = open(folder+'/../maker_all.gff3','w')\n",
    "for f in files:\n",
    "    fout.write(open(f).read())\n",
    "fout.close()\n",
    "\n",
    "```\n",
    "It seems snap and augustus are not working here. ingore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/\n",
    "cp ../8_improve_assembly/3318_genomefilter1.fa ./genome.fa\n",
    "source activate bio\n",
    "gffcompare  ../14_annotate_transcript/stringtie.merged.gtf ../14_annotate_transcript/3318_genomefilter1.fa.sqlite.pasa_assemblies.gtf -o genomeBased -s genome.fa\n",
    "gffread genomeBased.combined.gtf -o genomeBased.combined.gff3\n",
    "\n",
    "gffcompare ../15_annotate_homolog/*.gff -o homologyBased -p Spaln -X\n",
    "gffread homologyBased.combined.gtf -o homologyBased.combined.gff3\n",
    "\n",
    "grep '>' genome.fa | awk '{split($1,a,\">\");printf \"%s\\n\",a[2]}' > scaflist\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/prepare_repeat_for_maker.py ./\n",
    "python2 prepare_repeat_for_maker.py  ../12_mask_repeats/3318_repeats.gff repeats.gff3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "\n",
    "workfolder = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/'\n",
    "folder_makers = os.path.join(workfolder, 'maker_split')\n",
    "folder_cmds = os.path.join(workfolder, 'cmds')\n",
    "folder_ref = os.path.join(workfolder,'maker')\n",
    "file_maker_bopts = os.path.join(folder_ref,'maker_bopts.ctl')\n",
    "file_maker_exe = os.path.join(folder_ref,'maker_exe.ctl')#add missing programs to this file\n",
    "file_maker_opts = os.path.join(folder_ref,'maker_opts.ctl')#edit this file so that it works for all. \n",
    "#Basically, since all individual runs have similar input, set \n",
    "## genome=genome_each.fa\n",
    "## est_gff=est_each.gff\n",
    "## protein_gff=protein_each.gff\n",
    "## rm_gff=repeats_each.gff\n",
    "## est2genome=1\n",
    "## protein2genome=1\n",
    "## trna=1 # or 0 depending on whether to find tRNAs\n",
    "# other trained data file need to be changed, too\n",
    "file_genome = os.path.join(workfolder,'genome.fa')\n",
    "gff3_genomeBased = os.path.join(workfolder, 'genomeBased.combined.gff3')\n",
    "gff3_homologyBased = os.path.join(workfolder, 'homologyBased.combined.gff3')\n",
    "gff3_repeats = os.path.join(workfolder,'repeats.gff3')\n",
    "\n",
    "qsub_common = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "source /home/xcao/.bash_profile\n",
    "source /home/xcao/p/anaconda3_5.2.0/bin/activate bio\n",
    "cd {workfolder}\n",
    "maker --ignore_nfs_tmp\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def makefolder(*paths):\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "def writeFasta(seqs,outfile):\n",
    "    '''\n",
    "    seqs is a list of SeqIO sequence, write sequence to outfile\n",
    "    '''\n",
    "    with open(outfile,'w') as f:\n",
    "        for s in seqs:\n",
    "            f.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "    return None\n",
    "\n",
    "def getGffEach(gffall, scaffolds, outfile):\n",
    "    '''\n",
    "    gffall is a filename or a list by reading the gffall file with readlines()\n",
    "    scaffolds is scaffolds to keep in gffall\n",
    "    outfile is where to save the output file\n",
    "    filter the gffall with scaffolds, and save output to outfile\n",
    "    '''\n",
    "    if isinstance(gffall, str):\n",
    "        print('input gffall is a filename. Read it to list')\n",
    "        gffall = open(gffall).readlines()\n",
    "    elif isinstance(gffall,list):\n",
    "        print('input gffall is a list')\n",
    "    else:\n",
    "        print('unknown format for input')\n",
    "        return None\n",
    "    \n",
    "    if isinstance(scaffolds, list):\n",
    "        scaffolds = set(scaffolds)\n",
    "    if not isinstance(scaffolds,set):\n",
    "        print('scaffolds should be a list or set')\n",
    "        return None\n",
    "    \n",
    "    with open(outfile,'w') as f:\n",
    "        for line in gffall:\n",
    "            elements = line.split('\\t')\n",
    "            if len(elements) >8:\n",
    "                if elements[0] in scaffolds:\n",
    "                    f.write(line)\n",
    "    return None\n",
    "\n",
    "N = 1000\n",
    "makefolder(folder_cmds)\n",
    "makefolder(folder_makers)\n",
    "genome_seqs = list(SeqIO.parse(file_genome,'fasta'))\n",
    "ls_gff3_genomeBased = open(gff3_genomeBased).readlines()\n",
    "ls_gff3_homologyBased = open(gff3_homologyBased).readlines()\n",
    "ls_gff3_repeats = open(gff3_repeats).readlines()\n",
    "\n",
    "#split genome_seqs to N parts\n",
    "ls_genomeIDs = np.array_split(range(len(genome_seqs)),N)\n",
    "ls_genomeSeqs = [[genome_seqs[i] for i in e] for e in ls_genomeIDs]\n",
    "\n",
    "#split genome sequences to each folder\n",
    "# for each folder, create genome_each.fa est_each.gff protein_each.gff repeats_each.gff\n",
    "\n",
    "def processOne(i):\n",
    "    outfolder = os.path.join(folder_makers, str(i))\n",
    "    makefolder(outfolder)\n",
    "    file_each_genome = os.path.join(outfolder,'genome_each.fa')\n",
    "    file_each_est = os.path.join(outfolder,'est_each.gff')\n",
    "    file_each_protein = os.path.join(outfolder,'protein_each.gff')\n",
    "    file_each_repeats = os.path.join(outfolder,'repeats_each.gff')\n",
    "    writeFasta(ls_genomeSeqs[i], file_each_genome)\n",
    "    scaffolds = [e.id for e in ls_genomeSeqs[i]]\n",
    "    getGffEach(gffall=ls_gff3_genomeBased, scaffolds=scaffolds, outfile=file_each_est)\n",
    "    getGffEach(gffall=ls_gff3_homologyBased, scaffolds=scaffolds, outfile=file_each_protein)\n",
    "    getGffEach(gffall=ls_gff3_repeats, scaffolds=scaffolds, outfile=file_each_repeats)\n",
    "    \n",
    "    os.system('cp ' + file_maker_bopts + ' ' + outfolder + '/')\n",
    "    os.system('cp ' + file_maker_exe + ' ' + outfolder + '/')\n",
    "    os.system('cp ' + file_maker_opts + ' ' + outfolder + '/')\n",
    "    \n",
    "    open(os.path.join(folder_cmds,'qsub'+str(i)),'w').write(qsub_common.format(workfolder=outfolder))\n",
    "\n",
    "#for i in range(N):\n",
    "#    processOne(i)\n",
    "#    break\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(32)\n",
    "pool.map(processOne,list(range(N)))\n",
    "pool.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "workfolder=/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/cmds\n",
    "tosub=`ls $workfolder`\n",
    "for onefile in $tosub; do qsub \"$workfolder/$onefile\"; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### glimmer\n",
    "```\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/runGlimmer.py -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/genome.fa -d /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/17_train_denovo/train_glimmer/TrainGlimm/ -G /home/xcao/p/GlimmerHMM/GlimmerHMM/bin/glimmerhmm_linux_x86_64 -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/glimmer.gtf -t 32\n",
    "\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/\n",
    "source activate bio\n",
    "gffread glimmer.gtf -o glimmer.gff3\n",
    "```\n",
    "\n",
    "3318\n",
    "```\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/runGlimmer.py -g /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/genome.fa -d /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/17_train_denovo/train_glimmer/3318/ -G /home/xcao/p/GlimmerHMM/GlimmerHMM/bin/glimmerhmm_linux_x86_64 -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/glimmer.gtf -t 32\n",
    "\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/\n",
    "source activate bio\n",
    "gffread glimmer.gtf -o glimmer.gff3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maker does not work well on alea. Transfer files to bioHPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#transfer files\n",
    "scp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/* s185491@nucleus.biohpc.swmed.edu:/work/biophysics/s185491/2018Hermeuptychia/20190106maker/3303/\n",
    "scp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318//18_annotate_denovo/* s185491@nucleus.biohpc.swmed.edu:/work/biophysics/s185491/2018Hermeuptychia/20190106maker/3318/\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "\n",
    "workfolder = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/3303/'\n",
    "folder_makers = os.path.join(workfolder, 'maker_split')\n",
    "folder_cmds = os.path.join(workfolder, 'cmds')\n",
    "folder_ref = os.path.join(workfolder,'maker')\n",
    "file_maker_bopts = os.path.join(folder_ref,'maker_bopts.ctl')\n",
    "file_maker_exe = os.path.join(folder_ref,'maker_exe.ctl')#add missing programs to this file\n",
    "file_maker_opts = os.path.join(folder_ref,'maker_opts.ctl')#edit this file so that it works for all. \n",
    "#Basically, since all individual runs have similar input, set \n",
    "## genome=genome_each.fa\n",
    "## est_gff=est_each.gff\n",
    "## protein_gff=protein_each.gff\n",
    "## rm_gff=repeats_each.gff\n",
    "## est2genome=1\n",
    "## protein2genome=1\n",
    "## trna=1 # or 0 depending on whether to find tRNAs\n",
    "# other trained data file need to be changed, too\n",
    "file_genome = os.path.join(workfolder,'genome.fa')\n",
    "gff3_genomeBased = os.path.join(workfolder, 'genomeBased.combined.gff3')\n",
    "gff3_homologyBased = os.path.join(workfolder, 'homologyBased.combined.gff3')\n",
    "gff3_repeats = os.path.join(workfolder,'repeats.gff3')\n",
    "\n",
    "qsub_common = '''#!/bin/bash\n",
    "#SBATCH --job-name=maker\n",
    "#SBATCH --partition=32GB\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time=10-00:00:00\n",
    "#SBATCH --output=0.%j.out\n",
    "#####SBATCH --mail-user=xiaolong.cao@utsouthwestern.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "\n",
    "cd {workfolder}\n",
    "\n",
    "/home2/jshen3/apps/maker/bin/maker --ignore_nfs_tmp\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def makefolder(*paths):\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "def writeFasta(seqs,outfile):\n",
    "    '''\n",
    "    seqs is a list of SeqIO sequence, write sequence to outfile\n",
    "    '''\n",
    "    with open(outfile,'w') as f:\n",
    "        for s in seqs:\n",
    "            f.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "    return None\n",
    "\n",
    "def getGffEach(gffall, scaffolds, outfile):\n",
    "    '''\n",
    "    gffall is a filename or a list by reading the gffall file with readlines()\n",
    "    scaffolds is scaffolds to keep in gffall\n",
    "    outfile is where to save the output file\n",
    "    filter the gffall with scaffolds, and save output to outfile\n",
    "    '''\n",
    "    if isinstance(gffall, str):\n",
    "        print('input gffall is a filename. Read it to list')\n",
    "        gffall = open(gffall).readlines()\n",
    "    elif isinstance(gffall,list):\n",
    "        print('input gffall is a list')\n",
    "    else:\n",
    "        print('unknown format for input')\n",
    "        return None\n",
    "\n",
    "    if isinstance(scaffolds, list):\n",
    "        scaffolds = set(scaffolds)\n",
    "    if not isinstance(scaffolds,set):\n",
    "        print('scaffolds should be a list or set')\n",
    "        return None\n",
    "\n",
    "    with open(outfile,'w') as f:\n",
    "        for line in gffall:\n",
    "            elements = line.split('\\t')\n",
    "            if len(elements) >8:\n",
    "                if elements[0] in scaffolds:\n",
    "                    f.write(line)\n",
    "    return None\n",
    "\n",
    "N = 1000\n",
    "makefolder(folder_cmds)\n",
    "makefolder(folder_makers)\n",
    "genome_seqs = list(SeqIO.parse(file_genome,'fasta'))\n",
    "ls_gff3_genomeBased = open(gff3_genomeBased).readlines()\n",
    "ls_gff3_homologyBased = open(gff3_homologyBased).readlines()\n",
    "ls_gff3_repeats = open(gff3_repeats).readlines()\n",
    "\n",
    "#split genome_seqs to N parts\n",
    "ls_genomeIDs = np.array_split(range(len(genome_seqs)),N)\n",
    "ls_genomeSeqs = [[genome_seqs[i] for i in e] for e in ls_genomeIDs]\n",
    "\n",
    "#split genome sequences to each folder\n",
    "# for each folder, create genome_each.fa est_each.gff protein_each.gff repeats_each.gff\n",
    "\n",
    "def processOne(i):\n",
    "    outfolder = os.path.join(folder_makers, str(i))\n",
    "    makefolder(outfolder)\n",
    "    file_each_genome = os.path.join(outfolder,'genome_each.fa')\n",
    "    file_each_est = os.path.join(outfolder,'est_each.gff')\n",
    "    file_each_protein = os.path.join(outfolder,'protein_each.gff')\n",
    "    file_each_repeats = os.path.join(outfolder,'repeats_each.gff')\n",
    "    writeFasta(ls_genomeSeqs[i], file_each_genome)\n",
    "    scaffolds = [e.id for e in ls_genomeSeqs[i]]\n",
    "    getGffEach(gffall=ls_gff3_genomeBased, scaffolds=scaffolds, outfile=file_each_est)\n",
    "    getGffEach(gffall=ls_gff3_homologyBased, scaffolds=scaffolds, outfile=file_each_protein)\n",
    "    getGffEach(gffall=ls_gff3_repeats, scaffolds=scaffolds, outfile=file_each_repeats)\n",
    "\n",
    "    os.system('cp ' + file_maker_bopts + ' ' + outfolder + '/')\n",
    "    os.system('cp ' + file_maker_exe + ' ' + outfolder + '/')\n",
    "    os.system('cp ' + file_maker_opts + ' ' + outfolder + '/')\n",
    "\n",
    "    open(os.path.join(folder_cmds,'qsub'+str(i)),'w').write(qsub_common.format(workfolder=outfolder))\n",
    "\n",
    "#for i in range(N):\n",
    "#    processOne(i)\n",
    "#    break\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(32)\n",
    "pool.map(processOne,list(range(N)))\n",
    "pool.close()\n",
    "\n",
    "\n",
    "\n",
    "#for BioHPC\n",
    "folders = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/*/maker_split/*'\n",
    "foldercmd = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/cmds/'\n",
    "import glob\n",
    "import numpy as np\n",
    "workfolders = glob.glob(folders)\n",
    "commandlines = ['''cd {workfolder} && /home2/jshen3/apps/maker/bin/maker --ignore_nfs_tmp\\n'''.format(workfolder=e) for e in workfolders]\n",
    "N=20\n",
    "qsub_common = '''#!/bin/bash\n",
    "#SBATCH --job-name=maker\n",
    "#SBATCH --partition=32GB\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time=10-00:00:00\n",
    "#SBATCH --output=0.%j.out\n",
    "#####SBATCH --mail-user=xiaolong.cao@utsouthwestern.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "\n",
    "\n",
    "python /home2/s185491/p/xiaolongTools/multiThread.py 32 {file_commands}\n",
    "'''\n",
    "\n",
    "ls_commands = np.array_split(commandlines,N)\n",
    "for i,commands in zip(range(N),ls_commands):\n",
    "    file_commands = foldercmd+str(i)\n",
    "    file_qsub = foldercmd+'qsub_'+str(i)\n",
    "    open(file_commands,'w').write(''.join(list(commands)))\n",
    "    open(file_qsub,'w').write(qsub_common.format(file_commands=file_commands))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect data\n",
    "```\n",
    "import glob\n",
    "folder = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/3303/maker_split/'\n",
    "files = glob.glob(folder+'/*/genome_each.maker.output/genome_each_datastore/*/*/*/scaffold*.gff')\n",
    "fout = open(folder+'/../maker_all.gff3','w')\n",
    "for f in files:\n",
    "    fout.write(open(f).read())\n",
    "fout.close()\n",
    "\n",
    "import glob\n",
    "folder = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/3318/maker_split/'\n",
    "files = glob.glob(folder+'/*/genome_each.maker.output/genome_each_datastore/*/*/*/scaffold*.gff')\n",
    "fout = open(folder+'/../maker_all.gff3','w')\n",
    "for f in files:\n",
    "    fout.write(open(f).read())\n",
    "fout.close()\n",
    "```\n",
    "\n",
    "Transfer the data to alea. extract different part the same as previous job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bioHPC maker, change a new augustus so that it works\n",
    "in previous step, augustus does not work\n",
    "\n",
    "```\n",
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "\n",
    "workfolder = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/3303/'\n",
    "folder_makers = os.path.join(workfolder, 'maker_split')\n",
    "folder_cmds = os.path.join(workfolder, 'cmds')\n",
    "folder_ref = os.path.join(workfolder,'maker')\n",
    "file_maker_bopts = os.path.join(folder_ref,'maker_bopts.ctl')\n",
    "file_maker_exe = os.path.join(folder_ref,'maker_exe.ctl')#add missing programs to this file\n",
    "file_maker_opts = os.path.join(folder_ref,'maker_opts.ctl')#edit this file so that it works for all. \n",
    "#Basically, since all individual runs have similar input, set \n",
    "## genome=genome_each.fa\n",
    "## est_gff=est_each.gff\n",
    "## protein_gff=protein_each.gff\n",
    "## rm_gff=repeats_each.gff\n",
    "## est2genome=1\n",
    "## protein2genome=1\n",
    "## trna=1 # or 0 depending on whether to find tRNAs\n",
    "# other trained data file need to be changed, too\n",
    "file_genome = os.path.join(workfolder,'genome.fa')\n",
    "gff3_genomeBased = os.path.join(workfolder, 'genomeBased.combined.gff3')\n",
    "gff3_homologyBased = os.path.join(workfolder, 'homologyBased.combined.gff3')\n",
    "gff3_repeats = os.path.join(workfolder,'repeats.gff3')\n",
    "\n",
    "qsub_common = '''#!/bin/bash\n",
    "#SBATCH --job-name=maker\n",
    "#SBATCH --partition=32GB\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time=10-00:00:00\n",
    "#SBATCH --output=0.%j.out\n",
    "#####SBATCH --mail-user=xiaolong.cao@utsouthwestern.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "\n",
    "cd {workfolder}\n",
    "source /home2/s185491/p/anaconda3/anaconda520/bin/activate bio\n",
    "/home2/jshen3/apps/maker/bin/maker --ignore_nfs_tmp\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def makefolder(*paths):\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "def writeFasta(seqs,outfile):\n",
    "    '''\n",
    "    seqs is a list of SeqIO sequence, write sequence to outfile\n",
    "    '''\n",
    "    with open(outfile,'w') as f:\n",
    "        for s in seqs:\n",
    "            f.write('>'+s.id+'\\n'+str(s.seq)+'\\n')\n",
    "    return None\n",
    "\n",
    "def getGffEach(gffall, scaffolds, outfile):\n",
    "    '''\n",
    "    gffall is a filename or a list by reading the gffall file with readlines()\n",
    "    scaffolds is scaffolds to keep in gffall\n",
    "    outfile is where to save the output file\n",
    "    filter the gffall with scaffolds, and save output to outfile\n",
    "    '''\n",
    "    if isinstance(gffall, str):\n",
    "        print('input gffall is a filename. Read it to list')\n",
    "        gffall = open(gffall).readlines()\n",
    "    elif isinstance(gffall,list):\n",
    "        print('input gffall is a list')\n",
    "    else:\n",
    "        print('unknown format for input')\n",
    "        return None\n",
    "\n",
    "    if isinstance(scaffolds, list):\n",
    "        scaffolds = set(scaffolds)\n",
    "    if not isinstance(scaffolds,set):\n",
    "        print('scaffolds should be a list or set')\n",
    "        return None\n",
    "\n",
    "    with open(outfile,'w') as f:\n",
    "        for line in gffall:\n",
    "            elements = line.split('\\t')\n",
    "            if len(elements) >8:\n",
    "                if elements[0] in scaffolds:\n",
    "                    f.write(line)\n",
    "    return None\n",
    "\n",
    "N = 1000\n",
    "makefolder(folder_cmds)\n",
    "makefolder(folder_makers)\n",
    "genome_seqs = list(SeqIO.parse(file_genome,'fasta'))\n",
    "ls_gff3_genomeBased = open(gff3_genomeBased).readlines()\n",
    "ls_gff3_homologyBased = open(gff3_homologyBased).readlines()\n",
    "ls_gff3_repeats = open(gff3_repeats).readlines()\n",
    "\n",
    "#split genome_seqs to N parts\n",
    "ls_genomeIDs = np.array_split(range(len(genome_seqs)),N)\n",
    "ls_genomeSeqs = [[genome_seqs[i] for i in e] for e in ls_genomeIDs]\n",
    "\n",
    "#split genome sequences to each folder\n",
    "# for each folder, create genome_each.fa est_each.gff protein_each.gff repeats_each.gff\n",
    "\n",
    "def processOne(i):\n",
    "    outfolder = os.path.join(folder_makers, str(i))\n",
    "    makefolder(outfolder)\n",
    "    file_each_genome = os.path.join(outfolder,'genome_each.fa')\n",
    "    file_each_est = os.path.join(outfolder,'est_each.gff')\n",
    "    file_each_protein = os.path.join(outfolder,'protein_each.gff')\n",
    "    file_each_repeats = os.path.join(outfolder,'repeats_each.gff')\n",
    "    writeFasta(ls_genomeSeqs[i], file_each_genome)\n",
    "    scaffolds = [e.id for e in ls_genomeSeqs[i]]\n",
    "    getGffEach(gffall=ls_gff3_genomeBased, scaffolds=scaffolds, outfile=file_each_est)\n",
    "    getGffEach(gffall=ls_gff3_homologyBased, scaffolds=scaffolds, outfile=file_each_protein)\n",
    "    getGffEach(gffall=ls_gff3_repeats, scaffolds=scaffolds, outfile=file_each_repeats)\n",
    "\n",
    "    os.system('ln -s ' + file_maker_bopts + ' ' + outfolder + '/')\n",
    "    os.system('ln -s ' + file_maker_exe + ' ' + outfolder + '/')\n",
    "    os.system('ln -s ' + file_maker_opts + ' ' + outfolder + '/')\n",
    "\n",
    "    open(os.path.join(folder_cmds,'qsub'+str(i)),'w').write(qsub_common.format(workfolder=outfolder))\n",
    "\n",
    "#for i in range(N):\n",
    "#    processOne(i)\n",
    "#    break\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(48)\n",
    "pool.map(processOne,list(range(N)))\n",
    "pool.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folders = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/*/maker_split/*'\n",
    "foldercmd = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/cmds/'\n",
    "import glob\n",
    "import numpy as np\n",
    "workfolders = glob.glob(folders)\n",
    "commandlines = ['''cd {workfolder} && /home2/jshen3/apps/maker/bin/maker --ignore_nfs_tmp &\\n'''.format(workfolder=e) for e in workfolders]\n",
    "N=50\n",
    "qsub_common = '''#!/bin/bash\n",
    "#SBATCH --job-name=maker\n",
    "#SBATCH --partition=32GB\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time=10-00:00:00\n",
    "#SBATCH --output=0.%j.out\n",
    "#####SBATCH --mail-user=xiaolong.cao@utsouthwestern.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "\n",
    "source /home2/s185491/p/anaconda3/anaconda520/bin/activate bio\n",
    "\n",
    "{runninglines}\n",
    "\n",
    "wait\n",
    "\n",
    "'''\n",
    "\n",
    "ls_commands = np.array_split(commandlines,N)\n",
    "for i,commands in zip(range(N),ls_commands):\n",
    "    file_commands = foldercmd+str(i)\n",
    "    file_qsub = foldercmd+'qsub_'+str(i)\n",
    "    runninglines = ''.join(list(commands))\n",
    "    open(file_qsub,'w').write(qsub_common.format(runninglines=runninglines))\n",
    "\n",
    "\n",
    "import glob\n",
    "folder = '/work/biophysics/s185491/2018Hermeuptychia/20190106maker/'\n",
    "files = glob.glob(folder+'/*/*/*/genome_each.maker.output/genome_each_datastore/**/scaffold*.gff', recursive=True)\n",
    "fout = open(folder+'/maker_test.gff3','w')\n",
    "for f in files:\n",
    "    fout.write(open(f).read())\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 19_annotate_consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mkdir /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/\n",
    "cp /alea/home11/congqian/3314/19_annotate_consensus/*.py ./\n",
    "source activate bio\n",
    "\n",
    "python2 prepare_repeatmasker_for_EVM.py ../12_mask_repeats/3303_repeats.gff repeats.gff3\n",
    "python2 prepare_repeatrunner_for_EVM.py ../18_annotate_denovo/maker_repeatrunner.gff maker_repeatrunner.gff3\n",
    "cat repeats.gff3 maker_repeatrunner.gff3 >all_repeats.gff3\n",
    "\n",
    "python prepare_glimmer_for_EVM.py ../18_annotate_denovo/glimmer.gff3 glimmer.gff3\n",
    "python prepare_genemark_for_EVM.py ../18_annotate_denovo/maker_genemark.gff maker_genemark.gff3 \n",
    "python prepare_augustus_for_EVM.py ../18_annotate_denovo/maker_augustus.gff maker_augustus.gff3\n",
    "python prepare_maker_for_EVM.py ../18_annotate_denovo/maker_maker.gff maker_maker.gff3\n",
    "cat maker_maker.gff3 glimmer.gff3 maker_genemark.gff3   maker_augustus.gff3 >denovo.gff3\n",
    "\n",
    "python2 prepare_cufflinks_for_EVM.py ../14_annotate_transcript/stringtie.merged.gtf.gff3 stringtie.gff3\n",
    "python2 prepare_pasa_for_EVM.py ../14_annotate_transcript/sample_mydb_pasa.sqlite.pasa_assemblies.gff3 pasa.gff3\n",
    "cat stringtie.gff3 pasa.gff3 > transcript.gff3\n",
    "\n",
    "python2 prepare_spaln_gff3_for_EVM.py ../18_annotate_denovo/homologyBased.combined.gff3 homolog.gff3 \n",
    "\n",
    "mkdir EVM\n",
    "cd EVM\n",
    "\n",
    "/alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/partition_EVM_inputs.pl --genome ../../18_annotate_denovo/genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --segmentSize 100000000 --overlapSize 10000 --partition_listing partitions_list.out \n",
    "\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/write_EVM_commands.pl --genome ../../18_annotate_denovo/genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --output_file_name evm.out --partitions partitions_list.out --weights /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/weights.txt --search_long_introns 1 > commands\n",
    "\n",
    "cp commands ../commands\n",
    "cd ..\n",
    "split commands commands_split_ -d -n 4 -a 2\n",
    "python /home/xcao/p/xiaolongTools/multiThread.py 32 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/commands_split_00\n",
    "python /home/xcao/p/xiaolongTools/multiThread.py 32 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/commands_split_01\n",
    "python /home/xcao/p/xiaolongTools/multiThread.py 32 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/commands_split_02\n",
    "python /home/xcao/p/xiaolongTools/multiThread.py 32 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/commands_split_03\n",
    "\n",
    "\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/convert_EVM_outputs_to_GFF3.pl  --partitions partitions_list.out --output evm.out  --genome ../../18_annotate_denovo/genome.fa\n",
    "#cat */evm.out.gff3 > ../EVM.gff3 #does not work. argument list too long\n",
    "python /home/xcao/p/xiaolongTools/utils/annotation/combine_files.py -i */evm.out.gff3 -o ../EVM.gff3\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/gff3_file_to_proteins.pl ../EVM.gff3 ../../18_annotate_denovo/genome.fa prot > ../EVM.fa\n",
    "cd ..\n",
    "cat EVM.fa | awk '{printf \"%s\\n\",$1}' > EVM.protein.fa\n",
    "\n",
    "```\n",
    "\n",
    "3318\n",
    "```\n",
    "mkdir /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus\n",
    "cp /alea/home11/congqian/3314/19_annotate_consensus/*.py ./\n",
    "source activate bio\n",
    "\n",
    "\n",
    "python2 prepare_repeatmasker_for_EVM.py ../12_mask_repeats/3318_repeats.gff repeats.gff3\n",
    "python2 prepare_repeatrunner_for_EVM.py ../18_annotate_denovo/maker_repeatrunner.gff maker_repeatrunner.gff3\n",
    "cat repeats.gff3 maker_repeatrunner.gff3 >all_repeats.gff3\n",
    "\n",
    "python prepare_glimmer_for_EVM.py ../18_annotate_denovo/glimmer.gff3 glimmer.gff3\n",
    "python prepare_genemark_for_EVM.py ../18_annotate_denovo/maker_genemark.gff maker_genemark.gff3 \n",
    "python prepare_augustus_for_EVM.py ../18_annotate_denovo/maker_augustus.gff maker_augustus.gff3\n",
    "python prepare_maker_for_EVM.py ../18_annotate_denovo/maker_maker.gff maker_maker.gff3\n",
    "cat maker_maker.gff3 glimmer.gff3 maker_genemark.gff3   maker_augustus.gff3 >denovo.gff3\n",
    "\n",
    "python2 prepare_cufflinks_for_EVM.py ../14_annotate_transcript/stringtie.merged.gtf.gff3 stringtie.gff3\n",
    "python2 prepare_pasa_for_EVM.py ../14_annotate_transcript/3318_genomefilter1.fa.sqlite.pasa_assemblies.gff3 pasa.gff3\n",
    "cat stringtie.gff3 pasa.gff3 > transcript.gff3\n",
    "\n",
    "python2 prepare_spaln_gff3_for_EVM.py ../18_annotate_denovo/homologyBased.combined.gff3 homolog.gff3 \n",
    "\n",
    "mkdir EVM\n",
    "cd EVM\n",
    "\n",
    "/alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/partition_EVM_inputs.pl --genome ../../18_annotate_denovo/genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --segmentSize 100000000 --overlapSize 10000 --partition_listing partitions_list.out \n",
    "\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/write_EVM_commands.pl --genome ../../18_annotate_denovo/genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --output_file_name evm.out --partitions partitions_list.out --weights /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/weights.txt --search_long_introns 1 > commands\n",
    "\n",
    "cp commands ../commands\n",
    "cd ..\n",
    "split commands commands_split_ -d -n 2 -a 2\n",
    "python /home/xcao/p/xiaolongTools/multiThread.py 32 /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/commands_split_00\n",
    "python /home/xcao/p/xiaolongTools/multiThread.py 32 /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/commands_split_01\n",
    "\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/convert_EVM_outputs_to_GFF3.pl  --partitions partitions_list.out --output evm.out  --genome ../../18_annotate_denovo/genome.fa\n",
    "\n",
    "cat */evm.out.gff3 > ../EVM.gff3\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/gff3_file_to_proteins.pl EVM.gff3 ../../18_annotate_denovo/genome.fa prot > ../EVM.fa\n",
    "cd ..\n",
    "cat EVM.fa | awk '{printf \"%s\\n\",$1}' > EVM.protein.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVM is slow. store files in memory\n",
    "```\n",
    "import os\n",
    "os.chdir('/dev/shm/work/')\n",
    "os.rename('/dev/shm/work/EVM/partitions_list.out','/dev/shm/work/partitions_list.out')\n",
    "fout = open('EVM/partitions_list.out','w')\n",
    "lines = open('partitions_list.out').readlines()\n",
    "for l in lines:\n",
    "    f = l.split()[1]+'/evm.out'\n",
    "    if os.path.exists(f):\n",
    "        if len(open(f).readlines()) != 0:\n",
    "            fout.write(l)\n",
    "fout.close()\n",
    "\n",
    "\n",
    "\n",
    "import os,glob\n",
    "os.chdir('/dev/shm/work/')\n",
    "folders = glob.glob('/dev/shm/work/EVM/*')\n",
    "os.mkdir('/dev/shm/work/EVM2/')\n",
    "from collections import Counter\n",
    "from Bio import SeqIO\n",
    "print(Counter([len(glob.glob(e+'/*')) for e in folders]))\n",
    "for f in folders:\n",
    "    if os.path.isdir(f):\n",
    "        seqlen = len(SeqIO.read(f+'/genome.fa','fasta'))\n",
    "        if seqlen<=1000:\n",
    "            os.rename(f,f.replace('EVM','EVM2'))\n",
    "\n",
    "\n",
    "\n",
    "file1 = 'commands'\n",
    "file2 = 'EVM/partitions_list.out'\n",
    "\n",
    "ls1 = open(file1).readlines()\n",
    "ls2 = open(file2).readlines()\n",
    "ls1_keep = []\n",
    "ls2_keep = []\n",
    "from Bio import SeqIO\n",
    "for l1,l2 in zip(ls1,ls2):\n",
    "    fastafile = l2.split()[1] + '/genome.fa'\n",
    "    if len(SeqIO.read(fastafile,'fasta').seq) > 1000:\n",
    "        ls1_keep.append(l1)\n",
    "        ls2_keep.append(l2)\n",
    "\n",
    "open(file1,'w').write(''.join(ls1_keep))\n",
    "open(file2,'w').write(''.join(ls2_keep))\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /dev/shm\n",
    "mkdir work\n",
    "cd work\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/* ./\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/genome.fa ./\n",
    "source activate bio\n",
    "mkdir EVM\n",
    "cd EVM\n",
    "\n",
    "\n",
    "/alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/partition_EVM_inputs.pl --genome ../genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --segmentSize 100000000 --overlapSize 10000 --partition_listing partitions_list.out \n",
    "\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/write_EVM_commands.pl --genome ../genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --output_file_name evm.out --partitions partitions_list.out --weights /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/weights.txt --search_long_introns 1 > commands\n",
    "mv commands ../commands\n",
    "cd ..\n",
    "python /home/xcao/p/xiaolongTools/multiThread.py 48 commands\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/genome.fa* ./\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/convert_EVM_outputs_to_GFF3.pl  --partitions EVM/partitions_list.out --output evm.out  --genome genome.fa\n",
    "\n",
    "cd /dev/shm\n",
    "mkdir work\n",
    "cd work\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/* ./\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/genome.fa ./\n",
    "source activate bio\n",
    "mkdir EVM\n",
    "cd EVM\n",
    "/alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/partition_EVM_inputs.pl --genome ../genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --segmentSize 100000000 --overlapSize 10000 --partition_listing partitions_list.out \n",
    "\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/write_EVM_commands.pl --genome ../genome.fa --gene_predictions ../denovo.gff3 --protein_alignments ../homolog.gff3 --transcript_alignments ../transcript.gff3 --repeats ../all_repeats.gff3 --output_file_name evm.out --partitions partitions_list.out --weights /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/weights.txt --search_long_introns 1 > commands\n",
    "cp commands ../commands\n",
    "cd ..\n",
    "python /home/xcao/p/xiaolongTools/multiThread_shortSleep.py 48 commands\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/convert_EVM_outputs_to_GFF3.pl  --partitions EVM/partitions_list.out --output evm.out  --genome /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/EVM/../../18_annotate_denovo/genome.fa\n",
    "cat EVM/*/evm.out.gff3 >EVM.gff3.20190112\n",
    "cp EVM.gff3.20190112 /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/\n",
    "perl /alea/home5/qc_4/software/evidencemodeler/EVM_r2012-06-25/EvmUtils/gff3_file_to_proteins.pl EVM.gff3.20190112 ../18_annotate_denovo/genome.fa prot > EVM20190112.fa\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine PASA and EVM to make the final version\n",
    "EVM does not work well, as maker never work well. Combine EVM and PASA result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/sample_mydb_pasa.sqlite.pasa_assemblies.gtf -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/3303.pasa_assemblies.gff3\n",
    " \n",
    "gffcompare /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/EVM.gff3.20190110 /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/3303.pasa_assemblies.gff3 -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/20190111_3303  -p 3303 -C -X\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/20190111_3303.combined.gtf -o /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/20190111_3303.combined.gff3\n",
    "\n",
    "\n",
    "\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/3318_genomefilter1.fa.sqlite.pasa_assemblies.gtf -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/3318.pasa_assemblies.gff3\n",
    "\n",
    "gffcompare /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/EVM.gff3.20190110 /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/3318.pasa_assemblies.gff3 -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/20190111_3318  -p 3318 -C -X\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/20190111_3318.combined.gtf -o /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/20190111_3318.combined.gff3\n",
    "\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/20190111_3303.combined.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/20190111_3318.combined.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 21_identify_snp_in_others\n",
    "identify heterozygous rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/21_identify_snp_in_others/\n",
    "ln -s /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa genome.fa\n",
    "ln -s /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/13_align_reads_v1/2_filter3303_250s.TrimP.fq.bam input.bam\n",
    "java -jar /home/xcao/p/picard/picard2.18.20.jar CreateSequenceDictionary R=genome.fa O=genome.dict\n",
    "mkdir tmp\n",
    "samtools faidx genome.fa\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar SortSam INPUT=input.bam OUTPUT=sorted.bam SORT_ORDER=coordinate >& sortBAM.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar MarkDuplicates MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000 INPUT=sorted.bam OUTPUT=sorted_dedup.bam METRICS_FILE=sorted.metrics.txt >& markdup.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar  AddOrReplaceReadGroups  INPUT=sorted_dedup.bam  OUTPUT=sorted_addrg.bam SORT_ORDER=coordinate RGID=group1 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=4285 CREATE_INDEX=True >& add_readgroup.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar  BuildBamIndex INPUT=sorted_addrg.bam >& index.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T RealignerTargetCreator -R genome.fa -I sorted_addrg.bam -o sorted_realignment_targets.list >& prepare_realign.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T IndelRealigner -R genome.fa -I sorted_addrg.bam -targetIntervals sorted_realignment_targets.list -o  sorted_realigned.bam >& realign.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -nct 32 -R genome.fa -T  UnifiedGenotyper -stand_call_conf 30  -I sorted_realigned.bam -o sorted_snp.vcf\n",
    "\n",
    "```\n",
    "\n",
    "3318\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/21_identify_snp_in_others/\n",
    "ln -s /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter1.fa genome.fa\n",
    "ln -s /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/13_align_reads_v1/250bp.bam input.bam\n",
    "samtools faidx genome.fa\n",
    "java -jar /home/xcao/p/picard/picard2.18.20.jar CreateSequenceDictionary R=genome.fa O=genome.dict\n",
    "mkdir tmp\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar SortSam INPUT=input.bam OUTPUT=sorted.bam SORT_ORDER=coordinate >& sortBAM.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar MarkDuplicates INPUT=sorted.bam MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000 OUTPUT=sorted_dedup.bam METRICS_FILE=sorted.metrics.txt >& markdup.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar  AddOrReplaceReadGroups  INPUT=sorted_dedup.bam  OUTPUT=sorted_addrg.bam SORT_ORDER=coordinate RGID=group1 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=4285 CREATE_INDEX=True >& add_readgroup.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/picard/picard2.18.20.jar  BuildBamIndex INPUT=sorted_addrg.bam >& index.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T RealignerTargetCreator -R genome.fa -I sorted_addrg.bam -o sorted_realignment_targets.list >& prepare_realign.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -T IndelRealigner -R genome.fa -I sorted_addrg.bam -targetIntervals sorted_realignment_targets.list -o  sorted_realigned.bam >& realign.log\n",
    "java -Djava.io.tmpdir=tmp -jar /home/xcao/p/gatk/GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar -nct 32 -R genome.fa -T  UnifiedGenotyper -stand_call_conf 30  -I sorted_realigned.bam -o sorted_snp.vcf\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 23 predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# get the fasta file contains all protein sequences, like protein.fasta\n",
    "cd /work/biophysics/s185491/2018Hermeuptychia/20190114functionPrediction/3318/\n",
    "cp /work/archive/biophysics/Nick_lab/jshen3/annotation/3639/23_predict_function/*.py .\n",
    "cp /work/biophysics/s185491/2018Hermeuptychia/20190114functionPrediction/3318/20190111_3318.fa.transdecoder.pep.dedup protein.fasta\n",
    "sed -i 's/\\*//g' protein.fasta\n",
    "\n",
    "\n",
    "# get the fasta file contains all protein sequences, like 3303.fasta\n",
    "cd /work/biophysics/s185491/2018Hermeuptychia/20190114functionPrediction/3303/\n",
    "cp /work/archive/biophysics/Nick_lab/jshen3/annotation/3639/23_predict_function/*.py .\n",
    "cp /work/biophysics/s185491/2018Hermeuptychia/20190114functionPrediction/3303/20190111_3303.fa.transdecoder.pep.dedup protein.fasta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mkdir protein_prots\n",
    "mkdir protein_blastsp\n",
    "mkdir protein_blastdm\n",
    "cd protein_prots\n",
    "python2 ../split_fasta.py ../protein.fasta\n",
    "ls -1 *.fa | awk '{split($1,a,\".fa\");printf \"%s\\n\",a[1]}' > ../protein.list\n",
    "cd ..\n",
    "\n",
    "/home2/s185491/p/anaconda3/anaconda520/envs/bio/bin/blastp -query protein.fasta -out all.blastsp -evalue 0.00001 -db /work/archive/biophysics/Nick_lab/jshen3/database/swissprot -outfmt \"6 qseqid sseqid pident evalue qlen qstart qend slen sstart send qseq sseq stitle\" -task blastp-fast -num_threads 48 -num_alignments 1 \n",
    "/home2/s185491/p/anaconda3/anaconda520/envs/bio/bin/blastp -query protein.fasta -out all.blastdm -evalue 0.00001 -db /work/archive/biophysics/Nick_lab/jshen3/database/Dm_prots -outfmt \"6 qseqid sseqid pident evalue qlen qstart qend slen sstart send qseq sseq stitle\" -task blastp-fast -num_threads 48 -num_alignments 1 \n",
    "python blast_keep1.py all.blastsp\n",
    "python blast_keep1.py all.blastdm\n",
    "\n",
    "\n",
    "cp /work/archive/biophysics/Nick_lab/jshen3/annotation/4190/23_predict_function/Dm_def_map .\n",
    "cp /work/archive/biophysics/Nick_lab/jshen3/annotation/4190/23_predict_function/Dm_go_map .\n",
    "cp /work/archive/biophysics/Nick_lab/jshen3/annotation/4190/23_predict_function/swissprot_gos .\n",
    "python2 get_annotation_from_blastdm.py protein.list > protein_flybase_annotation\n",
    "python2 get_annotation_from_blastsp.py protein.list > protein_swissprot_annotation\n",
    "\n",
    "\n",
    "\n",
    "mkdir protein_blocks\n",
    "mkdir protein_interpro\n",
    "python /home2/s185491/p/xiaolongTools/utils/seq/splitFasta2Nparts.py -s protein.fasta -o protein_blocks/ -N 15\n",
    "#run interpro: scripts not shown here\n",
    "cat ./protein_interpro/*.tsv >protein_interpro.tsv\n",
    "python2 get_go_from_interpro.py protein_interpro.tsv > protein_interpro_go\n",
    "python2 get_domain_from_interpro.py protein_interpro.tsv > protein_interpro_domain\n",
    "python2 get_pathway_from_interpro.py protein_interpro.tsv > protein_interpro_pathway\n",
    "python2 get_signal_from_interpro.py protein_interpro.tsv > protein_interpro_signal\n",
    "cut -f 1,4 protein_flybase_annotation > protein_flybase_go\n",
    "cut -f 1,4 protein_swissprot_annotation > protein_swissprot_go\n",
    "cut -f 1,3 protein_swissprot_annotation > protein_func\n",
    "cut -f 1,2 protein_flybase_annotation > protein_flybase_id\n",
    "python2 integrate_go.py protein_interpro_go protein_flybase_go protein_swissprot_go > protein_gos\n",
    "python2 integrate_all.py protein.list protein.fasta protein_func protein_gos protein_flybase_id protein_interpro_domain protein_interpro_pathway protein_interpro_signal > protein_table\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep only those in final kept proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "file_result = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/23_predict_function/protein_table'\n",
    "fasta_proteins = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3303.fa.transdecoder.pep.dedup.GeneGroup.quality_Xlen100repeats50overlap50'\n",
    "\n",
    "file_result = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/23_predict_function/protein_table'\n",
    "fasta_proteins = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3318.fa.transdecoder.pep.dedup.GeneGroup.quality_Xlen100repeats50overlap50'\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "df = pd.read_csv(file_result,sep='\\t')\n",
    "df2 = df.copy()\n",
    "def getSeq(row):\n",
    "    if row['Sequence'] is np.nan:\n",
    "        return row['SignalP_EUK']\n",
    "    else:\n",
    "        return row['Sequence']\n",
    "df['Sequence'] = df2.apply(getSeq, axis='columns')\n",
    "def getSignalP(row):\n",
    "    if len(row['SignalP_EUK']) > 30:\n",
    "        return 'None'\n",
    "    return row['SignalP_EUK']\n",
    "df['SignalP_EUK'] = df.apply(getSignalP, axis='columns')\n",
    "\n",
    "seq_ids = [s.id for s in SeqIO.parse(fasta_proteins,'fasta')]\n",
    "seq_ids = set(seq_ids)\n",
    "df_keep = df[df['proteinID'].apply(lambda x:x in seq_ids)]\n",
    "\n",
    "\n",
    "df_keep.to_excel('/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/23_predict_function/3303filter_table.xlsx')\n",
    "\n",
    "df_keep.to_excel('/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/23_predict_function/3318filter_table.xlsx')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing for paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get genome information\n",
    "\n",
    "```\n",
    "\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "\n",
    "species = ['Ldi', 'Pra', 'Pse', 'Pgl', 'Ppo', 'Pxu', 'Dpl', 'Hme', 'Mci', 'Cce', 'Lac', 'Mse', 'Bmo', 'Pxy', 'Obr']\n",
    "dc_genomes = {e:'/local/jzhang/genome_comparison_data/genomes/'+e.lower() for e in species}\n",
    "dc_genomes['Hme'] = '/local/jzhang/genome_comparison_data/genomes/hm2'\n",
    "dc_genomes['3303'] = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/8_improve_assembly/wenlin3303min200filter.fa'\n",
    "dc_genomes['3318'] = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/8_improve_assembly/3318_genomefilter1.fa'\n",
    "\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/genomes/'\n",
    "for k,v in dc_genomes.items():\n",
    "    os.system('cp '+v+' '+outfolder+k+'&')\n",
    "\n",
    "species = list(dc_genomes.keys())\n",
    "genomes = [outfolder + e for e in species]\n",
    "\n",
    "def get_information_genome(filename):\n",
    "    '''\n",
    "    filename is a location of genome file. calculate \n",
    "        genome size with N\n",
    "            and without N\n",
    "        scaffold number\n",
    "        Scaffold N50\n",
    "        GC percentage\n",
    "    return a dictionary. keys are 'genome_size_all', 'genome_size_noN', 'scf_count','N50', 'GC_ratio','N_ratio'\n",
    "    '''\n",
    "    from Bio import SeqIO\n",
    "    dc = {}\n",
    "    dc['genome_size_all'] = 0\n",
    "    dc['genome_size_noN'] = 0\n",
    "    dc['scf_count'] = 0\n",
    "    dc['N50'] = 0\n",
    "    dc['GC_ratio'] = 0\n",
    "    ls_seqlen = []\n",
    "    GC = 0\n",
    "    for s in SeqIO.parse(filename,'fasta'):\n",
    "        seq = str(s.seq)\n",
    "        seq = seq.upper()\n",
    "        seqlen = len(seq)\n",
    "        seqlen_noN = sum(seq.count(e) for e in 'ATCG')\n",
    "        dc['scf_count'] += 1\n",
    "        ls_seqlen.append(seqlen)\n",
    "        dc['genome_size_all'] += seqlen\n",
    "        dc['genome_size_noN'] += seqlen_noN\n",
    "        GC += sum(seq.count(e) for e in 'GC')\n",
    "    dc['GC_ratio'] = GC / dc['genome_size_noN']\n",
    "    ls_seqlen.sort()\n",
    "    current = 0\n",
    "    for l in ls_seqlen:\n",
    "        current += l\n",
    "        if current >= dc['genome_size_all'] * 0.5:\n",
    "            dc['N50'] = l\n",
    "            break\n",
    "    dc['N_ratio'] = 1 - dc['genome_size_noN'] / dc['genome_size_all']\n",
    "    dc['species'] = os.path.basename(filename)\n",
    "    return dc\n",
    "\n",
    "pool = Pool(17)\n",
    "ls_info = pool.map(get_information_genome,genomes)\n",
    "pool.close()\n",
    "\n",
    "df = pd.DataFrame(ls_info)\n",
    "df = df.set_index('species')\n",
    "df = df.T\n",
    "df.to_excel('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/genome_sum.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/EVM.protein.fa /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/3303pr\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/EVM.protein.fa /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/3318pr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get transcript and protein sequence for the combined EVM and PASA result\n",
    "20190111\n",
    "```\n",
    "gffread -w /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3303.fa -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/genome.fa /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gff3\n",
    "gffread -w /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3318.combined.fa -g /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/genome.fa /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.gff3\n",
    "\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gff3 -o /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gtf -T\n",
    "\n",
    "gffread /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gff3 -o /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gtf -T\n",
    "\n",
    "/home/xcao/p/transdecoder/TransDecoder-TransDecoder-v5.5.0/util/gtf_to_alignment_gff3.pl /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gtf >/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gtf.gff3\n",
    "/home/xcao/p/transdecoder/TransDecoder-TransDecoder-v5.5.0/util/gtf_to_alignment_gff3.pl /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gtf >/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gtf.gff3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get transcript_id to gene_id\n",
    "```\n",
    "#get transcript_id to gene_id\n",
    "files = '''/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gff3\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gff3\n",
    "'''.split()\n",
    "\n",
    "def get_transcript2gene(filename):\n",
    "    '''\n",
    "    filename is a gff3 file. get and write transcript_id to gene_id\n",
    "    \n",
    "    '''\n",
    "    ls = open(filename).readlines()\n",
    "    fout = open(filename.replace('combined.gff3','tr2gene'),'w')\n",
    "    for l in ls:\n",
    "        l = l.strip()\n",
    "        if len(l)==0:\n",
    "            continue\n",
    "        if l[0]=='#':\n",
    "            continue\n",
    "        es = l.split('\\t')\n",
    "        if len(es)>8:\n",
    "            if es[8].startswith('ID='):\n",
    "                ess = es[8].split(';')\n",
    "                tr_id = ess[0][3:]\n",
    "                gene_id = ess[1][7:]\n",
    "                fout.write(tr_id+'\\t'+gene_id+'\\n')\n",
    "    fout.close()\n",
    "    return None\n",
    "\n",
    "for f in files:\n",
    "    get_transcript2gene(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### genome-guided translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/\n",
    "source activate bio\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3303.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3303.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/cdna_alignment_orf_to_genome_orf.pl 20190111_3303.fa.transdecoder.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gtf.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3303.fa > 20190111_3303.fa.transdecoder.genome.gff3\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3318.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3318.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/cdna_alignment_orf_to_genome_orf.pl 20190111_3318.fa.transdecoder.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gtf.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3318.fa > 20190111_3318.fa.transdecoder.genome.gff3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### improve proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine genes with overlap of 10% sites or over 100bp\n",
    "\n",
    "```\n",
    "\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gff3'\n",
    "\n",
    "lines = open(filename).readlines()\n",
    "dc_scf2gene2loc = {}\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    es = line.split('\\t')\n",
    "    if len(es) > 8:\n",
    "        if 'geneID' in es[8]:\n",
    "            geneID = es[8].split(';')[1][7:]\n",
    "            scf_id = es[0]\n",
    "            if scf_id not in dc_scf2gene2loc:\n",
    "                dc_scf2gene2loc[scf_id] = {}\n",
    "            if geneID not in dc_scf2gene2loc[scf_id]:\n",
    "                dc_scf2gene2loc[scf_id][geneID] = set()\n",
    "            dc_scf2gene2loc[scf_id][geneID].update(range(int(es[3]), int(es[4])+1))\n",
    "\n",
    "\n",
    "#if two genes shares over 10% or 100bp overlap, merge them\n",
    "import itertools\n",
    "dc_scf2groups = {}\n",
    "ratio_min = 0.1\n",
    "overlap_min = 100\n",
    "for scf, gene2loc in dc_scf2gene2loc.items():\n",
    "    dc_scf2groups[scf] = set()\n",
    "    genes = list(gene2loc.keys())\n",
    "    if len(genes) == 1:\n",
    "        dc_scf2groups.add((genes[0],))\n",
    "    for gene1, gene2 in itertools.combinations(genes, 2):\n",
    "        gene1_len = len(gene2loc[gene1])\n",
    "        gene2_len = len(gene2loc[gene2])\n",
    "        overlap = len(gene2loc[gene1] & gene2loc[gene2])\n",
    "        ratio = overlap / min(gene1_len, gene2_len)\n",
    "        if overlap > overlap_min or ratio > ratio_min:\n",
    "            dc_scf2groups[scf].add((gene1, gene2))\n",
    "        else:\n",
    "            dc_scf2groups[scf].add((gene1,))\n",
    "            dc_scf2groups[scf].add((gene2,))\n",
    "\n",
    "dc_scf2lsgroup = {}\n",
    "def groupingPairs(L):\n",
    "    L = [list(e) for e in L]\n",
    "    LL = set(itertools.chain.from_iterable(L)) \n",
    "    # LL is {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'k', 'o', 'p'}\n",
    "    \n",
    "    for each in LL:\n",
    "        components = [x for x in L if each in x]\n",
    "        for i in components:\n",
    "            L.remove(i)\n",
    "        L += [list(set(itertools.chain.from_iterable(components)))]\n",
    "    return L\n",
    "      \n",
    "for scf, groups in dc_scf2groups.items():\n",
    "    dc_scf2lsgroup[scf] = groupingPairs(groups)\n",
    "\n",
    "dc_gene2group = {}\n",
    "for n, genes in enumerate(itertools.chain.from_iterable(dc_scf2lsgroup.values())):\n",
    "    for gene in genes:\n",
    "        dc_gene2group[gene] = n\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.gene2group','w')\n",
    "for gene, group in dc_gene2group.items():\n",
    "    fout.write('{gene}\\t{group}\\n'.format(gene=gene,group=group))\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dealing with transdecoder for final version\n",
    "\n",
    "* get transcritps with proteins.\n",
    "* get genes with protein\n",
    "* keep the longest protein for each gene (20190114 after checking BUSCO, if only keep the longest protein for each gene, some good proteins will be removed. For each gene, if a protein shares over 80% identical amino acids with the longer one, remove it.)\n",
    "* calculate CDS length for all genes\n",
    "* calculate intron length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "file_3303 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.genome.gff3'\n",
    "file_3318 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.genome.gff3'\n",
    "\n",
    "dc_files = {'3303':file_3303, '3318':file_3318}\n",
    "dc_fileinfo = {}\n",
    "for k,filename in dc_files.items():\n",
    "    l = open(filename).readlines()\n",
    "    lines = [e.strip().split('\\t') for e in l if len(e.split('\\t'))>8]\n",
    "    dc_fileinfo[k] = lines\n",
    "\n",
    "def calculateLength(lines,keywords = 'gene'):\n",
    "    l = [e for e in lines if e[2]==keywords]\n",
    "    dc_scf = {}\n",
    "    for e in l:\n",
    "        if e[0] not in dc_scf:\n",
    "            dc_scf[e[0]] = set()\n",
    "        start = int(e[3])-1\n",
    "        end = int(e[4])\n",
    "        if start > end:\n",
    "            print(e,'start > end')\n",
    "        dc_scf[e[0]].update(range(start,end))\n",
    "    return sum(len(v) for v in dc_scf.values())\n",
    "\n",
    "print('3303 gene len',calculateLength(dc_fileinfo['3303'],'gene'))\n",
    "print('3303 CDS len', calculateLength(dc_fileinfo['3303'],'CDS'))\n",
    "print('3318 gene len',calculateLength(dc_fileinfo['3318'],'gene'))\n",
    "print('3318 CDS len', calculateLength(dc_fileinfo['3318'],'CDS'))\n",
    "\n",
    "def getCodingTranscripts(line):\n",
    "    coding = set()\n",
    "    for l in line:\n",
    "        if l[2] == 'CDS':\n",
    "            coding.add(l[8].split(';')[0].split('.')[1])\n",
    "    print('coding transcripts',len(coding))\n",
    "    return coding\n",
    "\n",
    "dc_coding={}#store coding transcripts\n",
    "for k,v in dc_fileinfo.items():\n",
    "    print(k)\n",
    "    dc_coding[k] = getCodingTranscripts(v)\n",
    "\n",
    "import pandas as pd\n",
    "df_t2g_3303 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.tr2gene',header=None,index_col=0,sep='\\t')\n",
    "df_t2g_3318 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.tr2gene',header=None,index_col=0,sep='\\t')\n",
    "dc_t2g_3303 = df_t2g_3303.to_dict()[1]\n",
    "dc_t2g_3318 = df_t2g_3318.to_dict()[1]\n",
    "\n",
    "dc_coding_genes = {}\n",
    "dc_coding_genes['3303'] = set([dc_t2g_3303[e] for e in dc_coding['3303']])\n",
    "dc_coding_genes['3318'] = set([dc_t2g_3318[e] for e in dc_coding['3318']])\n",
    "for k,v in dc_coding_genes.items():\n",
    "    print(k,'coding gene',len(v))\n",
    "    \n",
    "def calculateLengthCodingGene(lines,keywords = 'gene',genes=dc_coding_genes['3303']):\n",
    "    l = [e for e in lines if e[2]==keywords and e[8].split(';')[0][3:] in genes]\n",
    "    dc_scf = {}\n",
    "    for e in l:\n",
    "        if e[0] not in dc_scf:\n",
    "            dc_scf[e[0]] = set()\n",
    "        start = int(e[3])-1\n",
    "        end = int(e[4])\n",
    "        if start > end:\n",
    "            print(e,'start > end')\n",
    "        dc_scf[e[0]].update(range(start,end))\n",
    "    return sum(len(v) for v in dc_scf.values())\n",
    "\n",
    "for k,v in dc_fileinfo.items():\n",
    "    print(k,'coding gene length', calculateLengthCodingGene(v,'gene',dc_coding_genes[k]))\n",
    "\n",
    "#keep longest protein for each gene\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep'\n",
    "genes = dc_coding_genes['3303']\n",
    "from Bio import SeqIO\n",
    "proteins = list(SeqIO.parse(filename,'fasta'))\n",
    "dc_proteins = {}\n",
    "for p in proteins:\n",
    "    gene = dc_t2g_3303[p.id.split('.')[0]]\n",
    "    if gene not in dc_proteins:\n",
    "        dc_proteins[gene] = []\n",
    "    dc_proteins[gene].append(p)\n",
    "\n",
    "pr_3303 = []\n",
    "for seqs in dc_proteins.values():\n",
    "    if len(seqs) == 1:\n",
    "        pr_3303.append(seqs[0])\n",
    "    else:\n",
    "        seqs.sort(key=lambda x:len(x.seq))\n",
    "        pr_3303.append(seqs[-1])\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.longestPerGene','w')\n",
    "for seq in pr_3303:\n",
    "    fout.write('>'+seq.description+'\\n'+str(seq.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "#keep longest protein for each gene\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep'\n",
    "genes = dc_coding_genes['3318']\n",
    "from Bio import SeqIO\n",
    "proteins = list(SeqIO.parse(filename,'fasta'))\n",
    "dc_proteins = {}\n",
    "for p in proteins:\n",
    "    gene = dc_t2g_3318[p.id.split('.')[0]]\n",
    "    if gene not in dc_proteins:\n",
    "        dc_proteins[gene] = []\n",
    "    dc_proteins[gene].append(p)\n",
    "\n",
    "pr_3318 = []\n",
    "for seqs in dc_proteins.values():\n",
    "    if len(seqs) == 1:\n",
    "        pr_3318.append(seqs[0])\n",
    "    else:\n",
    "        seqs.sort(key=lambda x:len(x.seq))\n",
    "        pr_3318.append(seqs[-1])\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.longestPerGene','w')\n",
    "for seq in pr_3318:\n",
    "    fout.write('>'+seq.description+'\\n'+str(seq.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "#keep less redundant protein for each gene\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep'\n",
    "genes = dc_coding_genes['3303']\n",
    "from Bio import SeqIO\n",
    "proteins = list(SeqIO.parse(filename,'fasta'))\n",
    "dc_proteins = {}\n",
    "for p in proteins:\n",
    "    gene = dc_t2g_3303[p.id.split('.')[0]]\n",
    "    if gene not in dc_proteins:\n",
    "        dc_proteins[gene] = []\n",
    "    dc_proteins[gene].append(p)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/xcao/p/xiaolongTools/utils/seq')\n",
    "import sequenceComparison\n",
    "\n",
    "pr_3303 = []\n",
    "pr_3303_longest = []\n",
    "for seqs in dc_proteins.values():\n",
    "    if len(seqs) == 1:\n",
    "        pr_3303.append(seqs[0])\n",
    "    else:\n",
    "        seqs.sort(key=lambda x:len(x.seq),reverse=True)\n",
    "        pr_3303.append(seqs[0])\n",
    "        pr_3303_longest.append(seqs[0])\n",
    "        seqmaxlen = len(seqs[0].seq)\n",
    "        for seq in seqs[1:]:\n",
    "            matchlen = sequenceComparison.getProteinAlignLength([seqs[0],seq], muscle_exe='/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/muscle')\n",
    "            if matchlen / len(seq.seq) < 0.6:\n",
    "                pr_3303.append(seq)\n",
    "                print(seqs[0].id, seqmaxlen, seq.id, len(seq.seq), matchlen, 'keep')\n",
    "            else:\n",
    "                print(seqs[0].id, seqmaxlen, seq.id, len(seq.seq), matchlen, 'remove')\n",
    "\n",
    "def get_unique_per_gene(seqs):\n",
    "    to_return = []\n",
    "    if len(seqs) == 1:\n",
    "        to_return.append(seqs[0])\n",
    "    else:\n",
    "        seqs.sort(key=lambda x:len(x.seq),reverse=True)\n",
    "        to_return.append(seqs[0])\n",
    "        seqmaxlen = len(seqs[0].seq)\n",
    "        for seq in seqs[1:]:\n",
    "            matchlen = sequenceComparison.getProteinAlignLength([seqs[0],seq], muscle_exe='/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/muscle')\n",
    "            if matchlen / len(seq.seq) < 0.6:\n",
    "                to_return.append(seq)\n",
    "                print(seqs[0].id, seqmaxlen, seq.id, len(seq.seq), matchlen, 'keep')\n",
    "            else:\n",
    "                print(seqs[0].id, seqmaxlen, seq.id, len(seq.seq), matchlen, 'remove')\n",
    "    return to_return\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(32)\n",
    "pr_3303_chain = pool.map(get_unique_per_gene, dc_proteins.values())\n",
    "pool.close()\n",
    "import itertools\n",
    "pr_3303 = list(itertools.chain.from_iterable(pr_3303_chain))\n",
    "\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.dedup','w')\n",
    "for seq in pr_3303:\n",
    "    fout.write('>'+seq.description+'\\n'+str(seq.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "\n",
    "#3318\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep'\n",
    "genes = dc_coding_genes['3318']\n",
    "from Bio import SeqIO\n",
    "proteins = list(SeqIO.parse(filename,'fasta'))\n",
    "dc_proteins = {}\n",
    "for p in proteins:\n",
    "    gene = dc_t2g_3318[p.id.split('.')[0]]\n",
    "    if gene not in dc_proteins:\n",
    "        dc_proteins[gene] = []\n",
    "    dc_proteins[gene].append(p)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/xcao/p/xiaolongTools/utils/seq')\n",
    "import sequenceComparison\n",
    "\n",
    "pr_3318 = []\n",
    "for seqs in dc_proteins.values():\n",
    "    if len(seqs) == 1:\n",
    "        pr_3318.append(seqs[0])\n",
    "    else:\n",
    "        seqs.sort(key=lambda x:len(x.seq),reverse=True)\n",
    "        pr_3318.append(seqs[0])\n",
    "        seqmaxlen = len(seqs[0].seq)\n",
    "        for seq in seqs[1:]:\n",
    "            matchlen = sequenceComparison.getProteinAlignLength([seqs[0],seq], muscle_exe='/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/muscle')\n",
    "            if matchlen / len(seq.seq) < 0.6:\n",
    "                pr_3318.append(seq)\n",
    "                print(seqs[0].id, seqmaxlen, seq.id, len(seq.seq), matchlen, 'keep')\n",
    "            else:\n",
    "                print(seqs[0].id, seqmaxlen, seq.id, len(seq.seq), matchlen, 'remove')\n",
    "                \n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup','w')\n",
    "for seq in pr_3318:\n",
    "    fout.write('>'+seq.description+'\\n'+str(seq.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dealing with transdecoder, with gene groups\n",
    "\n",
    "some genes overlap with each other. use gene group to present genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the same as previous step. genes were further grouped. Use group instead of gene.\n",
    "```\n",
    "\n",
    "import pandas as pd\n",
    "df_t2g_3303 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.tr2gene',header=None,index_col=0,sep='\\t')\n",
    "df_t2g_3318 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.tr2gene',header=None,index_col=0,sep='\\t')\n",
    "df_g2G_3303 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.gene2group',header=None,index_col=0,sep='\\t')\n",
    "df_g2G_3318 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.gene2group',header=None,index_col=0,sep='\\t')\n",
    "dc_t2g_3303 = df_t2g_3303.to_dict()[1]\n",
    "dc_t2g_3318 = df_t2g_3318.to_dict()[1]\n",
    "dc_g2G_3303 = df_g2G_3303.to_dict()[1]\n",
    "dc_g2G_3318 = df_g2G_3318.to_dict()[1]\n",
    "dc_t2G_3303 = {k:dc_g2G_3303[v] for k,v in dc_t2g_3303.items()}\n",
    "dc_t2G_3318 = {k:dc_g2G_3318[v] for k,v in dc_t2g_3318.items()}\n",
    "\n",
    "\n",
    "#keep less redundant protein for each gene\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep'\n",
    "from Bio import SeqIO\n",
    "proteins = list(SeqIO.parse(filename,'fasta'))\n",
    "dc_proteins = {}\n",
    "for p in proteins:\n",
    "    gene = dc_t2G_3303[p.id.split('.')[0]]\n",
    "    if gene not in dc_proteins:\n",
    "        dc_proteins[gene] = []\n",
    "    dc_proteins[gene].append(p)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/xcao/p/xiaolongTools/utils/seq')\n",
    "import sequenceComparison\n",
    "import itertools\n",
    "\n",
    "def get_unique_per_gene(seqs):\n",
    "    seqlen = len(seqs)\n",
    "    seqs = sequenceComparison.fasta_uni_keepone(seqs)\n",
    "    if len(seqs) == 1:\n",
    "        return seqs\n",
    "    else:\n",
    "        seqs.sort(key=lambda x:len(x.seq),reverse=True)\n",
    "        to_remove = set()\n",
    "        for seq1,seq2 in itertools.combinations(seqs,2):\n",
    "            if len(seq1.seq) < len(seq2.seq):\n",
    "                seq1, seq2 = seq2, seq1\n",
    "            matchlen = sequenceComparison.getProteinAlignLength([seq1,seq2], muscle_exe='/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/muscle')\n",
    "            if matchlen / len(seq2.seq) > 0.6:\n",
    "                to_remove.add(seq2.id)\n",
    "    print('input', seqlen, 'seqs, with', seqlen -len(seqs),'seqs identical and ', len(to_remove), 'seqs further removed')\n",
    "    return [seq for seq in seqs if seq.id not in to_remove]\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(32)\n",
    "pr_3303_chain = pool.map(get_unique_per_gene, dc_proteins.values())\n",
    "pool.close()\n",
    "pr_3303 = list(itertools.chain.from_iterable(pr_3303_chain))\n",
    "\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.dedup.GeneGroup','w')\n",
    "for seq in pr_3303:\n",
    "    fout.write('>'+seq.description+'\\n'+str(seq.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "\n",
    "#3318\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep'\n",
    "from Bio import SeqIO\n",
    "proteins = list(SeqIO.parse(filename,'fasta'))\n",
    "dc_proteins = {}\n",
    "for p in proteins:\n",
    "    gene = dc_t2G_3318[p.id.split('.')[0]]\n",
    "    if gene not in dc_proteins:\n",
    "        dc_proteins[gene] = []\n",
    "    dc_proteins[gene].append(p)\n",
    "\n",
    "pool = Pool(32)\n",
    "pr_3318_chain = pool.map(get_unique_per_gene, dc_proteins.values())\n",
    "pool.close()\n",
    "pr_3318 = list(itertools.chain.from_iterable(pr_3318_chain))\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup.GeneGroup','w')\n",
    "for seq in pr_3318:\n",
    "    fout.write('>'+seq.description+'\\n'+str(seq.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup.GeneGroup'\n",
    "file_transcript_gff = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gff3'\n",
    "file_repeat_gff = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/all_repeats.gff3'\n",
    "file_transcript = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3318.fa'\n",
    "\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.dedup.GeneGroup'\n",
    "file_transcript_gff = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3303.combined.gff3'\n",
    "file_repeat_gff = '/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/all_repeats.gff3'\n",
    "file_transcript = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3303.fa'\n",
    "\n",
    "\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "seqs = list(SeqIO.parse(filename,'fasta'))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['seqid'] = [e.id for e in seqs]\n",
    "df['seqlen'] = [len(str(e.seq).strip('*')) for e in seqs]\n",
    "df['seqlenNoX'] = [len(str(e.seq).strip('*')) - str(e.seq).upper().count('X') for e in seqs]\n",
    "df['orf_type'] = [e.description.split()[3].split(':')[1] for e in seqs]\n",
    "df['transcript_id'] = df['seqid'].apply(lambda x:x.split('.')[0])\n",
    "seq_transcript = list(SeqIO.parse(file_transcript,'fasta'))\n",
    "dc_transcriptlen = {e.id:len(e.seq) for e in seq_transcript}\n",
    "\n",
    "from collections import defaultdict\n",
    "dc_repeat = defaultdict(set) #key is scaffold, value is a set of sites belong to repeats\n",
    "for line in open(file_repeat_gff):\n",
    "    es = line.split()\n",
    "    if len(es)>8:\n",
    "        dc_repeat[es[0]].update(list(range(int(es[3]), int(es[4])+1)))\n",
    "\n",
    "dc_transcript = {}#key is protein_id, value [scaffold_id, set of exon sites in that scaffold] \n",
    "for line in open(file_transcript_gff):\n",
    "    line = line.strip()\n",
    "    es = line.split()\n",
    "    if len(es)>8:\n",
    "        if es[2] == 'exon':\n",
    "            transcript_id = es[8].split(';')[0].split('=')[1]\n",
    "            if transcript_id not in dc_transcript:\n",
    "                dc_transcript[transcript_id] =[es[0], set(list(range(int(es[3]), int(es[4])+1)))]\n",
    "\n",
    "dc_transcript2gene = {}\n",
    "for line in open(file_transcript_gff):\n",
    "    line = line.strip()\n",
    "    es = line.split()\n",
    "    if len(es)>8:\n",
    "        if es[2] == 'transcript':\n",
    "            transcript_id = es[8].split(';')[0].split('=')[1]\n",
    "            gene_id = es[8].split(';')[1].split('=')[1]\n",
    "            dc_transcript2gene[transcript_id] = gene_id\n",
    "\n",
    "df['scf_id'] = df['transcript_id'].apply(lambda x:dc_transcript[x][0])\n",
    "df['repeats_count'] = df.apply(lambda x: len(dc_repeat[x['scf_id']] & dc_transcript[x['transcript_id']][1]), axis='columns')\n",
    "df['transcript_len'] = df['transcript_id'].apply(lambda x:dc_transcriptlen[x])\n",
    "df['repeats_ratio'] = df['repeats_count'] / df['transcript_len']\n",
    "df['gene_id'] = df['transcript_id'].apply(lambda x: dc_transcript2gene[x])\n",
    "\n",
    "df['quality_Xlen'] = df.apply(lambda x: (x['seqlenNoX']>100) or (x['orf_type'] != 'internal') ,axis='columns')\n",
    "df.to_csv(filename + '.info',sep='\\t')\n",
    "\n",
    "df_filter_qualityXlen = df[df['quality_Xlen']]\n",
    "df_filter_qualityXlen_repeat05 = df[(df['repeats_ratio'] < 0.05) & df['quality_Xlen']  ]\n",
    "df_filter_qualityXlen_repeat25 = df[(df['repeats_ratio'] < 0.25) & df['quality_Xlen']  ]\n",
    "df_filter_qualityXlen_repeat50 = df[(df['repeats_ratio'] < 0.50) & df['quality_Xlen']  ]\n",
    "df_filter_qualityXlen_repeat75 = df[(df['repeats_ratio'] < 0.75) & df['quality_Xlen']  ]\n",
    "\n",
    "\n",
    "def writeSeqs(dfuse, outfilename):\n",
    "    seqids = set(dfuse['seqid'])\n",
    "    fout = open(outfilename,'w')\n",
    "    for s in seqs:\n",
    "        if s.id in seqids:\n",
    "            fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "    fout.close()\n",
    "writeSeqs(df_filter_qualityXlen,filename+'.quality_Xlen100')\n",
    "writeSeqs(df_filter_qualityXlen_repeat05,filename+'.quality_Xlen100repeats05')\n",
    "writeSeqs(df_filter_qualityXlen_repeat25,filename+'.quality_Xlen100repeats25')\n",
    "writeSeqs(df_filter_qualityXlen_repeat50,filename+'.quality_Xlen100repeats50')\n",
    "writeSeqs(df_filter_qualityXlen_repeat75,filename+'.quality_Xlen100repeats75')\n",
    "\n",
    "\n",
    "print(len(df_filter_qualityXlen.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat05.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat25.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat50.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat75.gene_id.unique()))\n",
    "\n",
    "txt = 'source activate bio && cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/{file} -o {file} -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & '\n",
    "\n",
    "files = '''20190111_3303.fa.transdecoder.pep.dedup.GeneGroup\n",
    "20190111_3303.fa.transdecoder.pep.dedup.GeneGroup.quality_Xlen100\n",
    "20190111_3303.fa.transdecoder.pep.dedup.GeneGroup.quality_Xlen100repeats05\n",
    "20190111_3303.fa.transdecoder.pep.dedup.GeneGroup.quality_Xlen100repeats25\n",
    "20190111_3303.fa.transdecoder.pep.dedup.GeneGroup.quality_Xlen100repeats50\n",
    "20190111_3303.fa.transdecoder.pep.dedup.GeneGroup.quality_Xlen100repeats75\n",
    "'''.split()\n",
    "\n",
    "for file in files:\n",
    "    print(txt.format(file=file))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove overlapped proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "file1 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100repeats50'\n",
    "file2 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100repeats50'\n",
    "\n",
    "gff1 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.genome.gff3'\n",
    "gff2 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.genome.gff3'\n",
    "\n",
    "\n",
    "\n",
    "def getDC2Pr2loc(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    dc_scf2gene2loc = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        es = line.split('\\t')\n",
    "        if len(es) > 8:\n",
    "            if es[2] == 'CDS':\n",
    "                geneID = es[8].split(';')[0][3:]\n",
    "                scf_id = es[0]\n",
    "                if scf_id not in dc_scf2gene2loc:\n",
    "                    dc_scf2gene2loc[scf_id] = {}\n",
    "                if geneID not in dc_scf2gene2loc[scf_id]:\n",
    "                    dc_scf2gene2loc[scf_id][geneID] = set()\n",
    "                dc_scf2gene2loc[scf_id][geneID].update(range(int(es[3]), int(es[4])+1))\n",
    "    return dc_scf2gene2loc\n",
    "\n",
    "dc_3303scf2pr2loc = getDC2Pr2loc(gff1)\n",
    "dc_3318scf2pr2loc = getDC2Pr2loc(gff2)\n",
    "\n",
    "#if two proteins shares over 50% remove the shorter one\n",
    "def getPr2group(dc_scf2gene2loc):\n",
    "    import itertools\n",
    "    dc_scf2groups = {}\n",
    "    ratio_min = 0.5\n",
    "    for scf, gene2loc in dc_scf2gene2loc.items():\n",
    "        dc_scf2groups[scf] = set()\n",
    "        genes = list(gene2loc.keys())\n",
    "        if len(genes) == 1:\n",
    "            dc_scf2groups[scf].add((genes[0],))\n",
    "        for gene1, gene2 in itertools.combinations(genes, 2):\n",
    "            gene1_len = len(gene2loc[gene1])\n",
    "            gene2_len = len(gene2loc[gene2])\n",
    "            overlap = len(gene2loc[gene1] & gene2loc[gene2])\n",
    "            ratio = overlap / min(gene1_len, gene2_len)\n",
    "            if  ratio > ratio_min:\n",
    "                dc_scf2groups[scf].add((gene1, gene2))\n",
    "            else:\n",
    "                dc_scf2groups[scf].add((gene1,))\n",
    "                dc_scf2groups[scf].add((gene2,))\n",
    "\n",
    "    dc_scf2lsgroup = {}\n",
    "    def groupingPairs(L):\n",
    "        L = [list(e) for e in L]\n",
    "        LL = set(itertools.chain.from_iterable(L)) \n",
    "        # LL is {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'k', 'o', 'p'}\n",
    "\n",
    "        for each in LL:\n",
    "            components = [x for x in L if each in x]\n",
    "            for i in components:\n",
    "                L.remove(i)\n",
    "            L += [list(set(itertools.chain.from_iterable(components)))]\n",
    "        return L\n",
    "\n",
    "    for scf, groups in dc_scf2groups.items():\n",
    "        dc_scf2lsgroup[scf] = groupingPairs(groups)\n",
    "\n",
    "    dc_gene2group = {}\n",
    "    for n, genes in enumerate(itertools.chain.from_iterable(dc_scf2lsgroup.values())):\n",
    "        for gene in genes:\n",
    "            dc_gene2group[gene] = n\n",
    "    return dc_gene2group\n",
    "\n",
    "dc_3303_pr2group = getPr2group(dc_3303scf2pr2loc)\n",
    "dc_3318_pr2group = getPr2group(dc_3318scf2pr2loc)\n",
    "dc_3303_pr2group = {k.replace('cds.',''):v for k,v in dc_3303_pr2group.items()}\n",
    "dc_3318_pr2group = {k.replace('cds.',''):v for k,v in dc_3318_pr2group.items()}\n",
    "\n",
    "from Bio import SeqIO\n",
    "seqs1 = list(SeqIO.parse(file1,'fasta'))\n",
    "seqs2 = list(SeqIO.parse(file2, 'fasta'))\n",
    "dc_group2pr ={}\n",
    "seqs_nogroup = []\n",
    "for s in seqs1:\n",
    "    if s.id in dc_3303_pr2group:\n",
    "        group = dc_3303_pr2group[s.id]\n",
    "        if group not in dc_group2pr:\n",
    "            dc_group2pr[group] = []\n",
    "        dc_group2pr[group].append(s)\n",
    "    else:\n",
    "        seqs_nogroup.append(s)\n",
    "fout = open(file1+'overlap50','w')\n",
    "for k,s in dc_group2pr.items():\n",
    "    s.sort(key=lambda x:len(x))\n",
    "    s = s[-1]\n",
    "    fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "fout.close()\n",
    "fout = open(file1+'ovelap50_outgenome','w')\n",
    "for s in seqs_nogroup:\n",
    "    fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "dc_group2pr ={}\n",
    "seqs_nogroup = []\n",
    "for s in seqs2:\n",
    "    if s.id in dc_3318_pr2group:\n",
    "        group = dc_3318_pr2group[s.id]\n",
    "        if group not in dc_group2pr:\n",
    "            dc_group2pr[group] = []\n",
    "        dc_group2pr[group].append(s)\n",
    "    else:\n",
    "        seqs_nogroup.append(s)\n",
    "fout = open(file2+'overlap50','w')\n",
    "for k,s in dc_group2pr.items():\n",
    "    s.sort(key=lambda x:len(x))\n",
    "    s = s[-1]\n",
    "    fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "fout.close()\n",
    "fout = open(file2+'ovelap50_outgenome','w')\n",
    "for s in seqs_nogroup:\n",
    "    fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "file1 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100repeats50'\n",
    "file2 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100repeats50'\n",
    "\n",
    "gff1 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.genome.gff3'\n",
    "gff2 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.genome.gff3'\n",
    "\n",
    "\n",
    "\n",
    "def getDC2Pr2loc(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    dc_scf2gene2loc = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        es = line.split('\\t')\n",
    "        if len(es) > 8:\n",
    "            if es[2] == 'CDS':\n",
    "                geneID = es[8].split(';')[0][3:]\n",
    "                scf_id = es[0]\n",
    "                if scf_id not in dc_scf2gene2loc:\n",
    "                    dc_scf2gene2loc[scf_id] = {}\n",
    "                if geneID not in dc_scf2gene2loc[scf_id]:\n",
    "                    dc_scf2gene2loc[scf_id][geneID] = set()\n",
    "                dc_scf2gene2loc[scf_id][geneID].update(range(int(es[3]), int(es[4])+1))\n",
    "    return dc_scf2gene2loc\n",
    "\n",
    "dc_3303scf2pr2loc = getDC2Pr2loc(gff1)\n",
    "dc_3318scf2pr2loc = getDC2Pr2loc(gff2)\n",
    "\n",
    "#if two proteins shares over 50% remove the shorter one\n",
    "def getPr2group(dc_scf2gene2loc):\n",
    "    import itertools\n",
    "    dc_scf2groups = {}\n",
    "    ratio_min = 0.5\n",
    "    for scf, gene2loc in dc_scf2gene2loc.items():\n",
    "        dc_scf2groups[scf] = set()\n",
    "        genes = list(gene2loc.keys())\n",
    "        if len(genes) == 1:\n",
    "            dc_scf2groups[scf].add((genes[0],))\n",
    "        for gene1, gene2 in itertools.combinations(genes, 2):\n",
    "            gene1_len = len(gene2loc[gene1])\n",
    "            gene2_len = len(gene2loc[gene2])\n",
    "            overlap = len(gene2loc[gene1] & gene2loc[gene2])\n",
    "            ratio = overlap / min(gene1_len, gene2_len)\n",
    "            if  ratio > ratio_min:\n",
    "                dc_scf2groups[scf].add((gene1, gene2))\n",
    "            else:\n",
    "                dc_scf2groups[scf].add((gene1,))\n",
    "                dc_scf2groups[scf].add((gene2,))\n",
    "    \n",
    "    dc_scf2lsgroup = {}\n",
    "    def groupingPairs(L):\n",
    "        L = [list(e) for e in L]\n",
    "        LL = set(itertools.chain.from_iterable(L)) \n",
    "        # LL is {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'k', 'o', 'p'}\n",
    "        \n",
    "        for each in LL:\n",
    "            components = [x for x in L if each in x]\n",
    "            for i in components:\n",
    "                L.remove(i)\n",
    "            L += [list(set(itertools.chain.from_iterable(components)))]\n",
    "        return L\n",
    "          \n",
    "    for scf, groups in dc_scf2groups.items():\n",
    "        dc_scf2lsgroup[scf] = groupingPairs(groups)\n",
    "    \n",
    "    dc_gene2group = {}\n",
    "    for n, genes in enumerate(itertools.chain.from_iterable(dc_scf2lsgroup.values())):\n",
    "        for gene in genes:\n",
    "            dc_gene2group[gene] = n\n",
    "    return dc_gene2group\n",
    "\n",
    "dc_3303_pr2group = getPr2group(dc_3303scf2pr2loc)\n",
    "dc_3318_pr2group = getPr2group(dc_3318scf2pr2loc)\n",
    "dc_3303_pr2group = {k.replace('cds.',''):v for k,v in dc_3303_pr2group.items()}\n",
    "dc_3318_pr2group = {k.replace('cds.',''):v for k,v in dc_3318_pr2group.items()}\n",
    "\n",
    "from Bio import SeqIO\n",
    "seqs1 = list(SeqIO.parse(file1,'fasta'))\n",
    "seqs2 = list(SeqIO.parse(file2, 'fasta'))\n",
    "dc_group2pr ={}\n",
    "for s in seqs1:\n",
    "    if s.id in dc_3303_pr2group:\n",
    "        group = dc_3303_pr2group[s.id]\n",
    "        if group not in dc_group2pr:\n",
    "            dc_group2pr[group] = []\n",
    "        dc_group2pr[group].append(s)\n",
    "    else:\n",
    "        dc_group2pr[s.id] = [s]\n",
    "fout = open(file1+'overlap50','w')\n",
    "for k,s in dc_group2pr.items():\n",
    "    s.sort(key=lambda x:len(x))\n",
    "    s = s[-1]\n",
    "    fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "dc_group2pr ={}\n",
    "for s in seqs2:\n",
    "    if s.id in dc_3318_pr2group:\n",
    "        group = dc_3318_pr2group[s.id]\n",
    "        if group not in dc_group2pr:\n",
    "            dc_group2pr[group] = []\n",
    "        dc_group2pr[group].append(s)\n",
    "    else:\n",
    "        dc_group2pr[s.id] = [s]\n",
    "fout = open(file2+'overlap50','w')\n",
    "for k,s in dc_group2pr.items():\n",
    "    s.sort(key=lambda x:len(x))\n",
    "    s = s[-1]\n",
    "    fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "fout.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20190115 further improve protein\n",
    "remove those overlap with repetitive regions\n",
    "\n",
    "\n",
    "```\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup'\n",
    "\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "seqs = list(SeqIO.parse(filename,'fasta'))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['seqid'] = [e.id for e in seqs]\n",
    "df['seqlen'] = [len(str(e.seq).strip('*')) for e in seqs]\n",
    "df['seqlenNoX'] = [len(str(e.seq).strip('*')) - str(e.seq).upper().count('X') for e in seqs]\n",
    "df['orf_type'] = [e.description.split()[3].split(':')[1] for e in seqs]\n",
    "df['transcript_id'] = df['seqid'].apply(lambda x:x.split('.')[0])\n",
    "\n",
    "file_transcript_gff = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/20190111_3318.combined.gff3'\n",
    "file_repeat_gff = '/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/all_repeats.gff3'\n",
    "file_transcript = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/20190111_3318.fa'\n",
    "seq_transcript = list(SeqIO.parse(file_transcript,'fasta'))\n",
    "dc_transcriptlen = {e.id:len(e.seq) for e in seq_transcript}\n",
    "\n",
    "from collections import defaultdict\n",
    "dc_repeat = defaultdict(set) #key is scaffold, value is a set of sites belong to repeats\n",
    "for line in open(file_repeat_gff):\n",
    "    es = line.split()\n",
    "    if len(es)>8:\n",
    "        dc_repeat[es[0]].update(list(range(int(es[3]), int(es[4])+1)))\n",
    "\n",
    "dc_transcript = {}#key is protein_id, value [scaffold_id, set of exon sites in that scaffold] \n",
    "for line in open(file_transcript_gff):\n",
    "    line = line.strip()\n",
    "    es = line.split()\n",
    "    if len(es)>8:\n",
    "        if es[2] == 'exon':\n",
    "            transcript_id = es[8].split(';')[0].split('=')[1]\n",
    "            if transcript_id not in dc_transcript:\n",
    "                dc_transcript[transcript_id] =[es[0], set(list(range(int(es[3]), int(es[4])+1)))]\n",
    "\n",
    "dc_transcript2gene = {}\n",
    "for line in open(file_transcript_gff):\n",
    "    line = line.strip()\n",
    "    es = line.split()\n",
    "    if len(es)>8:\n",
    "        if es[2] == 'transcript':\n",
    "            transcript_id = es[8].split(';')[0].split('=')[1]\n",
    "            gene_id = es[8].split(';')[1].split('=')[1]\n",
    "            dc_transcript2gene[transcript_id] = gene_id\n",
    "\n",
    "df['scf_id'] = df['transcript_id'].apply(lambda x:dc_transcript[x][0])\n",
    "df['repeats_count'] = df.apply(lambda x: len(dc_repeat[x['scf_id']] & dc_transcript[x['transcript_id']][1]), axis='columns')\n",
    "df['transcript_len'] = df['transcript_id'].apply(lambda x:dc_transcriptlen[x])\n",
    "df['repeats_ratio'] = df['repeats_count'] / df['transcript_len']\n",
    "df['gene_id'] = df['transcript_id'].apply(lambda x: dc_transcript2gene[x])\n",
    "\n",
    "df['quality_Xlen'] = df.apply(lambda x: (x['seqlenNoX']>100) or (x['orf_type'] != 'internal') ,axis='columns')\n",
    "df.to_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3318.fa.info',sep='\\t')\n",
    "\n",
    "df_filter_qualityXlen = df[df['quality_Xlen']]\n",
    "df_filter_qualityXlen_repeat05 = df[(df['repeats_ratio'] < 0.05) & df['quality_Xlen']  ]\n",
    "df_filter_qualityXlen_repeat25 = df[(df['repeats_ratio'] < 0.25) & df['quality_Xlen']  ]\n",
    "df_filter_qualityXlen_repeat50 = df[(df['repeats_ratio'] < 0.50) & df['quality_Xlen']  ]\n",
    "df_filter_qualityXlen_repeat75 = df[(df['repeats_ratio'] < 0.75) & df['quality_Xlen']  ]\n",
    "\n",
    "\n",
    "def writeSeqs(dfuse, outfilename):\n",
    "    seqids = set(dfuse['seqid'])\n",
    "    fout = open(outfilename,'w')\n",
    "    for s in seqs:\n",
    "        if s.id in seqids:\n",
    "            fout.write('>'+s.description+'\\n'+str(s.seq)+'\\n')\n",
    "    fout.close()\n",
    "writeSeqs(df_filter_qualityXlen,filename+'.quality_Xlen100')\n",
    "writeSeqs(df_filter_qualityXlen_repeat05,filename+'.quality_Xlen100repeats05')\n",
    "writeSeqs(df_filter_qualityXlen_repeat25,filename+'.quality_Xlen100repeats25')\n",
    "writeSeqs(df_filter_qualityXlen_repeat50,filename+'.quality_Xlen100repeats50')\n",
    "writeSeqs(df_filter_qualityXlen_repeat75,filename+'.quality_Xlen100repeats75')\n",
    "\n",
    "\n",
    "print(len(df_filter_qualityXlen.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat05.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat25.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat50.gene_id.unique()))\n",
    "print(len(df_filter_qualityXlen_repeat75.gene_id.unique()))\n",
    "\n",
    "txt = 'source activate bio && cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/{file} -o {file} -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & '\n",
    "\n",
    "files = '''20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100\n",
    "20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100repeats05\n",
    "20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100repeats25\n",
    "20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100repeats50\n",
    "20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100repeats75\n",
    "20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100\n",
    "20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100repeats05\n",
    "20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100repeats25\n",
    "20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100repeats50\n",
    "20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100repeats75\n",
    "'''.split()\n",
    "\n",
    "for file in files:\n",
    "    print(txt.format(file=file))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUSCO for kept proteins\n",
    "also for other transdecoder results\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.longestPerGene -o 20190111_3303.fa.transdecoder.pep.longestPerGene -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.longestPerGene -o 20190111_3318.fa.transdecoder.pep.longestPerGene -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep -o 20190111_3303.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep -o 20190111_3318.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3303.pasa.fa.transdecoder.pep -o 3303.pasa.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & \n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3303.stringtie.fa.transdecoder.pep -o 3303.stringtie.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & \n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3318.pasa.fa.transdecoder.pep -o 3318.pasa.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & \n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3318.stringtie.fa.transdecoder.pep -o 3318.stringtie.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & \n",
    "\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.dedup -o 20190111_3303.fa.transdecoder.pep.dedup -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & \n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup -o 20190111_3318.fa.transdecoder.pep.dedup -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ & \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ && /home/xcao/p/quast/quast-5.0.2/quast.py -t 32 --eukaryote --large  --no-gzip ./genomes/* -o ./quast -k -m 1 --conserved-genes-finding &\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/genomes/Bombyx_mori/ && /home/xcao/p/quast/quast-5.0.2/quast.py -t 32 --eukaryote --large  --no-gzip Bomo_genome_assembly.fa -o ./quast -k -m 1 --conserved-genes-finding &\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUSCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVM proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for proteins, BUSCO\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/ \n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303pr -o 3303pr_BUSCO -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ \n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318pr -o 3318pr_BUSCO -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/19_annotate_consensus/EVM.fa 3303evm.20190110\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/19_annotate_consensus/EVM.fa 3318evm.20190110\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303evm.20190110 -o 3303evm.20190110_BUSCO -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318evm.20190110 -o 3318evm.20190110_BUSCO -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303evm.20190112 -o 3303evm.20190112_BUSCO -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318evm.20190112 -o 3318evm.20190112_BUSCO -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASA, stringtie, Trinity, Trinity-GG maker transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get sequences\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie.merged.gtf.fasta 3303.stringtie.fa\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/Trinity.fasta Trinity.fa\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/Trinity-GG.fasta Trinity-GG.fa\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/sample_mydb_pasa.sqlite.assemblies.fasta 3303.pasa.fa\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie.merged.gtf.fasta 3318.stringtie.fa\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/3318_genomefilter1.fa.sqlite.assemblies.fasta 3318.pasa.fa\n",
    "gffread -w 3303.maker.fa -g /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/genome.fa /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/18_annotate_denovo/maker_maker.gff\n",
    "gffread -w 3318.maker.fa -g /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/genome.fa /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/18_annotate_denovo/maker_maker.gff\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### genomes\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/genomes\n",
    "source activate bio\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303 -o 3303_BUSCO2 -c 32 -m geno -l /home/xcao/p/BUSCO/db/insecta_odb9/ --long\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318 -o 3318_BUSCO2 -c 32 -m geno -l /home/xcao/p/BUSCO/db/insecta_odb9/ --long\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i Ldi -o Ldi_BUSCO -c 32 -m geno -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run Bombyx with new genome\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/genomes\n",
    "cp /home/xcao/w/genomes/Bombyx_mori/Bomo_genome_assembly.fa ./\n",
    "source activate bio\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i Bomo_genome_assembly.fa -c 48 -m geno -l /home/xcao/p/BUSCO/db/insecta_odb9/ -o Bomo_genome_BUSCO\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run BUSCO\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303.maker.fa -o 3303.maker.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303.pasa.fa -o 3303.pasa.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303.stringtie.fa -o 3303.stringtie.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318.maker.fa -o 3318.maker.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318.pasa.fa -o 3318.pasa.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318.stringtie.fa -o 3318.stringtie.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i Trinity.fa -o Trinity.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i Trinity-GG.fa -o Trinity-GG.fa_BUSCO -c 32 -m tran -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proteins to get species Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "txt_species = '''/home/xcao/w/genomes/proteins_ref/all_pr/aly  Achalarus_lyciades\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/atr  Amyelois_transitella\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/bmo  Bombyx_mori\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/cce  Calycopis_cecrops\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/cne  Calephelis_nemesis\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/csu  Chilo_suppressalis\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/dpl  Danaus plexippus\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_000836215.1_Ppol_1.0_protein.faa  Papilio_polytes\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_002938995.1_ASM293899v1_protein_Vanessa_tameamea.faa  Vanessa_tameamea\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_003589595.1_ASM358959v1_protein_Hyposmocoma_kahamanoa.faa  Hyposmocoma_kahamanoa\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_900239965.1_Bicyclus_anynana_v1.2_protein.faa  Bicyclus_anynana\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/hm2  Heliconius_melpomene_melpomene\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/lac  Lerema_accius\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/ldi  Lymantria_dispar\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/mci  Melitaea_cinxia\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/mse  Manduca_sexta\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/obr  Operophtera_brumata\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pgl  Pterourus_glaucus\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pin  Plodia_interpunctella\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pra  Pieris_rapae\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pse  Phoebis_sennae\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pxu  Papilio_xuthus\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pxy  Plutella_xylostella\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/tni  Trichoplusia_ni\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/mvi  Megathymus_ursus_violae\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3303.pasa.fa.transdecoder.pep  3303_pasa\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3303.stringtie.fa.transdecoder.pep  3303_stringtie\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3318.pasa.fa.transdecoder.pep  3318_pasa\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/3318.stringtie.fa.transdecoder.pep  3318_stringtie\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/Trinity.fa.transdecoder.pep  satyr_trinity\n",
    "'''\n",
    "\n",
    "dc_species ={}\n",
    "_lsinfo = txt_species.strip().split('\\n')\n",
    "for e in _lsinfo:\n",
    "    es = e.split()\n",
    "    dc_species[es[1]] = es[0]\n",
    "\n",
    "import os\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/'\n",
    "for k,v in dc_species.items():\n",
    "    os.system('cd {outfolder} && python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i {filein} -o {fileout} -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/ '.format(filein = v, fileout = 'BUSCO_'+k, outfolder=outfolder))\n",
    "\n",
    "#get complete sequences for each species\n",
    "    \n",
    "def getCompleteIDs(filename):\n",
    "    '''\n",
    "    filename is a BUSCo full table\n",
    "    return dictionary of protein IDs that is Complete or Duplicated. If Duplicated, return the last one\n",
    "    '''\n",
    "    dc = {}\n",
    "    for line in open(filename):\n",
    "        if len(line)<1:\n",
    "            continue\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        es = line.split()\n",
    "        if len(es) <5:\n",
    "            continue\n",
    "        if es[1] == 'Complete' or es[1] == 'Duplicated':\n",
    "            dc[es[0]] = es[2]\n",
    "    return dc\n",
    "\n",
    "file_BUSCO = [outfolder+'run_'+'BUSCO_'+k+'/full_table_BUSCO_'+k+'.tsv' for k in dc_species.keys()]\n",
    "import pandas as pd\n",
    "results = [getCompleteIDs(e) for e in file_BUSCO]\n",
    "df_complete = pd.DataFrame(results)\n",
    "df_complete.index = dc_species.keys()\n",
    "df_complete = df_complete.T\n",
    "#allow 3 missing values per protein\n",
    "missing_allowed = 3\n",
    "df_good = df_complete[df_complete.isna().sum(axis=1) <= missing_allowed]\n",
    "\n",
    "from Bio import SeqIO\n",
    "dc_species_seq = {}\n",
    "for k in dc_species:\n",
    "    dc_species_seq[k] = SeqIO.to_dict(SeqIO.parse(dc_species[k],'fasta'))\n",
    "\n",
    "for n, line in df_good.iterrows():\n",
    "    #break\n",
    "    fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/BUSCO_complete_fasta/'+n,'w')\n",
    "    for k,v in line.items():\n",
    "        try:\n",
    "            seq = dc_species_seq[k][v]\n",
    "            seq='>'+k+'\\n'+str(seq.seq)+'\\n'\n",
    "        except:\n",
    "            seq=''\n",
    "        fout.write(seq)\n",
    "    fout.close()\n",
    "#run muscle\n",
    "import os\n",
    "import glob\n",
    "folder_fasta = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/BUSCO_complete_fasta/'\n",
    "folder_out = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/BUSCO_complete_fastaAlign/'\n",
    "files = os.listdir(folder_fasta)\n",
    "for f in files:\n",
    "    os.system('muscle -in {filein} -out {fileout} -maxiters 1000 &'.format(filein = folder_fasta+f, fileout=folder_out+f))\n",
    "#combine the alignments\n",
    "file_out = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/BUSCO_complete_combine/combined.fa'\n",
    "dc_aligns = {k:'' for k in dc_species}\n",
    "for f in files:\n",
    "    _dc = SeqIO.to_dict(SeqIO.parse(folder_out+f,'fasta'))\n",
    "    for s in _dc.values():\n",
    "        break\n",
    "    seqlen = len(s.seq)\n",
    "    for s in dc_aligns:\n",
    "        if s in _dc:\n",
    "            dc_aligns[s] = dc_aligns[s] + str(_dc[s].seq)\n",
    "        else:\n",
    "            dc_aligns[s] = dc_aligns[s] + '-'*seqlen\n",
    "fout = open(file_out,'w')\n",
    "for k,v in dc_aligns.items():\n",
    "    fout.write('>'+k+'\\n'+v+'\\n')\n",
    "fout.close()\n",
    "\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/PrOfSpecies/'\n",
    "for k,v in dc_species.items():\n",
    "    os.system('cp '+v+' '+outfolder+k)\n",
    "\n",
    "l = '''3303_pasa\n",
    "3303_stringtie\n",
    "3318_pasa\n",
    "3318_stringtie\n",
    "Achalarus_lyciades\n",
    "Amyelois_transitella\n",
    "Bicyclus_anynana\n",
    "Bombyx_mori\n",
    "Calephelis_nemesis\n",
    "Calycopis_cecrops\n",
    "Chilo_suppressalis\n",
    "Danaus\n",
    "Heliconius_melpomene_melpomene\n",
    "Hyposmocoma_kahamanoa\n",
    "Lerema_accius\n",
    "Lymantria_dispar\n",
    "Manduca_sexta\n",
    "Megathymus_ursus_violae\n",
    "Melitaea_cinxia\n",
    "Operophtera_brumata\n",
    "Papilio_polytes\n",
    "Papilio_xuthus\n",
    "Phoebis_sennae\n",
    "Pieris_rapae\n",
    "Plodia_interpunctella\n",
    "Plutella_xylostella\n",
    "Pterourus_glaucus\n",
    "satyr_trinity\n",
    "Trichoplusia_ni\n",
    "Vanessa_tameamea\n",
    "'''.split()\n",
    "txt = '/export/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclAdjustFasta {key} ../PrOfSpecies/{key} 1'\n",
    "for e in l:\n",
    "    print(txt.format(key=e))\n",
    "\n",
    "\n",
    "cmd = 'blastp -num_threads 1 -task blastp-fast -query ./blast/seq{n} -db goodProteins -evalue 0.00001 -max_target_seqs 10000 -outfmt 6 -out ./blast/seq{n}.blast &'\n",
    "for n in range(32):\n",
    "    os.system(cmd.format(n=n))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### species Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run RAxML\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/proteins/BUSCO_complete_combine &&\\\n",
    "/home/xcao/p/RAxML/standard-RAxML-master/raxmlHPC-PTHREADS-SSE3 -m PROTGAMMAGTR -p 234 -s combined30.fa -x 12345 -n combined30 -T 32 -N 100 -f a\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ribosome proteins\n",
    "```\n",
    "cat /export/home10/congqian/3306/24_compare_genomes/ribosome/Dmel_ribosome_prots/CG* >/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/Dmel_ribosome_prots.fa\n",
    "#make blastDB\n",
    "source activate bio\n",
    "makeblastdb -in /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/genomes/3303 -dbtype nucl -out /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/blastDB/3303nt\n",
    "makeblastdb -in /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/genomes/3318 -dbtype nucl -out /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/blastDB/3318nt\n",
    "makeblastdb -in /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3303.fa.transdecoder.pep.dedup -out /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/20190111_3303.fa.transdecoder.pep.dedup -dbtype prot\n",
    "makeblastdb -in /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3318.fa.transdecoder.pep.dedup -out /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/20190111_3318.fa.transdecoder.pep.dedup -dbtype prot\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "file_query = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/Dmel_ribosome_prots.fa'\n",
    "file_check = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3318.fa.transdecoder.pep.dedup'\n",
    "#file_check = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep'\n",
    "#file_check = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/PrOfSpecies/Bombyx_mori'\n",
    "MAKEBLASTDB = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/makeblastdb'\n",
    "workfolder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/'\n",
    "BLASTP = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/blastp'\n",
    "import os\n",
    "#make blastdb\n",
    "basename_query = os.path.basename(file_check)\n",
    "cmd = '{MAKEBLASTDB} -in {file_check} -out {workfolder}/{basename_query}.blastDB -dbtype prot'.format(MAKEBLASTDB=MAKEBLASTDB, file_check=file_check, workfolder=workfolder,basename_query=basename_query)\n",
    "os.system(cmd)\n",
    "\n",
    "#run blastp\n",
    "cmd = '''{BLASTP} -db {workfolder}/{basename_query}.blastDB -query {file_query} -out {workfolder}/{basename_query}.blast6 -outfmt \"6 qseqid sseqid pident evalue qlen qstart qend slen sstart send\"  -num_threads 48 -evalue 0.0000000001'''.format(BLASTP=BLASTP, workfolder=workfolder, file_check=file_check,basename_query=basename_query,file_query=file_query)\n",
    "os.system(cmd)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('{workfolder}/{basename_query}.blast6'.format(workfolder=workfolder, basename_query=basename_query), sep='\\t',header=None)\n",
    "df.columns = ['qseqid', 'sseqid', 'pident', 'evalue', 'qlen', 'qstart', 'qend', 'slen', 'sstart', 'send']\n",
    "#df.drop_duplicates(subset='qseqid')\n",
    "df = df.sort_values(by=['sseqid','evalue'])\n",
    "df_result = df.drop_duplicates(subset=['sseqid'])\n",
    "df_result=df_result.sort_values(by=['qseqid','evalue'])\n",
    "df_result = df_result.drop_duplicates(subset=['qseqid'])\n",
    "\n",
    "#based on genome\n",
    "file_check = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/genomes/3318'\n",
    "TBLASTN = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/tblastn'\n",
    "#make blastdb\n",
    "basename_query = os.path.basename(file_check)\n",
    "cmd = '{MAKEBLASTDB} -in {file_check} -out {workfolder}/{basename_query}.blastDB -dbtype nucl'.format(MAKEBLASTDB=MAKEBLASTDB, file_check=file_check, workfolder=workfolder,basename_query=basename_query)\n",
    "os.system(cmd)\n",
    "#run tblastn\n",
    "cmd = '''{TBLASTN} -db {workfolder}/{basename_query}.blastDB -query {file_query} -out {workfolder}/{basename_query}.blast6 -outfmt \"6 qseqid sseqid pident evalue qlen qstart qend slen sstart send\"  -num_threads 48 -evalue 0.0000000001'''.format(TBLASTN=TBLASTN, workfolder=workfolder, file_check=file_check,basename_query=basename_query,file_query=file_query)\n",
    "os.system(cmd)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('{workfolder}/{basename_query}.blast6'.format(workfolder=workfolder, basename_query=basename_query), sep='\\t',header=None)\n",
    "df.columns = ['qseqid', 'sseqid', 'pident', 'evalue', 'qlen', 'qstart', 'qend', 'slen', 'sstart', 'send']\n",
    "df = df[(df['evalue'] < 1e-5) & (df['pident']>50)]\n",
    "dc_query2position = {}\n",
    "dc_query2len = {}\n",
    "for n,row in df.iterrows():\n",
    "    if row['qseqid'] not in dc_query2position:\n",
    "        dc_query2position[row['qseqid']] = set()\n",
    "    dc_query2position[row['qseqid']].update(range(row['qstart'], row['qend']+1))\n",
    "    dc_query2len[row['qseqid']] = row['qlen']\n",
    "dc_query2position = {k:len(v) for k,v in dc_query2position.items()}\n",
    "df_result = pd.DataFrame([dc_query2len,dc_query2position])\n",
    "df_result = df_result.T\n",
    "df_result.columns = ['qlen','match_len']\n",
    "df_result['cov'] = df_result['match_len'] / df_result['qlen']\n",
    "df_result.to_csv('{workfolder}/{basename_query}.ribosome.result'.format(workfolder=workfolder, basename_query=basename_query), sep='\\t')\n",
    "df_result.shape\n",
    "\n",
    "df2 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/3318.blast6',sep='\\t',header=None)\n",
    "df2.columns = ['qseqid', 'sseqid', 'pident', 'evalue', 'qlen', 'qstart', 'qend', 'slen', 'sstart', 'send']\n",
    "df3 = pd.concat([df,df2])\n",
    "df3 = df3.sort_values(by=['qseqid','evalue'])\n",
    "df4 =df3.drop_duplicates(subset=['qseqid'])\n",
    "df4.shape\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/3303.blast6', sep='\\t',header=None)\n",
    "df2 = pd.read_csv('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/ribosome/20190111_3303.fa.transdecoder.pep.dedup.blast6', sep='\\t',header=None)\n",
    "df3 = pd.concat([df1,df2],ignore_index=True)\n",
    "df3.columns = ['qseqid', 'sseqid', 'pident', 'evalue', 'qlen', 'qstart', 'qend', 'slen', 'sstart', 'send']\n",
    "df3 = df3.sort_values(by=['qseqid','evalue'])\n",
    "df4 =df3.drop_duplicates(subset=['qseqid'])\n",
    "df4.shape\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeats summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python2 /alea/home10/congqian/3306/12_mask_repeats/cleanup_table.py /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/12_mask_repeats/3303_repeats.sum >/home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/12_mask_repeats/3303_repeats.table\n",
    "\n",
    "python2 /alea/home10/congqian/3306/12_mask_repeats/cleanup_table.py /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/12_mask_repeats/3318_repeats.sum >/home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/12_mask_repeats/3318_repeats.sum.table\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gff files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/stringtie.merged.gtf.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3303.stringtie.gff3\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181208QianPipeline/14_annotate_transcript/sample_mydb_pasa.sqlite.pasa_assemblies.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3303.PASA.gff3\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/stringtie.merged.gtf.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3318.stringtie.gff3\n",
    "cp /home/xcao/w/20181205Hermeuptychia/20181224QianPipleline_3318/14_annotate_transcript/3318_genomefilter1.fa.sqlite.pasa_assemblies.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3318.PASA.gff3\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translate proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/\n",
    "source activate bio\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/Trinity.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/Trinity.fa\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/Trinity-GG.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/Trinity-GG.fa\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3303.pasa.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3303.pasa.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/cdna_alignment_orf_to_genome_orf.pl 3303.pasa.fa.transdecoder.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3303.PASA.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3303.pasa.fa > 3303.pasa.fa.transdecoder.genome.gff3\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3303.stringtie.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3303.stringtie.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/cdna_alignment_orf_to_genome_orf.pl 3303.stringtie.fa.transdecoder.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3303.stringtie.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3303.stringtie.fa > 3303.stringtie.fa.transdecoder.genome.gff3\n",
    "\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3318.pasa.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3318.pasa.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/cdna_alignment_orf_to_genome_orf.pl 3318.pasa.fa.transdecoder.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3318.PASA.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3318.pasa.fa > 3318.pasa.fa.transdecoder.genome.gff3\n",
    "\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.LongOrfs -m 60 -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3318.stringtie.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/TransDecoder.Predict -t /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3318.stringtie.fa\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/cdna_alignment_orf_to_genome_orf.pl 3318.stringtie.fa.transdecoder.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/gff/3318.stringtie.gff3 /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transcripts/3318.stringtie.fa > 3318.stringtie.fa.transdecoder.genome.gff3\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### translated protein BUSCO\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder\n",
    "source activate bio\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303.pasa.fa.transdecoder.pep -o 3303.pasa.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318.pasa.fa.transdecoder.pep -o 3318.pasa.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3303.stringtie.fa.transdecoder.pep -o 3303.stringtie.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "python /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/run_BUSCO.py -i 3318.stringtie.fa.transdecoder.pep -o 3318.stringtie.fa.transdecoder.pep -c 32 -m prot -l /home/xcao/p/BUSCO/db/insecta_odb9/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orthomcl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "txt_species = '''/home/xcao/w/genomes/proteins_ref/all_pr/aly  aly\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/atr  atr\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/bmo  bmo\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/cce  cce\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/cne  cne\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/csu  csu\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/dpl  dpl\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_000836215.1_Ppol_1.0_protein.faa  ppo\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_002938995.1_ASM293899v1_protein_Vanessa_tameamea.faa  vta\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_003589595.1_ASM358959v1_protein_Hyposmocoma_kahamanoa.faa  hka\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/GCF_900239965.1_Bicyclus_anynana_v1.2_protein.faa  ban\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/hm2  hm2\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/lac  lac\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/ldi  ldi\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/mci  mci\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/mse  mse\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/obr  obr\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pgl  pgl\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pin  pin\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pra  pra\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pse  pse\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pxu  pxu\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/pxy  pxy\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/tni  tni\n",
    "/home/xcao/w/genomes/proteins_ref/all_pr/mvi  mvi\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3303.fa.transdecoder.pep.dedup  3303\n",
    "/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/transdecoder/20190111_3318.fa.transdecoder.pep.dedup  3318\n",
    "'''\n",
    "dc_species ={}\n",
    "_lsinfo = txt_species.strip().split('\\n')\n",
    "for e in _lsinfo:\n",
    "    es = e.split()\n",
    "    dc_species[es[1]] = es[0]\n",
    "\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/pr_all/'\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "def renamePr(filename,species):\n",
    "    '''\n",
    "    for proteins in pr, reanme protein names to 6digit number P000001\n",
    "    '''\n",
    "    fout = open(outfolder+species,'w')\n",
    "    for n, seq in enumerate(SeqIO.parse(filename,'fasta')):\n",
    "        fout.write('>P{n:06d}\\t{description}\\n{sequence}\\n'.format(n=n+1, description=seq.description, sequence = str(seq.seq)))\n",
    "    fout.close()\n",
    "\n",
    "for k,v in dc_species.items():\n",
    "    renamePr(v,k)\n",
    "\n",
    "orthofolder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/PrOfSpecies/'\n",
    "os.chdir(orthofolder)\n",
    "cmd = '/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclAdjustFasta  {k} {filein} 1'\n",
    "for k in dc_species:\n",
    "    os.system(cmd.format(filein = outfolder+k, fileout = orthofolder+k, k=k))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl\n",
    "/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclFilterFasta ./PrOfSpecies 10 20\n",
    "mv goodProteins.fasta goodProteins\n",
    "/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/makeblastdb -in goodProteins -dbtype prot\n",
    "\n",
    "#split to 32 parts\n",
    "python /home/xcao/p/xiaolongTools/utils/seq/splitFasta2Nparts.py -s /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/goodProteins -N 320 -o /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blast/seq\n",
    "#run blastp\n",
    "#combine the result\n",
    "cat /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blast/seq*.blast > /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/goodProteins.blast\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cmd = 'cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blast/ && /home/xcao/p/anaconda3_5.2.0/envs/bio/bin/blastp -query seq{n} -db ../goodProteins -max_target_seqs 1000 -outfmt 6 -out seq{n}.blast -evalue 0.00001 '\n",
    "\n",
    "qsub = '''#!/bin/bash\n",
    "#$ -S /bin/sh\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "source /home/xcao/.bashrc\n",
    "{cmd}\n",
    "'''\n",
    "for n in range(240):\n",
    "    open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blastcmds/qsub'+str(n),'w').write(qsub.format(cmd=cmd.format(n=n)))\n",
    "\n",
    "\n",
    "```\n",
    "morpho qsub jobs with bash\n",
    "\n",
    "for i in {0..239}; do qsub /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blastcmds/qsub$i; done;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cat /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blast/seq*.blast >/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/goodProteins.blast\n",
    "\n",
    "cd /home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/\n",
    "/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclBlastParser goodProteins.blast ./compliantFasta/ >> similarSequences.txt\n",
    "\n",
    "/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclInstallSchema ./orthomcl.config install_schema.log\n",
    "/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclLoadBlast ./orthomcl.config ./similarSequences.txt\n",
    "/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclPairs ./orthomcl.config ./orthomcl_pairs.log -cleanup=no\n",
    "/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclDumpPairsFiles ./orthomcl.config\n",
    "\n",
    "/home/jshen/apps/mcl-14-137/bin/mcl ./mclInput --abc -I 1.5 -o ./mclOutput\n",
    "\n",
    "/alea/home5/qc_4/software/orthomcl/orthomclSoftware-v2.0.9/bin/orthomclMclToGroups LEP 10000 < mclOutput > groups.txt\n",
    "python2 select_groups_for_tree.py > groups_for_tree\n",
    "mkdir proteins_for_tree\n",
    "python2 get_proteins.py groups_for_tree\n",
    "cat list | awk '{printf \"mkdir %s_prots\\n\",$1}' | bash\n",
    "cat list | awk '{printf \"cd %s_prots\\npython ../split_fasta.py ../%s.fasta &\\ncd ..\\n\",$1,$1}' | bash\n",
    "cat id_mapping  | awk '{printf \"cd %s_transcripts\\npython ../split_fasta.py ../../all_transcriptomes/%s &\\ncd ..\\n\",$1,$2}' | bash\n",
    "python get_transcripts.py groups_for_tree\n",
    "cd transcripts_for_tree/\n",
    "wc -l *.fa | sort -k 1 -g | head -145 | awk '{printf \"rm %s\\n\",$2}' | bash # remove the files that does not contain all the species\n",
    "ls -1 *.fa | awk '{split($1,a,\".\");printf \"%s\\n\",a[1]}' > list\n",
    "cd ../proteins_for_tree/\n",
    "ls -1 *.fa | awk '{split($1,a,\".\");printf \"%s\\n\",a[1]}' > list\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### further process, remove proteins\n",
    "\n",
    "```\n",
    "folder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/compliantFasta/'\n",
    "outfolder = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blast2Dm/'\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "files = glob.glob(folder+'*')\n",
    "for f in files:\n",
    "    fout = open(outfolder+os.path.basename(f),'w')\n",
    "    for s in SeqIO.parse(f,'fasta'):\n",
    "        species, pr_id = s.id.split('|')\n",
    "        fout.write('>'+species+'|'+species+pr_id+'\\n'+str(s.seq)+'\\n')\n",
    "    fout.close()\n",
    "\n",
    "files = [outfolder+os.path.basename(f) for f in files]\n",
    "for f in files:\n",
    "    fout = open(outfolder+'../'+os.path.basename(f).split('.')[0]+'.len','w')\n",
    "    for s in SeqIO.parse(f,'fasta'):\n",
    "        fout.write(s.id+'\\t'+str(len(s.seq))+'\\n')\n",
    "    fout.close()\n",
    "\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/groups.txt'\n",
    "ls_info = open(filename).readlines()\n",
    "fout = open(filename,'w')\n",
    "def helpfun(x):\n",
    "    if '|' in x:\n",
    "        s,i = x.split('|')\n",
    "        return s+'|'+s+i\n",
    "    return x\n",
    "for l in ls_info:\n",
    "    es = l.split()\n",
    "    es = [helpfun(e) for e in es]\n",
    "    fout.write(' '.join(es)+'\\n')\n",
    "fout.close()\n",
    "    \n",
    "\n",
    "\n",
    "BLASTP = '/home/xcao/p/anaconda3_5.2.0/envs/bio/bin/blastp'\n",
    "BLASTDB = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/blast2Dm/Dm_prots'\n",
    "for f in files:\n",
    "    cmd = '''{BLASTP} -db {BLASTDB} -query {file_query} -out {file_out} -outfmt \"6 qseqid sseqid pident evalue qlen qstart qend slen sstart send\"  -num_threads 48 -evalue 0.0000000001 '''.format(BLASTP=BLASTP, BLASTDB=BLASTDB, file_query=f, file_out=f+'.blast_Dm')\n",
    "    print(cmd)\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/all_map_to_flybase','w')\n",
    "ids = set()\n",
    "for f in files:\n",
    "    for l in open(f+'.blast_Dm'):\n",
    "        es = l.split()\n",
    "        if es[0] not in ids:\n",
    "            ids.add(es[0])\n",
    "            pr_id = es[0].split('|')[1]\n",
    "            fout.write(pr_id+'\\t'+es[1]+'\\n')\n",
    "fout.close()\n",
    "\n",
    "\n",
    "# get dc_newName2oldname\n",
    "dc_pr_n2o ={}\n",
    "files_pr_ori = glob.glob('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/pr_all/*')\n",
    "for f in files_pr_ori:\n",
    "    species = os.path.basename(f)\n",
    "    for s in SeqIO.parse(f,'fasta'):\n",
    "        des = s.description.split()\n",
    "        newname = species + des[0]\n",
    "        oldname = species + des[1]\n",
    "        dc_pr_n2o[newname] = oldname\n",
    "dc_pr_o2n ={v:k for k,v in dc_pr_n2o.items()}\n",
    "\n",
    "\n",
    "\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/speciesOldName2NewName','w')\n",
    "for k,v in dc_pr_n2o.items():\n",
    "    fout.write(k+'\\t'+v+'\\n')\n",
    "fout.close()\n",
    "\n",
    "file_fun1 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/3303_fun_ori'\n",
    "file_fun2 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/3318_fun_ori'\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/3303_func','w')\n",
    "for l in open(file_fun1):\n",
    "    e1,e2 = l.split('\\t')\n",
    "    e1 = dc_pr_o2n['3303'+e1]\n",
    "    fout.write(e1+'\\t'+e2)\n",
    "fout.close()\n",
    "fout = open('/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/3318_func','w')\n",
    "for l in open(file_fun2):\n",
    "    e1,e2 = l.split('\\t')\n",
    "    e1 = dc_pr_o2n['3318'+e1]\n",
    "    fout.write(e1+'\\t'+e2)\n",
    "fout.close()\n",
    "\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/duplicate_groups_step4_3303'\n",
    "ls_info = open(filename).readlines()\n",
    "os.rename(filename,filename+'.backup')\n",
    "fout = open(filename,'w')\n",
    "for l in ls_info:\n",
    "    names, info = l.split('\\t',maxsplit=1)\n",
    "    names = names.split(',')\n",
    "    newnames = [dc_pr_n2o[e] for e in names]\n",
    "    newnames = [e[4:] for e in newnames]\n",
    "    newnames = ','.join(newnames)\n",
    "    fout.write(newnames+'\\t'+info)\n",
    "fout.close()\n",
    "filename = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/duplicate_groups_step4_3318'\n",
    "ls_info = open(filename).readlines()\n",
    "os.rename(filename,filename+'.backup')\n",
    "fout = open(filename,'w')\n",
    "for l in ls_info:\n",
    "    names, info = l.split('\\t',maxsplit=1)\n",
    "    names = names.split(',')\n",
    "    newnames = [dc_pr_n2o[e] for e in names]\n",
    "    newnames = [e[4:] for e in newnames]\n",
    "    newnames = ','.join(newnames)\n",
    "    fout.write(newnames+'\\t'+info)\n",
    "fout.close()\n",
    "\n",
    "\n",
    "#for groups.txt, all_map_to_flybase, change sequence names back to their original name. didn't do it\n",
    "file_groups_txt = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/groups.txt'\n",
    "ls_groups_txt = open(file_groups_txt).readlines()\n",
    "os.rename(file_groups_txt,file_groups_txt+'.backup')\n",
    "def helpfun(x):\n",
    "    if '|' in x:\n",
    "        s,i = x.split('|')\n",
    "        return s+'|'+dc_pr_n2o[i]\n",
    "    return x\n",
    "fout = open(file_groups_txt)\n",
    "for l in ls_groups_txt:\n",
    "    es = l.split()\n",
    "    es = [helpfun(e) for e in es]\n",
    "    fout.write(' '.join(es)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "\n",
    "#for group.txt, for 3303 and 3318, only keep those in filtered fasta file\n",
    "file_pr_o2n = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/speciesOldName2NewName'\n",
    "file_3303 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3303.fa.transdecoder.pep.dedup.quality_Xlen100repeats50overlap50'\n",
    "file_3318 = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/summary/20190111_3318.fa.transdecoder.pep.dedup.quality_Xlen100repeats50overlap50'\n",
    "file_group = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/groups.txt'\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "df = pd.read_csv(file_pr_o2n, sep='\\t', header=None)\n",
    "df.columns = ['newName','oldName']\n",
    "def oldname2name(x):\n",
    "    if x[0]== '3':\n",
    "        return x[4:]\n",
    "    return x[3:]\n",
    "df['ori_name'] = df['oldName'].apply(oldname2name)\n",
    "\n",
    "dc_oriName2newName = dict(zip(df['ori_name'], df['newName']))\n",
    "\n",
    "keep_ids = [e.id for e in SeqIO.parse(file_3303,'fasta')] + [e.id for e in SeqIO.parse(file_3318,'fasta')]\n",
    "keep_idsNewName = [dc_oriName2newName[e] for e in keep_ids]\n",
    "keep_idsNewName = set(keep_idsNewName)\n",
    "\n",
    "def helpfun(x):\n",
    "    if '|' not in x:\n",
    "        return x\n",
    "    species = x.split('|')[0]\n",
    "    if species not in ['3303','3318']:\n",
    "        return x\n",
    "    pr_id = x.split('|')[1]\n",
    "    if pr_id not in keep_idsNewName:\n",
    "        print('remove',x)\n",
    "        return ''\n",
    "    return x\n",
    "\n",
    "lines = open(file_group+'.backup').readlines()\n",
    "fout = open(file_group,'w')\n",
    "for line in lines:\n",
    "    es = line.split()\n",
    "    es =[helpfun(e) for e in es]\n",
    "    fout.write(' '.join(es)+'\\n')\n",
    "fout.close()\n",
    "\n",
    "file_map2filybase = '/home/xcao/w/20181205Hermeuptychia/20190105CompareGenomes/orthomcl/all_map_to_flybase'\n",
    "lines = open(file_map2filybase+'.backup').readlines()\n",
    "fout = open(file_map2filybase,'w')\n",
    "for line in lines:\n",
    "    es = line.split()\n",
    "    if es[0].startswith('33'):\n",
    "        if es[0] not in keep_idsNewName:\n",
    "            print('remove',es[0])\n",
    "            continue\n",
    "    fout.write(line)\n",
    "fout.close()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
